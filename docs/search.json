[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Power, Politics, and Data\n        ",
    "section": "",
    "text": "Power, Politics, and Data\n        \n        \n            A Hands-On Introduction to Political Science Data Analysis with R.\n        \n        \n            Winter 2025Department of Government and PoliticsUniversity of Maryland, College Park\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\n\nLecturer\n\n   Harriet Goers\n   Chincoteague Building\n   hgoers@umd.edu\n   hgoers\n\n\n\n\nCourse details\n\n   January 2 - 22\n   Asynchronous\n   Online\n\n\n\nOffice hours\n\n   By appointment\n   Zoom\n\n\n\n\nContacting me\nE-mail is the best ways to get in contact with me. I will try to respond to all course-related e-mails within 24 hours."
  },
  {
    "objectID": "content/03-02-bivariate.html",
    "href": "content/03-02-bivariate.html",
    "title": "Exploring the Relationship Between Two Variables",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"countrycode\", \"broom\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(wbstats)\nlibrary(poliscidata)\nlibrary(countrycode)\nlibrary(broom)\nlibrary(janitor)\nlibrary(ggridges)\nlibrary(modelsummary)\nlibrary(scales)",
    "crumbs": [
      "Content",
      "Session 3",
      "Exploring the Relationship Between Two Variables"
    ]
  },
  {
    "objectID": "content/03-02-bivariate.html#set-up",
    "href": "content/03-02-bivariate.html#set-up",
    "title": "Exploring the Relationship Between Two Variables",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"countrycode\", \"broom\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(wbstats)\nlibrary(poliscidata)\nlibrary(countrycode)\nlibrary(broom)\nlibrary(janitor)\nlibrary(ggridges)\nlibrary(modelsummary)\nlibrary(scales)",
    "crumbs": [
      "Content",
      "Session 3",
      "Exploring the Relationship Between Two Variables"
    ]
  },
  {
    "objectID": "content/03-02-bivariate.html#bivariate-relationships",
    "href": "content/03-02-bivariate.html#bivariate-relationships",
    "title": "Exploring the Relationship Between Two Variables",
    "section": "Bivariate relationships",
    "text": "Bivariate relationships\nHow do two variables move with one another? When when goes up, does the other go down, up, or not really move at all? How dramatic is this shift?\nThe type of variables we have determines how we can answer this question. To begin, we will explore the relationship between two continuous variables. Later in the section, we will look at how to explore the relationship between a continuous and categorical variable.\nWe will return to the relationship between a country’s wealth and health. This question was made popular by the Gapminder project. We were introduced to it during the Transformations section in Session One.\nCollecting our data\nFirst, we need to collect our data. Following the Gapminder project, we measure each country’s health by its average life expectancy and its wealth by its GDP per capita. We will use wbstats::wb_data() to pull these data directly from the World Bank.\n\ngapminder_df &lt;- wb_data(\n  indicator = c(\"SP.DYN.LE00.IN\", \"NY.GDP.PCAP.CD\"),\n  start_date = 2016,\n  end_date = 2016\n) |&gt; \n  # Give these variables more friendly names\n  rename(\n    life_exp = SP.DYN.LE00.IN,\n    gdp_per_cap = NY.GDP.PCAP.CD\n  ) |&gt;\n  mutate(\n    # Create a new variable that is GDP per capita logged\n    log_gdp_per_cap = log(gdp_per_cap),\n    # Add each country's region to the data set\n    region = countrycode(country, \"country.name\", \"region\")\n  ) |&gt; \n  relocate(region, .after = country)\n\ngapminder_df\n\n# A tibble: 217 × 8\n   iso2c iso3c country         region  date gdp_per_cap life_exp log_gdp_per_cap\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n 1 AW    ABW   Aruba           Latin…  2016      27442.     75.6           10.2 \n 2 AF    AFG   Afghanistan     South…  2016        522.     63.1            6.26\n 3 AO    AGO   Angola          Sub-S…  2016       1808.     61.1            7.50\n 4 AL    ALB   Albania         Europ…  2016       4124.     78.9            8.32\n 5 AD    AND   Andorra         Europ…  2016      40130.     NA             10.6 \n 6 AE    ARE   United Arab Em… Middl…  2016      41326.     79.3           10.6 \n 7 AR    ARG   Argentina       Latin…  2016      12700.     76.3            9.45\n 8 AM    ARM   Armenia         Europ…  2016       3524.     74.7            8.17\n 9 AS    ASM   American Samoa  East …  2016      12843.     NA              9.46\n10 AG    ATG   Antigua and Ba… Latin…  2016      16558.     78.2            9.71\n# ℹ 207 more rows\n\n\nWhat is the relationship between these two variables?\nWhat is the relationship between a country’s average life expectancy and its GDP per capita? The easiest way to determine this is to visualize these two variables:\n\nggplot(gapminder_df, aes(x = gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  theme_minimal() + \n  labs(x = \"GDP per capita (USD current)\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\n\nThere seems to be a good case that there is a strong relationship between a country’s GDP per capita (wealth) and its average life expectancy (health). It appears that we expect citizens that live in countries that have larger GPD per capita to live longer, on average. But this relationship is not linear (a straight line drawn through them will not summarize this relationship very well).\nBecause we want to explore linear relationships at this stage of the course, we will look at the logged GDP per capita variable:\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can transform your data to make it easier to work with. Just remember that you now need to talk in terms of logged GDP per capita instead of GDP per capita.\n\n\nI can imagine drawing a straight line among these points that summarizes how they vary with each other. It appears that as a country’s logged GDP per capita increases, so too does the average life expectancy of its population. As wealth increases, so too does health. These increases are consistent across each interval increase in wealth.\nWell, that was easy! What is the relationship between health and wealth? They increase with each other.\nHow can we measure the strength of that relationship?\nNow we need some way of measuring the strength of the relationship. In other words, what amount of the variation in countries’ average life expectancy is associated with variation in their GDP per capita? We can measure the strength of this association using correlations. The correlation coefficient tells us how closely variables relate to one another. It tells us both the strength and direction of the association.\n\nStrength: how closely are these values tied to one another. Measured from 0 to |1|, with values closer to 0 indicating a very weak relationship and values closer to |1| indicating a very strong relationship.\n\n\n\n\n\n\n\nTip\n\n\n\nWhat are those funny looking |s? They represent the absolute value, which is shorthand for the number regardless of its sign. To demonstrate, |1| is the absolute value of 1 and -1.\n\n\n\nDirection: do both \\(X\\) and \\(Y\\) change in the same direction? Positive correlations show that when \\(X\\) increases (decreases), so does \\(Y\\). Negative correlations show that when \\(X\\) increases (decreases), \\(Y\\) decreases (increases). In other words, they move in different directions.\n\nWhat is the correlation between logged GDP per capita and life expectancy?\n\ncor(gapminder_df$log_gdp_per_cap, gapminder_df$life_exp, use = \"complete.obs\")\n\n[1] 0.8506936\n\n\nAs expected, the relationship is positive and strong.\nBuilding a generalizable description of this relationship\nWe have very quickly gained the skills to determine whether the relationship between two variables is positive, negative, or non-existent. We have also learnt how to describe the strength of that relationship. To that end, we are now able to describe the bivariate relationship between health and wealth as a positive and strong one.\nThis is useful, but we tend to need a more concrete way of describing the relationship between two variables. For example, what if a policy-maker comes up to you and asks what you think the effect of a $1,000 increase in a country’s GDP per capita will do to its average life expectancy? We can build simple models of this relationship to provide that policy-maker with a prediction of what we might expect to happen, on average. Further, we can use the model to describe the relationship between these two variables in a generalized way. If a new country were to spring into existence, we can use our knowledge of its GDP per capita to determine how long we might expect its citizens to live.\nOLS and linear regression\nLooking back at our data, we can image a straight line running between each country’s plotted average life expectancy and GDP per capita. Let’s draw that line:\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\n\nWe can, of course, draw many different lines through these points. Each of us has probably drawn a slightly different line in our heads. Which is the best line?\nOrdinary least squares (OLS) regression provides an answer. OLS regression draws the line that minimizes the distance between itself and all of the data points. That line can take many shapes, including a straight line, an S, a frowney face, and smiley face, etc.\nLooking at our data above, it appears that a straight line is the best line to draw.\n\n\n\n\n\n\nNote\n\n\n\nOverfitting involves fitting a model (or drawing a line through our data) that misses the forest for the trees. You can draw all kinds of shapes through those data that perhaps result in a smaller distance between itself and each dot. In fact, if you draw a line that connects all of those dots there will be no difference between your line and the data points.\nHowever, this model will be too focused on the data we have at hand. Our model will have no idea what to do with any new data points we introduce. This is bad! Your aim here is to produce a generalizable model of the relationship between these two variables, not to draw a line that connects this particular constellation of dots.\n\n\nOkay, so a straight line is the best type of line to draw. But there are still many, many different straight lines that we can draw. Which straight line is best? Remember, OLS regression finds the line that minimizes the distance between itself and all of the data points. Let’s step through this. Look at the graph above.\n\nDraw a line through those dots. Pick a line, any line!\nCalculate the distance between each dot and the line.\nSum up the absolute values of those distances. Remember, we just care about the distance, so we don’t need to worry about whether or not the dots are above or below the line.\nRepeat steps 1 - 3 many, many, many times.\nPick the line with the smallest sum of distances (the results from step 3).\n\nPhew, this seems tedious. Happily, maths and R are to the rescue. Here is the line that minimizes those distances (all with the addition of one extra line of code).\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = F) + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\n\nEstimating a linear model in R\nHow did R do this? To answer this, we will first do some review.\nRemember (back to your high school maths classes) the general equation for a line:\n\\[\ny = a + mx\n\\]\nRead this as: the value of \\(y\\) is the sum of some constant, \\(a\\), and some \\(x\\) variable that has been transformed by some slope value \\(m\\).\nRemember that the slope constant, \\(m\\), tells you how much \\(y\\) changes for every one unit increase in \\(x\\).\nSo, if:\n\\[\ny = 10 + 2x\n\\]\nThen, when \\(x = 20\\):\n\\[\ny = 10 + 2*20 = 50\n\\]\nFor many values of \\(x\\):\n\nggplot(tibble(x = 0:50, y = 10 + 2*x), aes(x = x, y = y)) + \n  geom_line(colour = \"lightgrey\", linewidth = 3) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\n\n\nWell, let’s substitute in our variables of interest. Our \\(y\\) variable is a country’s average life expectancy and our \\(x\\) variable is that country’s logged GDP per capita.\n\\[\nlife Exp_i = \\beta_0 + \\beta_1 logGdpPerCap_i + \\epsilon\n\\]\nRead this as: country \\(i\\)’s average life expectancy is a function of some constant (\\(\\beta_0\\)) and its logged GDP per capita transformed by some value \\(\\beta_1\\) with some random error (\\(\\epsilon\\)).\nLet’s imagine that this relationship is accurately described by the following formula:\n\\[\nlife Exp_i = 30 + 4 * logGdpPerCap_i\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWe will get to that pesky error term in just a minute.\n\n\nThen, our model would predict the following average life expectancy for countries with log GDPs per capita between 0 and 20:\n\nggplot(\n  tibble(log_gdp_per_cap = 0:20, life_exp = 30 + 4*log_gdp_per_cap), \n  aes(x = log_gdp_per_cap, y = life_exp)\n) + \n  geom_line(colour = \"lightgrey\", linewidth = 3) + \n  geom_point() + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\n\nA country with a logged GDP per capita of 5 (the equivalent of a GDP per capita of $148.41) has a predicted average life expectancy of 50 years, or \\(30 + 4*5\\).\nA country with a logged GDP per capita of 10 (the equivalent of a GDP per capita of $22,026.47) has a predicted average life expectancy of 70 years, or \\(30 + 4*10\\).\nDoes this accurately describe what we see in our data? What is the average life expectancy for countries with roughly $22,000 GDP per capita?\n\ncountries_10 &lt;- filter(gapminder_df, gdp_per_cap &gt; 21000 & gdp_per_cap &lt; 23000)\n\ncountries_10\n\n# A tibble: 3 × 8\n  iso2c iso3c country          region  date gdp_per_cap life_exp log_gdp_per_cap\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n1 KN    KNA   St. Kitts and N… Latin…  2016      21388.     71.7            9.97\n2 SA    SAU   Saudi Arabia     Middl…  2016      21516.     77.1            9.98\n3 SI    SVN   Slovenia         Europ…  2016      21448.     81.2            9.97\n\n\nWe predicted 70 years, but our data suggest that these countries have closer to an average of 77 years. Why do we have this difference?\nWell, we probably haven’t produced the best model we can (this isn’t the best line!). We just picked those numbers (\\(\\beta_0\\) and \\(\\beta_1\\)) out of thin air. Let’s fit a linear OLS regression and see if we improve our ability to predict what we have seen in the wild.\nHow do we calculate the constant (\\(\\beta_0\\)) using OLS regression?\nRemember, OLS regression simply finds the line that minimizes the distance between itself and all the data points.\n\n\n\n\n\n\nNote\n\n\n\nThe constant that minimizes this distance is the mean of \\(Y\\) minus \\(\\beta_1\\) times the mean of \\(X\\). You can prove this using some calculus. We won’t do that here, but feel free to Google it if you are very interested.\n\n\nSo, the constant that best predicts a country’s average life expectancy based on its logged GDP per capita is equal to the average life expectancy across our sample (72.3 years) minus the average logged GDP per capita ($8.80, or $6,652.93 GDP per capita) transformed by \\(\\beta_1\\).\nSo…\nHow do we calculate the coefficient \\(\\beta_1\\)?\nThe regression slope is the correlation coefficient between \\(X\\) and \\(Y\\) multiplied by the standard deviation of \\(Y\\) divided by the standard deviation of \\(X\\).\nEw… Let’s step through that.\nRemember, the correlation coefficient simply measures how \\(X\\) and \\(Y\\) change together. Does \\(Y\\) increase when \\(X\\) increases? How strong is this relationship?\nThe standard deviations of \\(X\\) and \\(Y\\) just measure how spread out they are.\nBringing these together, we are interested in how much \\(X\\) and \\(Y\\) change with each other moderated by how much they change independently of each other.\nFormally:\n\\[\n\\beta_1 = (\\frac{\\Sigma(\\frac{x_i - \\bar{x}}{s_X})(\\frac{y_i - \\bar{y}}{s_Y})}{n - 1})(\\frac{s_Y}{s_X}) = \\frac{\\Sigma(x_i - \\bar{x})(y_i - \\bar{y})}{\\Sigma(x_i - \\bar{x})^2}\n\\]\nHappily R does all of this for us.\nLet’s fit that model already!\n\nm &lt;- lm(life_exp ~ log_gdp_per_cap, data = gapminder_df)\n\nm\n\n\nCall:\nlm(formula = life_exp ~ log_gdp_per_cap, data = gapminder_df)\n\nCoefficients:\n    (Intercept)  log_gdp_per_cap  \n         32.794            4.521  \n\n\nOkay, so the line of best fit describing the relationship between average life expectancy and logged GDP per capita is:\n\\[\nlife Exp_i = 32.9 + 4.5 * logGdpPerCap_i + \\epsilon\n\\]\nThat’s it! We now have a model of the relationship between a country’s average life expectancy and its logged GDP per capita. This model is informed by what we actually observed in the world. It carefully balances our need to accurately describe what we have observed and to develop something that is generalizable.\nThe above model output is difficult to read. It will not be accepted by any journal or professor. Luckily, we can use modelsummary::modelsummary() to easily generate a professionally formatted table.\n\nmodelsummary(\n  m, \n  statistic = NULL,\n  coef_rename = c(\"log_gdp_per_cap\" = \"GDP per capita (logged)\"),\n  gof_map = \"nobs\"\n)\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\n(Intercept)            \n                  32.794\n                \n\nGDP per capita (logged)\n                  4.521 \n                \n\nNum.Obs.               \n                  203   \n                \n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAlways make sure to change your variable names from ones that are easily read by a computer (for example, log_gdp_per_cap to one that are easily read by your human reader (for example, GDP per capita (logged)).\n\n\nAssumptions\nNote that OLS regression, particularly linear regression, requires that you make a lot of important assumptions about the relationship between your two variables. For example, we need to assume that the best line to fit is a straight one. We also assume that the best way to generate and describe the relationship across all observations is to fit the line that minimizes the distance between itself and the observed values or dots.\nThere are other approaches to determining the “best” line. These include maximum likelihood estimation and Bayesian statistics. We won’t discuss these approaches in this class. It’s worth noting here; however, that OLS regression requires a whole bunch of assumptions that may or may not be appropriate to your research question or theory. This class prepares you to grapple with those questions and to appropriately use these tools in your own research.\nPrediction and performance\nOkay, so we now have a model that describes the relationship between our outcome of interest (health) and our independent variable of interest (wealth). We can use this to predict our outcome of interest for different values of our independent variable. For example, what do we predict to be the average life expectancy of a country with a GDP per capita of $20,000?\nbroom::tidy(m) makes this model object a lot easier (tidier) to work with.\n\nm_res &lt;- tidy(m)\nm_res\n\n# A tibble: 2 × 5\n  term            estimate std.error statistic  p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)        32.8      1.75       18.8 4.18e-46\n2 log_gdp_per_cap     4.52     0.197      22.9 4.80e-58\n\n\nFirst, let’s pull out the estimated constant (or intercept or \\(\\beta_0\\)) for our calculations.\n\nbeta_0 &lt;- m_res |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  pull(estimate)\n\nbeta_0\n\n[1] 32.79384\n\n\nNext, let’s pull out the estimated coefficient for (logged) GDP per capita:\n\nbeta_1 &lt;- m_res |&gt; \n  filter(term == \"log_gdp_per_cap\") |&gt; \n  pull(estimate)\n\nbeta_1\n\n[1] 4.520601\n\n\nFinally, we can plug this in to our model:\n\\[\nlife Exp_i = \\beta_0 + \\beta_1 logGdpPerCap_i\n\\]\n\nlife_exp_20000 &lt;- beta_0 + beta_1 * log(20000)\nlife_exp_20000\n\n[1] 77.56355\n\n\nOn average, countries with GDPs per capita of $20,000 are predicted to have an average life expectancy of 78 years.\nLet’s take a look back at our data. Remember, these data describe what the World Bank actually observed for each country in 2016. How close is our predicted value to our observed values?\n\ncountries_10\n\n# A tibble: 3 × 8\n  iso2c iso3c country          region  date gdp_per_cap life_exp log_gdp_per_cap\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt;  &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n1 KN    KNA   St. Kitts and N… Latin…  2016      21388.     71.7            9.97\n2 SA    SAU   Saudi Arabia     Middl…  2016      21516.     77.1            9.98\n3 SI    SVN   Slovenia         Europ…  2016      21448.     81.2            9.97\n\n\nAs above, our data suggest that these countries have closer to an average of 77 years. Although our model predicted an average life expectancy closer to this than our guess above (which predicted 70 years), we still have a gap. Why?\nOur model is an attempt to formalize our understanding of the general relationship between a country’s wealth and health. Plotting our model against the observed values we used to generate it illustrates this point well:\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  geom_vline(xintercept = log(20000)) + \n  geom_hline(yintercept = life_exp_20000) + \n  geom_smooth(method = \"lm\", se = F) + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\n\nThe world is a complicated and messy place. There are many countries that have a GDP per capita of around $20,000 (those dots sitting around the vertical black line). They have a wide range of average life expectancy: look at their various placement along that vertical line. Some are higher than others.\nAlso, there are several countries with a wide range of logged GDP per capita that have an average life expectancy of 78 years (those sitting at or around the horizontal black line). These have a wide range of logged GDP per capita: some are further to the left than others.\nOur model is our best attempt at accounting for that diversity whilst still producing a useful summary of the relationship between health and wealth for those countries and all other countries with all observed values of GDP per capita.\nA bit of noise (or error) is expected. How much error is okay? This is a complicated question that has contested answers. Let’s start with actually measuring that error. Then we can chat about whether or not it’s small enough to allow us to be confident in our model.\nMeasuring error in our model\nReturning to our question above, how close are our predicted values to our observed values? For example, how far from the observed average life expectancy of countries with a GDP per capita of or close to $20,000 is 78 years?\nStart by working out the average life expectancy predicted by our model for the logged GDP per capita of all of our countries. We can then compare this to the average life expectancy actually observed in all these countries. We can predict values from a model using broom::augment():\n\naugment(m)\n\n# A tibble: 203 × 9\n   .rownames life_exp log_gdp_per_cap .fitted .resid    .hat .sigma   .cooksd\n   &lt;chr&gt;        &lt;dbl&gt;           &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1 1             75.6           10.2     79.0 -3.38  0.00999   4.10 0.00347  \n 2 2             63.1            6.26    61.1  2.05  0.0192    4.10 0.00252  \n 3 3             61.1            7.50    66.7 -5.61  0.00850   4.08 0.00812  \n 4 4             78.9            8.32    70.4  8.43  0.00533   4.06 0.0114   \n 5 6             79.3           10.6     80.8 -1.51  0.0132    4.10 0.000921 \n 6 7             76.3            9.45    75.5  0.797 0.00609   4.10 0.000117 \n 7 8             74.7            8.17    69.7  4.95  0.00569   4.09 0.00421  \n 8 10            78.2            9.71    76.7  1.44  0.00712   4.10 0.000448 \n 9 11            82.4           10.8     81.7  0.753 0.0149    4.10 0.000260 \n10 12            81.6           10.7     81.2  0.406 0.0140    4.10 0.0000706\n# ℹ 193 more rows\n# ℹ 1 more variable: .std.resid &lt;dbl&gt;\n\n\nThis function is simply fitting our model (\\(life Exp_i = 32.9 + 4.5 * logGdpPerCap_i\\)) to each country’s logged GDP per capita. You can confirm this by running the model yourself:\n\ngapminder_df |&gt; \n  transmute(country, log_gdp_per_cap, .fitted = beta_0 + beta_1*log_gdp_per_cap)\n\n# A tibble: 217 × 3\n   country              log_gdp_per_cap .fitted\n   &lt;chr&gt;                          &lt;dbl&gt;   &lt;dbl&gt;\n 1 Aruba                          10.2     79.0\n 2 Afghanistan                     6.26    61.1\n 3 Angola                          7.50    66.7\n 4 Albania                         8.32    70.4\n 5 Andorra                        10.6     80.7\n 6 United Arab Emirates           10.6     80.8\n 7 Argentina                       9.45    75.5\n 8 Armenia                         8.17    69.7\n 9 American Samoa                  9.46    75.6\n10 Antigua and Barbuda             9.71    76.7\n# ℹ 207 more rows\n\n\nHow did the model do? What is the difference between what it predicted and the country’s observed average life expectancy? Compare .fitted (the predicted average life expectancy) to life_exp (the actual observed average life expectancy).\n\nm_eval &lt;- augment(m) |&gt; \n  transmute(\n    life_exp, \n    .fitted,\n    diff = life_exp - .fitted\n  )\n\nm_eval\n\n# A tibble: 203 × 3\n   life_exp .fitted   diff\n      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1     75.6    79.0 -3.38 \n 2     63.1    61.1  2.05 \n 3     61.1    66.7 -5.61 \n 4     78.9    70.4  8.43 \n 5     79.3    80.8 -1.51 \n 6     76.3    75.5  0.797\n 7     74.7    69.7  4.95 \n 8     78.2    76.7  1.44 \n 9     82.4    81.7  0.753\n10     81.6    81.2  0.406\n# ℹ 193 more rows\n\n\nNote that broom::augment() already did this calculation and stored it in the .resid variable. The formal term for the difference between the predicted and observed values is the residual.\n\naugment(m) |&gt; \n  select(life_exp, .fitted, .resid)\n\n# A tibble: 203 × 3\n   life_exp .fitted .resid\n      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1     75.6    79.0 -3.38 \n 2     63.1    61.1  2.05 \n 3     61.1    66.7 -5.61 \n 4     78.9    70.4  8.43 \n 5     79.3    80.8 -1.51 \n 6     76.3    75.5  0.797\n 7     74.7    69.7  4.95 \n 8     78.2    76.7  1.44 \n 9     82.4    81.7  0.753\n10     81.6    81.2  0.406\n# ℹ 193 more rows\n\n\nOkay, so there are some differences. Let’s look at those differences a bit more closely:\n\nggplot(augment(m), aes(x = .resid)) + \n  geom_density() + \n  geom_vline(xintercept = 0) + \n  theme_minimal()\n\n\n\n\n\n\n\nIf our model perfectly predicted each country’s life expectancy, we would see no difference between the predicted and observed values. There would just be a very tall straight line at 0 on the graph above.\nOur model hasn’t predicted life expectancy perfectly. Whilst most predictions are within a couple of years of the country’s true life expectancy, there are some that are very different (up to 10 or 15 years!). Where the model has got it wrong, it has tended to overestimate life expectancy (note that the peak of the density curve sits above 0).\nCan you see for which points these large differences exist?\n\nggplot(gapminder_df, aes(x = log_gdp_per_cap, y = life_exp)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = F) + \n  theme_minimal() + \n  labs(x = \"Logged GDP per capita\",\n       y = \"Average life expectancy (years)\") + \n  scale_x_continuous(labels = label_dollar())\n\n\n\n\n\n\n\nWhat is causing these differences? A lot of your work as a political scientist is trying to answer this very question!\n(Random) error\nThe world is a messy and complicated place. Things often vary in random ways. That’s okay! It means that your observational data are going to move in funny and random ways. That’s okay too! As long as your model includes all of the systematic drivers of the thing you are interested in measuring (such as average life expectancy), we can accept a bit of random error.\nIn fact, we have already accounted for this. Remember that error term:\n\\[\nlife Exp_x = \\beta_0 + \\beta_1 logGdpPerCap_x + \\epsilon\n\\]\nWe run into issues when there are non-random things bundled up into the difference between what our model predicts and what we actually observe. We will discuss this more in later sessions.\nA model-wide value for error\nWe often want to understand how the model has performed as a whole, rather than how well it predicts each individual observed data point. There are many different ways we can do this.\nSum of squared residuals (deviance)\nThe sum of squared residuals measures the total error in our model. Formally:\n\\[\n\\Sigma(y_i - \\hat{y_i})^2\n\\]\nWhere \\(y_i\\) is each observed value (the country’s actual average life expectancy) and \\(\\hat{y_i}\\) is each predicted value (the model’s estimate of country’s average life expectancy). We just add those all up to get a single measure of the model’s overall performance.\nRemember that we tend to square things when we don’t care about their direction. We don’t care that the predicted value is less or more than the observed value, just about how far they are from each other.\nWe can do this ourselves:\n\naugment(m) |&gt; \n  summarise(sum(.resid^2))\n\n# A tibble: 1 × 1\n  `sum(.resid^2)`\n            &lt;dbl&gt;\n1           3366.\n\n\nOr we can use broom::glance():\n\nglance(m)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.724         0.722  4.09      526. 4.80e-58     1  -573. 1152. 1162.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nglance(m) |&gt; \n  select(deviance)\n\n# A tibble: 1 × 1\n  deviance\n     &lt;dbl&gt;\n1    3366.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhere broom::tidy() gives us information about the coefficients of our model, broom::glance() gives us information on the model overall.\n\n\nThis is useful, but it is influenced by the units by which we measure our variables. If one model includes something like GDP which is includes values in the billions, we will get a very large sum of squared residuals. If another model includes something like percentage of as state’s citizens who will vote for Donald Trump, we will get a relatively small sum of squared residuals. What if we want to compare model performance in a meaningful way?\n\\(R^2\\)\nThe \\(R^2\\) value measures the amount of variation in the dependent variable that is explained by the independent variable. In our example, it measures how much the changes in countries’ average life expectancy is explained by the changes in their (logged) GDP per capita.\n\\[\nR^2 = 1 - \\frac{Unexplained\\ variation}{Total\\ variation}\n\\]\nThe \\(R^2\\) value is useful because it does not reflect the units of measurement used in our variables. Therefore, we can compare how well different models perform.\nThe \\(R^2\\) value has three component parts.\nTotal Sum of Squares (TSS)\nTSS measures the squared sum of the differences between all predicted values of the dependent variable and the mean of the dependent variable.\nExplained Sum of Squares (ESS)\nESS measures the sum of the squares of the deviations of the predicted values from the mean value of the dependent variable.\nResidual Sum of Squares (RSS)\nRSS measures the difference between the TSS and ESS. In other words, the error not explained by the model.\nFormally, the \\(R^2\\) value is:\n\\[\nR^2 = 1 - \\frac{RSS}{TSS} = 1 - \\frac{\\Sigma(y_i - \\hat{y_i})^2}{\\Sigma(y_i - \\hat{y})^2}\n\\]\nOr:\n\\[\nR^2 = \\frac{ESS}{TSS} = \\frac{\\Sigma(\\hat{y}_i - \\bar{y})^2}{\\Sigma(y_i - \\bar{y})^2}\n\\]\nOur model’s \\(R^2\\) can be accessed using broom::glance():\n\nglance(m) |&gt; \n  select(r.squared)\n\n# A tibble: 1 × 1\n  r.squared\n      &lt;dbl&gt;\n1     0.724\n\n\nAn \\(R^2\\) of one means that all changes in the dependent variable are completely explained by changes in the independent variable. Here, it would mean that all changes to a country’s average life expectancy are explained through changes to the country’s logged GDP per capita.\nAccording to our model, 72.4% of changes in a country’s average life expectancy are explained through changes to the country’s logged GDP per capita.",
    "crumbs": [
      "Content",
      "Session 3",
      "Exploring the Relationship Between Two Variables"
    ]
  },
  {
    "objectID": "content/00-introduction.html",
    "href": "content/00-introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to GVPT399F: Power, Politics, and Data. This hands-on introduction to political science data analysis will (re)introduce you to R and statistics in an accessible and engaging way. We will avoid abstractions and jargon, opting instead for a hands-on, ground-up, and simulation-focused approach to understanding how these concepts and skills work. By the end of this winter, you’ll not only gain confidence in your ability to analyze and interpret data but also build in-demand skills valued in careers across government, international organizations, think tanks, and the private sector. No prior experience in statistics or coding (and definitely no ancient Greek) is needed—just bring your curiosity!",
    "crumbs": [
      "Content",
      "Session 0",
      "Introduction"
    ]
  },
  {
    "objectID": "content/00-introduction.html#what-this-course-covers",
    "href": "content/00-introduction.html#what-this-course-covers",
    "title": "Introduction",
    "section": "What this course covers",
    "text": "What this course covers\nAfter successfully completing this course you will be able to:\n\nUse R to collect, clean, and analyze data\nDescribe important features of your outcomes of interest and the variables you think drive changes to those outcomes\nIdentify and evaluate the relationship between two variables using statistical models\nDescribe those relationships using clear and precise language\nCritically evaluate empirical claims made in political news and analysis.",
    "crumbs": [
      "Content",
      "Session 0",
      "Introduction"
    ]
  },
  {
    "objectID": "content/00-introduction.html#course-structure",
    "href": "content/00-introduction.html#course-structure",
    "title": "Introduction",
    "section": "Course structure",
    "text": "Course structure\nThe course comprises six substantive sessions, this introductory session, and a session to conclude. You should complete these in order: each builds on the previous sessions.\nEach session includes some written content and a series of short recorded lectures. Each ends with a mandatory multiple-choice quiz (taken through ELMs). You will be introduced to new R code and statistical concepts in each session.\nThree substantive sessions will be released each week. You should complete them within that week. The quizzes for all three sessions released that week will be due at 11:59PM on Friday nights.\nYou will also complete a final exam at the end of the course. All material covered in all eight sessions could be tested.\nQuiz and exam schedule\n\n\n\n\n\n\n\n\nWEEK\nASSIGNMENT\nRELEASE DATE\nDUE DATE\n\n\n\n1\n0: Introduction quiz\n2 January 2025\n10 January 2025, 11:59PM\n\n\n2\n\n1: Session 1 quiz\n2: Session 2 quiz\n3: Session 3 quiz\n\n6 January 2025\n10 January 2025, 11:59PM\n\n\n3\n\n4: Session 4 quiz\n5: Session 5 quiz\n6: Session 6 quiz\n\n13 January 2025\n17 January 2025, 11:59PM\n\n\n4\n7: Final exam\n18 January 2025\n22 January 2025, 11:59PM\n\n\n\nPlease note: weeks one and four are short.",
    "crumbs": [
      "Content",
      "Session 0",
      "Introduction"
    ]
  },
  {
    "objectID": "content/00-introduction.html#course-resources",
    "href": "content/00-introduction.html#course-resources",
    "title": "Introduction",
    "section": "Course resources",
    "text": "Course resources\nEach session includes several resources written just for you. These can all be accessed from this website. They include:\n\na series of recorded lectures\ncorresponding slides with embedded R code\nsome written content.\n\nThere are no additional required readings for this course. Along the way, I may suggest other resources - book chapters, blog posts, videos, etc. - that you might find helpful. Sometimes it helps to hear these concepts explained in a couple of different ways.\nAdditional required resources\nTo complete this course, you need access to a personal computer and a stable internet connection. You also need to have access to the latest versions of R and RStudio. Here are detailed instructions on how to download or update these two free resources:\n Instructions on downloading R\n Instructions on downloading RStudio\nEverything you need to successfully complete this course is available for free.",
    "crumbs": [
      "Content",
      "Session 0",
      "Introduction"
    ]
  },
  {
    "objectID": "content/00-introduction.html#introduction-to-r-and-rstudio",
    "href": "content/00-introduction.html#introduction-to-r-and-rstudio",
    "title": "Introduction",
    "section": "Introduction to R and RStudio",
    "text": "Introduction to R and RStudio\nI will now introduce you to two tools you will use to successfully complete this course: R and RStudio. R is a versatile programming language that excels in statistical analysis. It is widely used by academics and in the private, government, and international sectors. You will certainly get a lot of use out of it going forward!\nR is also a very flexible language. You can make all kinds of very cool things with R, including websites, apps, slides, and more. In fact, all the resources I produced for this course were made using R, including this website and fancy slides.\nAnother advantage R has over other statistical programming languages is its accessibility. It is entirely free to use. There are many resources out there that will introduce you to its many uses. There is also an enthusiastic and welcoming community of R users who continue to grow R itself and the various resources you might need to expand your skills.\nR and RStudio\nSo, what is the difference between R and RStudio? R is the statistical programming language. RStudio is the platform, or integrated development environment, you will use to work with R. RStudio is free and used widely by R users.\nThe R skills you will learn\nThis course aims to provide you with two broad skills: statistical analysis and R. I will now outline what you will learn in relation to R.\nYou will learn how to import your data into R. You will learn how to load data stored in an external file, database, or online into a data frame in R.\nYou will then be introduced to methods for cleaning up those data. Oftentimes, data comes to us in a messy format, with missingness, and inconsistencies. You will need to tidy it up into a format that is easy to work with and consistent.\nOnce you have tidy data, you will then need to transform it so that it is ready for your analysis. This includes focusing your data on the observations you are interested in and creating new variables.\nNext, we will focus on visualizing your data. You can learn a lot more about your data and relationships lurking within it from a plot than you can from looking at the raw numbers.\nWe will also spend a fair chunk of time learning how to model those relationships within our data. Alongside visualization, this is where R excels.\nFinally, I will also introduce you to tools for communicating your findings in an engaging and replicable way.",
    "crumbs": [
      "Content",
      "Session 0",
      "Introduction"
    ]
  },
  {
    "objectID": "content/00-introduction.html#a-tour-of-rstudio",
    "href": "content/00-introduction.html#a-tour-of-rstudio",
    "title": "Introduction",
    "section": "A tour of RStudio",
    "text": "A tour of RStudio\n\n\nExercises\nUsing the console, find the summation of 45, 978, and 121.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nsum(45, 978, 121)\n\n[1] 1144\n\n\nOr:\n\n45 + 978 + 121\n\n[1] 1144\n\n\n\n\n\nWhat is 67 divided by 6?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\n67 / 6\n\n[1] 11.16667\n\n\n\n\n\nWhat is the square root of 894? Hint: use the sqrt() function.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nsqrt(894)\n\n[1] 29.89983",
    "crumbs": [
      "Content",
      "Session 0",
      "Introduction"
    ]
  },
  {
    "objectID": "content/00-introduction.html#quiz",
    "href": "content/00-introduction.html#quiz",
    "title": "Introduction",
    "section": "Quiz",
    "text": "Quiz\nHead over to ELMs to complete this session’s mandatory multiple-choice quiz.",
    "crumbs": [
      "Content",
      "Session 0",
      "Introduction"
    ]
  },
  {
    "objectID": "content/slides/00-01-intro_to_r_rstudio.html#learning-objectives-for-today",
    "href": "content/slides/00-01-intro_to_r_rstudio.html#learning-objectives-for-today",
    "title": "Introduction to R and RStudio",
    "section": "Learning objectives for today",
    "text": "Learning objectives for today\n\nIntroduction to R\nIntroduction to RStudio"
  },
  {
    "objectID": "content/slides/00-01-intro_to_r_rstudio.html#why-r",
    "href": "content/slides/00-01-intro_to_r_rstudio.html#why-r",
    "title": "Introduction to R and RStudio",
    "section": "Why R?",
    "text": "Why R?\n\nA versatile programming language\n\nAll materials used in this course were produced using R, including the website and fancy slides\n\nFree and accessible!"
  },
  {
    "objectID": "content/slides/00-01-intro_to_r_rstudio.html#r-and-rstudio",
    "href": "content/slides/00-01-intro_to_r_rstudio.html#r-and-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\nR\nR is a free and open-source programming language and software environment for statistical computing and graphics.\n\nRStudio\nRStudio is an integrated development environment (IDE) for the R programming language.\n\n\n\nInstructions on how to download R and RStudio are provided in the Install or upgrade R and RStudio chapter in Jennifer Bryan’s Happy Git and GitHub for the useR."
  },
  {
    "objectID": "content/slides/00-01-intro_to_r_rstudio.html#the-r-skills-you-will-learn",
    "href": "content/slides/00-01-intro_to_r_rstudio.html#the-r-skills-you-will-learn",
    "title": "Introduction to R and RStudio",
    "section": "The R skills you will learn",
    "text": "The R skills you will learn\nThis course will introduce you to both statistics and R. Focusing on R, you will learn how to:\n\nImport your data into R\nTidy your data\nTransform it\nVisualize it\nModel patterns and relationships within it\nCommunicate your findings."
  },
  {
    "objectID": "content/slides/00-01-intro_to_r_rstudio.html#a-tour-of-rstudio",
    "href": "content/slides/00-01-intro_to_r_rstudio.html#a-tour-of-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "A Tour of RStudio",
    "text": "A Tour of RStudio\n\nSource: R4DS"
  },
  {
    "objectID": "content/slides/00-01-intro_to_r_rstudio.html#summary",
    "href": "content/slides/00-01-intro_to_r_rstudio.html#summary",
    "title": "Introduction to R and RStudio",
    "section": "Summary",
    "text": "Summary\nThis session you:\n\nLearnt about new data science tools to help you conduct replicable and reproducible political science research\nSet up your data science tools"
  },
  {
    "objectID": "content/02-01-transformation.html",
    "href": "content/02-01-transformation.html",
    "title": "Data Transformation",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(\"gapminder\")\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\nThis section focuses on introducing you to some new R skills. Data rarely come to us perfectly formatted and without annoying errors or inconsistencies. We can use R to clean our data up and get them ready for analysis.",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#set-up",
    "href": "content/02-01-transformation.html#set-up",
    "title": "Data Transformation",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(\"gapminder\")\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\nThis section focuses on introducing you to some new R skills. Data rarely come to us perfectly formatted and without annoying errors or inconsistencies. We can use R to clean our data up and get them ready for analysis.",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#gapminder",
    "href": "content/02-01-transformation.html#gapminder",
    "title": "Data Transformation",
    "section": "Gapminder",
    "text": "Gapminder\nThis session, we will explore the long-studied relationship between countries’ health and wealth. Attention was brought to this relationship by the Gapminder project. You can read more about their research here.\nBefore we get started, check out this video that describes (very enthusiastically) the relationship between health and wealth:",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#introduction",
    "href": "content/02-01-transformation.html#introduction",
    "title": "Data Transformation",
    "section": "Introduction",
    "text": "Introduction\nToday, I am going to introduce you to some of my most widely used functions in R. The dplyr R package, which houses these functions, focuses on providing you with some very helpful tools to tidy your data. This step in the data analysis process is critical, and often one of the most time consuming, so let’s get started!\nR objects\nAs a reminder, objects sit in R’s memory. You can see which ones exist in your current session and their values over in the environment tab.\nTo create a new object, use: &lt;-. You can update that object at any time.\n\n\n\n\n\n\nNote\n\n\n\nSome people use = instead of &lt;-. I strongly recommend against this. It makes your script difficult to read, and it can lead to syntax errors.\n\n\nR functions\nFunctions are helpful short-hands that perform specific tasks in R. Many of these functions come straight out of the box with R. For example, you can run the following code without loading any packages into your current session:\n\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe seq() function takes three main arguments: a start value, end value, and interval value. Above I have asked it to start at 1 and end at 10. By default, its interval value is 1. Therefore, its output is every whole number from 1 to 10.\n\n\nYou can even create objects with R functions:\n\nx &lt;- seq(1, 10)\n\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nNow, the x object is a vector of all 10 whole numbers from 1 to 10.\nData\nAs mentioned above, we are going to be using the Gapminder project’s data on countries’ health and wealth to explore data transformation. Happily, there is an R package that provides that data for us. We will now install it:\n\ninstall.packages(\"gapminder\")\n\nNext, you want to create a new script for this session. At the top of that script, include the code to load in the packages we will be using today:\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\nYou can now access the Gapminder data directly:\n\ngapminder\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nAbove, R prints out some useful information about our data. First, we learn that it is a tibble. This is the tidyverse version of a data frame.\nSecond, we learn how many rows and columns are included in our data set. We have 1,704 rows and 6 columns.\nNext, we learn the column (or variable) titles:\n\ncolnames(gapminder)\n\n[1] \"country\"   \"continent\" \"year\"      \"lifeExp\"   \"pop\"       \"gdpPercap\"\n\n\nNext, we see some funny looking three letter words under each column name. These refer to the column’s data type. We will discuss these below.\nFinally, we see the first few rows of our data set. We can see that each row provides a country’s information in a single year.\nData types\nThose funny three-letter words refer to the column’s data type. In this data set, we have three different types:\n\n&lt;fct&gt;, which stands for factor (R’s word for categorical variable)\n&lt;int&gt;, which stands for integer\n&lt;dbl&gt;, which stands for double (or real number)\n\nSome other common data types include:\n\n&lt;chr&gt;, which stands for character (or string)\n&lt;dttm&gt;, which stands for date-time\n&lt;lgl&gt;, which stands for local (which can only be TRUE or FALSE)\n\nData types are important because each column can only contain one data type. You cannot, for example, include a character in an integer column (imagine trying to run some calculation on that column: how would R treat the stray character value?).\n\ndplyr basics\nNow we know a little bit more about our data set, we are going to use it to explore five of the most commonly used functions in R:\n\nfilter()\narrange()\nselect()\nmutate()\nsummarise()\nExercises\nWhat is the unit of observation for the gapminder data set?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\nThe unit of observation is country-year.\n\n\n\nHow many country-years are included in the gapminder data set?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nnrow(gapminder)\n\n[1] 1704\n\n\n\n\n\nWhich two variables in the gapminder data set are factors?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\ncountry and continent are factors (or categorical variables).",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#filtering-your-data",
    "href": "content/02-01-transformation.html#filtering-your-data",
    "title": "Data Transformation",
    "section": "Filtering your data",
    "text": "Filtering your data\nWe are going to start by learning how to filter our data to only include those observations we are interested in exploring.\nAll dplyr functions are structured the same way. They take the data object you want to transform as their first argument. You then need to identify the columns within that data object you want to transform and what you want to do with them.\nFor example, the following code takes our data set, gapminder, and tells filter() that we want to only include rows in which the country column matches “Australia” and the year column is greater than 2000:\n\nfilter(gapminder, country == \"Australia\", year &gt; 2000)\n\n# A tibble: 2 × 6\n  country   continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Australia Oceania    2002    80.4 19546792    30688.\n2 Australia Oceania    2007    81.2 20434176    34435.\n\n\nWe can ask filter() to include rows that match multiple values:\n\nfilter(gapminder, continent %in% c(\"Asia\", \"Oceania\"))\n\n# A tibble: 420 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 410 more rows\n\n\nHere, I have used the %in% value and a vector (which is c(...)) of strings to ask filter to include all rows in which the continent column matches the values “Asia” and “Oceania”.\nWe can ask filter() to include values within a range. The following code asks filter() to include all rows in which the pop column is greater than 500,000 and less than 1,000,000:\n\nfilter(gapminder, pop &gt; 500000 & pop &lt; 1000000)\n\n# A tibble: 88 × 6\n   country  continent  year lifeExp    pop gdpPercap\n   &lt;fct&gt;    &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;     &lt;dbl&gt;\n 1 Bahrain  Asia       1992    72.6 529491    19036.\n 2 Bahrain  Asia       1997    73.9 598561    20292.\n 3 Bahrain  Asia       2002    74.8 656397    23404.\n 4 Bahrain  Asia       2007    75.6 708573    29796.\n 5 Botswana Africa     1962    51.5 512764      984.\n 6 Botswana Africa     1967    53.3 553541     1215.\n 7 Botswana Africa     1972    56.0 619351     2264.\n 8 Botswana Africa     1977    59.3 781472     3215.\n 9 Botswana Africa     1982    61.5 970347     4551.\n10 Comoros  Africa     1997    60.7 527982     1174.\n# ℹ 78 more rows\n\n\nThe following code asks filter() to include all rows in which the pop column is greater than 500,000 or less than 1,000,000.\n\nfilter(gapminder, pop &gt; 500000 | pop &lt; 1000000)\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nR includes some handy operators:\n\n== is equal to\n!= is not equal to\n&gt;= is greater than or equal to\n&lt;= is less than or equal to\n| is OR\n& is AND\n%in% is in\n\nExercises\nFind all country-years that have populations greater than 1 billion people.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nfilter(gapminder, pop &gt; 1e9)\n\n# A tibble: 8 × 6\n  country continent  year lifeExp        pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;      &lt;int&gt;     &lt;dbl&gt;\n1 China   Asia       1982    65.5 1000281000      962.\n2 China   Asia       1987    67.3 1084035000     1379.\n3 China   Asia       1992    68.7 1164970000     1656.\n4 China   Asia       1997    70.4 1230075000     2289.\n5 China   Asia       2002    72.0 1280400000     3119.\n6 China   Asia       2007    73.0 1318683096     4959.\n7 India   Asia       2002    62.9 1034172547     1747.\n8 India   Asia       2007    64.7 1110396331     2452.\n\n\nNote: 1e9 is scientific notation for 1 billion (which has nine zeros).\n\n\n\nFind all countries in Oceania.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nfilter(gapminder, continent == \"Oceania\")\n\n# A tibble: 24 × 6\n   country   continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Australia Oceania    1952    69.1  8691212    10040.\n 2 Australia Oceania    1957    70.3  9712569    10950.\n 3 Australia Oceania    1962    70.9 10794968    12217.\n 4 Australia Oceania    1967    71.1 11872264    14526.\n 5 Australia Oceania    1972    71.9 13177000    16789.\n 6 Australia Oceania    1977    73.5 14074100    18334.\n 7 Australia Oceania    1982    74.7 15184200    19477.\n 8 Australia Oceania    1987    76.3 16257249    21889.\n 9 Australia Oceania    1992    77.6 17481977    23425.\n10 Australia Oceania    1997    78.8 18565243    26998.\n# ℹ 14 more rows\n\n\n\n\n\nFind all countries in both Asia and Europe.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nfilter(gapminder, continent %in% c(\"Asia\", \"Europe\"))\n\n# A tibble: 756 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 746 more rows\n\n\n\n\n\nFind all country-years that have a life expectancy greater than 50 years and less than 60 years.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nfilter(gapminder, lifeExp &gt; 50 & lifeExp &lt; 60)\n\n# A tibble: 336 × 6\n   country    continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;      &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Albania    Europe     1952    55.2  1282697     1601.\n 2 Albania    Europe     1957    59.3  1476505     1942.\n 3 Algeria    Africa     1967    51.4 12760499     3247.\n 4 Algeria    Africa     1972    54.5 14760787     4183.\n 5 Algeria    Africa     1977    58.0 17152804     4910.\n 6 Bahrain    Asia       1952    50.9   120447     9867.\n 7 Bahrain    Asia       1957    53.8   138655    11636.\n 8 Bahrain    Asia       1962    56.9   171863    12753.\n 9 Bahrain    Asia       1967    59.9   202182    14805.\n10 Bangladesh Asia       1982    50.0 93074406      677.\n# ℹ 326 more rows\n\n\n\n\n\nFind all country-years that have a life expectancy less than 50 years or greater than 60 years.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nfilter(gapminder, lifeExp &lt; 50 | lifeExp &gt; 60)\n\n# A tibble: 1,368 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,358 more rows",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#sorting-your-data",
    "href": "content/02-01-transformation.html#sorting-your-data",
    "title": "Data Transformation",
    "section": "Sorting your data",
    "text": "Sorting your data\nWe can control the order of our data using arrange(). The following code sorts our data by country name (alphabetically) and year (in ascending numerical order):\n\narrange(gapminder, country, year)\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nTo sort in descending order, simply wrap your column name in the desc() function:\n\narrange(gapminder, country, desc(year))\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       2007    43.8 31889923      975.\n 2 Afghanistan Asia       2002    42.1 25268405      727.\n 3 Afghanistan Asia       1997    41.8 22227415      635.\n 4 Afghanistan Asia       1992    41.7 16317921      649.\n 5 Afghanistan Asia       1987    40.8 13867957      852.\n 6 Afghanistan Asia       1982    39.9 12881816      978.\n 7 Afghanistan Asia       1977    38.4 14880372      786.\n 8 Afghanistan Asia       1972    36.1 13079460      740.\n 9 Afghanistan Asia       1967    34.0 11537966      836.\n10 Afghanistan Asia       1962    32.0 10267083      853.\n# ℹ 1,694 more rows\n\n\nYou can combine arrange() and filter() using the slice_X() functions. For example, you can filter for the smallest value in a column using slice_min(). The following code filters for the smallest value in the lifeExp column:\n\nslice_min(gapminder, lifeExp)\n\n# A tibble: 1 × 6\n  country continent  year lifeExp     pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;     &lt;dbl&gt;\n1 Rwanda  Africa     1992    23.6 7290203      737.\n\n\nThe following code filters for the largest value in this column:\n\nslice_max(gapminder, lifeExp)\n\n# A tibble: 1 × 6\n  country continent  year lifeExp       pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;     &lt;int&gt;     &lt;dbl&gt;\n1 Japan   Asia       2007    82.6 127467972    31656.\n\n\nExercises\nWhich country-year has the lowest life expectancy?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\narrange(gapminder, lifeExp)\n\n# A tibble: 1,704 × 6\n   country      continent  year lifeExp     pop gdpPercap\n   &lt;fct&gt;        &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;     &lt;dbl&gt;\n 1 Rwanda       Africa     1992    23.6 7290203      737.\n 2 Afghanistan  Asia       1952    28.8 8425333      779.\n 3 Gambia       Africa     1952    30    284320      485.\n 4 Angola       Africa     1952    30.0 4232095     3521.\n 5 Sierra Leone Africa     1952    30.3 2143249      880.\n 6 Afghanistan  Asia       1957    30.3 9240934      821.\n 7 Cambodia     Asia       1977    31.2 6978607      525.\n 8 Mozambique   Africa     1952    31.3 6446316      469.\n 9 Sierra Leone Africa     1957    31.6 2295678     1004.\n10 Burkina Faso Africa     1952    32.0 4469979      543.\n# ℹ 1,694 more rows\n\n\nNote: check out slice_min() and slice_max() for more efficient ways of doing this.\n\n\n\nWhich country-year has the largest population?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\narrange(gapminder, desc(pop))\n\n# A tibble: 1,704 × 6\n   country continent  year lifeExp        pop gdpPercap\n   &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;      &lt;int&gt;     &lt;dbl&gt;\n 1 China   Asia       2007    73.0 1318683096     4959.\n 2 China   Asia       2002    72.0 1280400000     3119.\n 3 China   Asia       1997    70.4 1230075000     2289.\n 4 China   Asia       1992    68.7 1164970000     1656.\n 5 India   Asia       2007    64.7 1110396331     2452.\n 6 China   Asia       1987    67.3 1084035000     1379.\n 7 India   Asia       2002    62.9 1034172547     1747.\n 8 China   Asia       1982    65.5 1000281000      962.\n 9 India   Asia       1997    61.8  959000000     1459.\n10 China   Asia       1977    64.0  943455000      741.\n# ℹ 1,694 more rows\n\n\nNote: check out slice_min() and slice_max() for more efficient ways of doing this.",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#selecting-relevant-columns",
    "href": "content/02-01-transformation.html#selecting-relevant-columns",
    "title": "Data Transformation",
    "section": "Selecting relevant columns",
    "text": "Selecting relevant columns\nYou can focus your data set on only those variables you are interested in using select(). The following code selects only the country, year, and pop variables from our larger gapminder data set:\n\nselect(gapminder, country, year, pop)\n\n# A tibble: 1,704 × 3\n   country      year      pop\n   &lt;fct&gt;       &lt;int&gt;    &lt;int&gt;\n 1 Afghanistan  1952  8425333\n 2 Afghanistan  1957  9240934\n 3 Afghanistan  1962 10267083\n 4 Afghanistan  1967 11537966\n 5 Afghanistan  1972 13079460\n 6 Afghanistan  1977 14880372\n 7 Afghanistan  1982 12881816\n 8 Afghanistan  1987 13867957\n 9 Afghanistan  1992 16317921\n10 Afghanistan  1997 22227415\n# ℹ 1,694 more rows\n\n\ndplyr includes some operators that help keep your code clean when working with a lot of data. For example, you can use a colon (:) to select all columns between two columns:\n\nselect(gapminder, country:pop)\n\n# A tibble: 1,704 × 5\n   country     continent  year lifeExp      pop\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;\n 1 Afghanistan Asia       1952    28.8  8425333\n 2 Afghanistan Asia       1957    30.3  9240934\n 3 Afghanistan Asia       1962    32.0 10267083\n 4 Afghanistan Asia       1967    34.0 11537966\n 5 Afghanistan Asia       1972    36.1 13079460\n 6 Afghanistan Asia       1977    38.4 14880372\n 7 Afghanistan Asia       1982    39.9 12881816\n 8 Afghanistan Asia       1987    40.8 13867957\n 9 Afghanistan Asia       1992    41.7 16317921\n10 Afghanistan Asia       1997    41.8 22227415\n# ℹ 1,694 more rows\n\n\nYou can use a negative sign (-) to specify which columns you want to exclude:\n\nselect(gapminder, -(lifeExp:pop))\n\n# A tibble: 1,704 × 4\n   country     continent  year gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952      779.\n 2 Afghanistan Asia       1957      821.\n 3 Afghanistan Asia       1962      853.\n 4 Afghanistan Asia       1967      836.\n 5 Afghanistan Asia       1972      740.\n 6 Afghanistan Asia       1977      786.\n 7 Afghanistan Asia       1982      978.\n 8 Afghanistan Asia       1987      852.\n 9 Afghanistan Asia       1992      649.\n10 Afghanistan Asia       1997      635.\n# ℹ 1,694 more rows\n\n\nExercises\nSelect only the country, year, and lifeExp variables from gapminder.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nselect(gapminder, country, year, lifeExp)\n\n# A tibble: 1,704 × 3\n   country      year lifeExp\n   &lt;fct&gt;       &lt;int&gt;   &lt;dbl&gt;\n 1 Afghanistan  1952    28.8\n 2 Afghanistan  1957    30.3\n 3 Afghanistan  1962    32.0\n 4 Afghanistan  1967    34.0\n 5 Afghanistan  1972    36.1\n 6 Afghanistan  1977    38.4\n 7 Afghanistan  1982    39.9\n 8 Afghanistan  1987    40.8\n 9 Afghanistan  1992    41.7\n10 Afghanistan  1997    41.8\n# ℹ 1,694 more rows\n\n\n\n\n\nWhat does the any_of() function do? Why might it be helpful in conjunction with this vector?\n\nvars &lt;- c(\"country\", \"year\", \"lifeExp\", \"boop\")\n\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nselect(gapminder, any_of(vars))\n\n# A tibble: 1,704 × 3\n   country      year lifeExp\n   &lt;fct&gt;       &lt;int&gt;   &lt;dbl&gt;\n 1 Afghanistan  1952    28.8\n 2 Afghanistan  1957    30.3\n 3 Afghanistan  1962    32.0\n 4 Afghanistan  1967    34.0\n 5 Afghanistan  1972    36.1\n 6 Afghanistan  1977    38.4\n 7 Afghanistan  1982    39.9\n 8 Afghanistan  1987    40.8\n 9 Afghanistan  1992    41.7\n10 Afghanistan  1997    41.8\n# ℹ 1,694 more rows\n\n\n\n\n\nWhat does the following code produce?\n\nselect(gapminder, starts_with(\"c\"))\n\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nselect(gapminder, starts_with(\"c\"))\n\n# A tibble: 1,704 × 2\n   country     continent\n   &lt;fct&gt;       &lt;fct&gt;    \n 1 Afghanistan Asia     \n 2 Afghanistan Asia     \n 3 Afghanistan Asia     \n 4 Afghanistan Asia     \n 5 Afghanistan Asia     \n 6 Afghanistan Asia     \n 7 Afghanistan Asia     \n 8 Afghanistan Asia     \n 9 Afghanistan Asia     \n10 Afghanistan Asia     \n# ℹ 1,694 more rows",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#create-or-change-columns-of-data",
    "href": "content/02-01-transformation.html#create-or-change-columns-of-data",
    "title": "Data Transformation",
    "section": "Create or change columns of data",
    "text": "Create or change columns of data\nOftentimes, we need to create new columns from existing ones or change in a consistent way existing columns of data. You can use mutate() to do this. For example, the following code creates a new column, gdp, which is the product of gdpPercap and pop:\n\nmutate(gapminder, gdp = gdpPercap * pop)\n\n# A tibble: 1,704 × 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# ℹ 1,694 more rows\n\n\nThe following code transforms the existing column gdpPercap to its logged form:\n\nmutate(gapminder, gdpPercap = log(gdpPercap))\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      6.66\n 2 Afghanistan Asia       1957    30.3  9240934      6.71\n 3 Afghanistan Asia       1962    32.0 10267083      6.75\n 4 Afghanistan Asia       1967    34.0 11537966      6.73\n 5 Afghanistan Asia       1972    36.1 13079460      6.61\n 6 Afghanistan Asia       1977    38.4 14880372      6.67\n 7 Afghanistan Asia       1982    39.9 12881816      6.89\n 8 Afghanistan Asia       1987    40.8 13867957      6.75\n 9 Afghanistan Asia       1992    41.7 16317921      6.48\n10 Afghanistan Asia       1997    41.8 22227415      6.45\n# ℹ 1,694 more rows\n\n\nYou can combine select() and mutate() using the transmute() function:\n\ntransmute(gapminder, country, year, gdp = gdpPercap * pop)\n\n# A tibble: 1,704 × 3\n   country      year          gdp\n   &lt;fct&gt;       &lt;int&gt;        &lt;dbl&gt;\n 1 Afghanistan  1952  6567086330.\n 2 Afghanistan  1957  7585448670.\n 3 Afghanistan  1962  8758855797.\n 4 Afghanistan  1967  9648014150.\n 5 Afghanistan  1972  9678553274.\n 6 Afghanistan  1977 11697659231.\n 7 Afghanistan  1982 12598563401.\n 8 Afghanistan  1987 11820990309.\n 9 Afghanistan  1992 10595901589.\n10 Afghanistan  1997 14121995875.\n# ℹ 1,694 more rows\n\n\nExercises\nCreate a new variable that provides each country-year’s GDP (which you can get by multiplying its GDP with its population).\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nmutate(gapminder, gdp = gdpPercap * pop)\n\n# A tibble: 1,704 × 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# ℹ 1,694 more rows\n\n\n\n\n\nCreate a new data set that only includes information on each country-year’s name, year, and GDP.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\ntransmute(gapminder, country, year, gdp = gdpPercap * pop)\n\n# A tibble: 1,704 × 3\n   country      year          gdp\n   &lt;fct&gt;       &lt;int&gt;        &lt;dbl&gt;\n 1 Afghanistan  1952  6567086330.\n 2 Afghanistan  1957  7585448670.\n 3 Afghanistan  1962  8758855797.\n 4 Afghanistan  1967  9648014150.\n 5 Afghanistan  1972  9678553274.\n 6 Afghanistan  1977 11697659231.\n 7 Afghanistan  1982 12598563401.\n 8 Afghanistan  1987 11820990309.\n 9 Afghanistan  1992 10595901589.\n10 Afghanistan  1997 14121995875.\n# ℹ 1,694 more rows",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#summarize-your-data",
    "href": "content/02-01-transformation.html#summarize-your-data",
    "title": "Data Transformation",
    "section": "Summarize your data",
    "text": "Summarize your data\nFinally, you can summarize (or aggregate) your data. For example, we often want to find the average of our observations. The following code finds the average population and GDP per capita for all country-years in our data set:\n\nsummarise(\n  gapminder, avg_pop = mean(pop), avg_gdp_per_cap = mean(gdpPercap)\n)\n\n# A tibble: 1 × 2\n    avg_pop avg_gdp_per_cap\n      &lt;dbl&gt;           &lt;dbl&gt;\n1 29601212.           7215.\n\n\nNote that the output is now one row long.\nThe following finds both the average and mean of our country-years’ populations and GDPs per capita:\n\nsummarise(\n  gapminder, \n  avg_pop = mean(pop), \n  median_pop = median(pop), \n  avg_gdp_per_cap = mean(gdpPercap),\n  median_gdp_per_cap = median(gdpPercap)\n)\n\n# A tibble: 1 × 4\n    avg_pop median_pop avg_gdp_per_cap median_gdp_per_cap\n      &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;\n1 29601212.   7023596.           7215.              3532.\n\n\nSometimes, we want to summarize our data within meaningful groups. For example, we may want to find the average population and GDP per capita for each continent included in our data set. To do this, you need to use the group_by() function to group your data. You can then use the summarise() function to summarize it within those groups:\n\ngapminder_continent &lt;- group_by(gapminder, continent)\n\nsummarise(\n  gapminder_continent, \n  avg_pop = mean(pop), \n  avg_gdp_per_cap = mean(gdpPercap)\n)\n\n# A tibble: 5 × 3\n  continent   avg_pop avg_gdp_per_cap\n  &lt;fct&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 Africa     9916003.           2194.\n2 Americas  24504795.           7136.\n3 Asia      77038722.           7902.\n4 Europe    17169765.          14469.\n5 Oceania    8874672.          18622.\n\n\nExercises\nCalculate each country-year’s GDP.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nmutate(gapminder, gdp = pop * gdpPercap)\n\n# A tibble: 1,704 × 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# ℹ 1,694 more rows\n\n\n\n\n\nFind each country’s average GDP across all years in the gapminder data set.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\ngapminder_country &lt;- group_by(gapminder, country)\n\ngapminder_country_avg &lt;- summarise(\n  mutate(gapminder_country, gdp = pop * gdpPercap), avg_gdp = mean(gdp)\n)\n\ngapminder_country_avg\n\n# A tibble: 142 × 2\n   country           avg_gdp\n   &lt;fct&gt;               &lt;dbl&gt;\n 1 Afghanistan  12709647583.\n 2 Albania       9094669267.\n 3 Algeria      96735171261.\n 4 Angola       25532681843.\n 5 Argentina   266754123835.\n 6 Australia   320253755823.\n 7 Austria     158579002935.\n 8 Bahrain       7694793798.\n 9 Bangladesh   80648494456.\n10 Belgium     197371599665.\n# ℹ 132 more rows\n\n\n\n\n\nFind the country with the smallest average GDP across these years.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\narrange(gapminder_country_avg, avg_gdp)\n\n# A tibble: 142 × 2\n   country                   avg_gdp\n   &lt;fct&gt;                       &lt;dbl&gt;\n 1 Sao Tome and Principe  151723722.\n 2 Comoros                450509962.\n 3 Gambia                 551998132.\n 4 Guinea-Bissau          583673324.\n 5 Djibouti               647199614.\n 6 Liberia               1054141313.\n 7 Equatorial Guinea     1143738921.\n 8 Lesotho               1257957241.\n 9 Eritrea               1683400010.\n10 Burundi               2253225196.\n# ℹ 132 more rows\n\n\n\n\n\nFind the country with the largest average GDP across these years.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\narrange(gapminder_country_avg, desc(avg_gdp))\n\n# A tibble: 142 × 2\n   country        avg_gdp\n   &lt;fct&gt;            &lt;dbl&gt;\n 1 United States  6.40e12\n 2 Japan          2.12e12\n 3 China          1.70e12\n 4 Germany        1.62e12\n 5 United Kingdom 1.11e12\n 6 France         1.04e12\n 7 Italy          9.11e11\n 8 India          8.62e11\n 9 Brazil         8.11e11\n10 Mexico         5.95e11\n# ℹ 132 more rows",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/02-01-transformation.html#the-pipe",
    "href": "content/02-01-transformation.html#the-pipe",
    "title": "Data Transformation",
    "section": "The pipe",
    "text": "The pipe\nThat got messy! We had a lot of different objects representing intermediate steps in our calculations, but we never need those objects again. Can we avoid creating them?\nLet’s introduce perhaps the defining feature of the tidyverse: the pipe.\nRead the pipe (|&gt;) as:\nTake this |&gt; (and then…)\ndo this |&gt; (and then…)\ndo this\nFor example:\n\ngapminder |&gt; \n  group_by(continent) |&gt; \n  summarise(avg_pop = mean(pop), avg_gdp_per_cap = mean(gdpPercap)) |&gt;\n  arrange(avg_gdp_per_cap)\n\n# A tibble: 5 × 3\n  continent   avg_pop avg_gdp_per_cap\n  &lt;fct&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 Africa     9916003.           2194.\n2 Americas  24504795.           7136.\n3 Asia      77038722.           7902.\n4 Europe    17169765.          14469.\n5 Oceania    8874672.          18622.\n\n\nReads as:\n\nTake the gapminder data set, and then…\nGroup it by continent, and then…\nFind the average population and GDP per capita for each of those continents, and then…\nSort those summaries by their average GDPs per capita (in ascending order).\n\nYou can combine all tidyverse functions with the pipe:\n\ngapminder |&gt; \n  group_by(continent) |&gt; \n  summarise(avg_pop = mean(pop), avg_gdp_per_cap = mean(gdpPercap)) |&gt; \n  ggplot(aes(x = continent, y = avg_gdp_per_cap)) + \n  geom_col() + \n  theme_minimal()\n\n\n\n\n\n\n\nIt is worth noting that there are two versions of the pipe running around. The first |&gt; is the base pipe. This comes straight out of the box with R. You do not need to load in any packages to use it. The second, %&gt;%, is the tidyverse pipe. To use it, you need to load in either dplyr or the magrittr package.\nI have switched to using the base pipe, so that’s the one you will see in all of my code. You can use whichever you prefer!\nExercises\nUse the pipe to calculate the average GDP per capita for countries in the Americas in all years including or after 2000.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\ngapminder_americas_2000 &lt;- gapminder |&gt; \n  filter(continent == \"Americas\", year &gt; 2000) |&gt; \n  group_by(country) |&gt; \n  summarise(avg_gdp_per_cap = mean(gdpPercap))\n\ngapminder_americas_2000\n\n# A tibble: 25 × 2\n   country            avg_gdp_per_cap\n   &lt;fct&gt;                        &lt;dbl&gt;\n 1 Argentina                   10789.\n 2 Bolivia                      3618.\n 3 Brazil                       8599.\n 4 Canada                      34824.\n 5 Chile                       11975.\n 6 Colombia                     6381.\n 7 Costa Rica                   8684.\n 8 Cuba                         7644.\n 9 Dominican Republic           5295.\n10 Ecuador                      6323.\n# ℹ 15 more rows\n\n\n\n\n\nPlot your results.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nggplot(gapminder_americas_2000, aes(x = avg_gdp_per_cap, y = reorder(country, avg_gdp_per_cap))) + \n  geom_col() +\n  theme_minimal() + \n  labs(title = \"Average GDP per capita for countries in the Americas in 2002 and 2007\",\n       x = \"Average GDP per capita (US$)\",\n       y = NULL) + \n  scale_x_continuous(labels = scales::label_dollar())\n\n\n\n\n\n\n\nNote: Check out the scales R package for very handy formatting functions: https://scales.r-lib.org.",
    "crumbs": [
      "Content",
      "Session 2",
      "Data Transformation"
    ]
  },
  {
    "objectID": "content/slides/02-01-transformation_intro.html#learning-objectives",
    "href": "content/slides/02-01-transformation_intro.html#learning-objectives",
    "title": "Data Transformation",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nLearn basic operations in R\nBe introduced to dplyr\nClean up and transform your data"
  },
  {
    "objectID": "content/slides/02-01-transformation_intro.html#r-objects",
    "href": "content/slides/02-01-transformation_intro.html#r-objects",
    "title": "Data Transformation",
    "section": "R objects",
    "text": "R objects\nCreate new objects with &lt;-\n\nx &lt;- 3 * 4\n\nx\n\n[1] 12\n\n\n\n\nx &lt;- 3 * 10\n\nx\n\n[1] 30\n\n\n\n\nSome people use = instead of &lt;-. I strongly recommend against this. It makes your script difficult to read, and it can lead to syntax errors."
  },
  {
    "objectID": "content/slides/02-01-transformation_intro.html#r-functions",
    "href": "content/slides/02-01-transformation_intro.html#r-functions",
    "title": "Data Transformation",
    "section": "R functions",
    "text": "R functions\nMany functions come with R straight out of the box:\n\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nYou can create objects using functions:\n\nx &lt;- seq(1, 10)\n\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "content/slides/02-01-transformation_intro.html#gapminder",
    "href": "content/slides/02-01-transformation_intro.html#gapminder",
    "title": "Data Transformation",
    "section": "Gapminder",
    "text": "Gapminder\nFirst, you need to install the gapminder package:\n\ninstall.packages(\"gapminder\")\n\nThen access the gapminder data set:\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\nhead(gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786."
  },
  {
    "objectID": "content/slides/02-01-transformation_intro.html#data-types",
    "href": "content/slides/02-01-transformation_intro.html#data-types",
    "title": "Data Transformation",
    "section": "Data types",
    "text": "Data types\nIn gapminder:\n\nfctr stands for factors, which R uses to represent categorical variables with fixed possible values.\nint stands for integer.\ndbl stands for doubles (or real numbers)."
  },
  {
    "objectID": "content/slides/02-01-transformation_intro.html#data-types-1",
    "href": "content/slides/02-01-transformation_intro.html#data-types-1",
    "title": "Data Transformation",
    "section": "Data types",
    "text": "Data types\nOther types:\n\nchr stands for character vectors, or strings.\ndttm stands for date-times (a date + a time).\nlgl stands for logical, vectors that contain only TRUE or FALSE.1\n\nTRUE can be shortened to T and FALSE can be shortened to F."
  },
  {
    "objectID": "content/slides/02-01-transformation_intro.html#introducing-dplyr",
    "href": "content/slides/02-01-transformation_intro.html#introducing-dplyr",
    "title": "Data Transformation",
    "section": "Introducing dplyr",
    "text": "Introducing dplyr\nHelp you with most of your data transformation needs.\nFive basic functions:\n\nfilter()\narrange()\nselect()\nmutate()\nsummarise()"
  },
  {
    "objectID": "content/slides/02-02-filter.html#dplyr-basics",
    "href": "content/slides/02-02-filter.html#dplyr-basics",
    "title": "Filtering Your Data",
    "section": "dplyr basics",
    "text": "dplyr basics\n\nFirst argument is always a data object (for example, a dataframe).\nSubsequent arguments typically describe which columns to operate on, using the variable names (without quotes).\nOutput is always a new data object."
  },
  {
    "objectID": "content/slides/02-02-filter.html#filter-rows-with-filter",
    "href": "content/slides/02-02-filter.html#filter-rows-with-filter",
    "title": "Filtering Your Data",
    "section": "Filter rows with filter()",
    "text": "Filter rows with filter()\n\nfilter(gapminder, country == \"Australia\", year &gt; 2000)\n\n# A tibble: 2 × 6\n  country   continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Australia Oceania    2002    80.4 19546792    30688.\n2 Australia Oceania    2007    81.2 20434176    34435."
  },
  {
    "objectID": "content/slides/02-02-filter.html#filter-rows-with-filter-1",
    "href": "content/slides/02-02-filter.html#filter-rows-with-filter-1",
    "title": "Filtering Your Data",
    "section": "Filter rows with filter()",
    "text": "Filter rows with filter()\n\nfilter(gapminder, continent %in% c(\"Asia\", \"Oceania\"))\n\n# A tibble: 420 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 410 more rows"
  },
  {
    "objectID": "content/slides/02-02-filter.html#filter-rows-with-filter-2",
    "href": "content/slides/02-02-filter.html#filter-rows-with-filter-2",
    "title": "Filtering Your Data",
    "section": "Filter rows with filter()",
    "text": "Filter rows with filter()\n\nfilter(gapminder, pop &gt; 500000 & pop &lt; 1000000)\n\n# A tibble: 88 × 6\n   country  continent  year lifeExp    pop gdpPercap\n   &lt;fct&gt;    &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;     &lt;dbl&gt;\n 1 Bahrain  Asia       1992    72.6 529491    19036.\n 2 Bahrain  Asia       1997    73.9 598561    20292.\n 3 Bahrain  Asia       2002    74.8 656397    23404.\n 4 Bahrain  Asia       2007    75.6 708573    29796.\n 5 Botswana Africa     1962    51.5 512764      984.\n 6 Botswana Africa     1967    53.3 553541     1215.\n 7 Botswana Africa     1972    56.0 619351     2264.\n 8 Botswana Africa     1977    59.3 781472     3215.\n 9 Botswana Africa     1982    61.5 970347     4551.\n10 Comoros  Africa     1997    60.7 527982     1174.\n# ℹ 78 more rows"
  },
  {
    "objectID": "content/slides/02-02-filter.html#filter-rows-with-filter-3",
    "href": "content/slides/02-02-filter.html#filter-rows-with-filter-3",
    "title": "Filtering Your Data",
    "section": "Filter rows with filter()",
    "text": "Filter rows with filter()\n\nfilter(gapminder, pop &gt; 500000 | pop &lt; 1000000)\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-02-filter.html#handy-operations",
    "href": "content/slides/02-02-filter.html#handy-operations",
    "title": "Filtering Your Data",
    "section": "Handy operations",
    "text": "Handy operations\n== is equal to\n\n!= is not equal to\n\n&gt;= is greater than or equal to\n\n&lt;= is less than or equal to"
  },
  {
    "objectID": "content/slides/02-02-filter.html#handy-operations-1",
    "href": "content/slides/02-02-filter.html#handy-operations-1",
    "title": "Filtering Your Data",
    "section": "Handy operations",
    "text": "Handy operations\n\n| is OR\n\n& is AND\n\n%in% is in"
  },
  {
    "objectID": "content/slides/02-03-arrange.html#arrange-rows-with-arrange",
    "href": "content/slides/02-03-arrange.html#arrange-rows-with-arrange",
    "title": "Sorting Your Data",
    "section": "Arrange rows with arrange()",
    "text": "Arrange rows with arrange()\n\narrange(gapminder, country, year)\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-03-arrange.html#arrange-rows-with-arrange-1",
    "href": "content/slides/02-03-arrange.html#arrange-rows-with-arrange-1",
    "title": "Sorting Your Data",
    "section": "Arrange rows with arrange()",
    "text": "Arrange rows with arrange()\n\narrange(gapminder, country, desc(year))\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       2007    43.8 31889923      975.\n 2 Afghanistan Asia       2002    42.1 25268405      727.\n 3 Afghanistan Asia       1997    41.8 22227415      635.\n 4 Afghanistan Asia       1992    41.7 16317921      649.\n 5 Afghanistan Asia       1987    40.8 13867957      852.\n 6 Afghanistan Asia       1982    39.9 12881816      978.\n 7 Afghanistan Asia       1977    38.4 14880372      786.\n 8 Afghanistan Asia       1972    36.1 13079460      740.\n 9 Afghanistan Asia       1967    34.0 11537966      836.\n10 Afghanistan Asia       1962    32.0 10267083      853.\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-03-arrange.html#get-the-smallest-or-largest-value-in-one-line-of-code",
    "href": "content/slides/02-03-arrange.html#get-the-smallest-or-largest-value-in-one-line-of-code",
    "title": "Sorting Your Data",
    "section": "Get the smallest or largest value in one line of code",
    "text": "Get the smallest or largest value in one line of code\n\nslice_min(gapminder, lifeExp)\n\n# A tibble: 1 × 6\n  country continent  year lifeExp     pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;     &lt;dbl&gt;\n1 Rwanda  Africa     1992    23.6 7290203      737.\n\n\n\n\nslice_max(gapminder, lifeExp)\n\n# A tibble: 1 × 6\n  country continent  year lifeExp       pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;     &lt;int&gt;     &lt;dbl&gt;\n1 Japan   Asia       2007    82.6 127467972    31656."
  },
  {
    "objectID": "content/slides/02-04-select.html#select-columns-with-select",
    "href": "content/slides/02-04-select.html#select-columns-with-select",
    "title": "Selecting Relevant Columns",
    "section": "Select columns with select()",
    "text": "Select columns with select()\n\nselect(gapminder, country, year, pop)\n\n# A tibble: 1,704 × 3\n   country      year      pop\n   &lt;fct&gt;       &lt;int&gt;    &lt;int&gt;\n 1 Afghanistan  1952  8425333\n 2 Afghanistan  1957  9240934\n 3 Afghanistan  1962 10267083\n 4 Afghanistan  1967 11537966\n 5 Afghanistan  1972 13079460\n 6 Afghanistan  1977 14880372\n 7 Afghanistan  1982 12881816\n 8 Afghanistan  1987 13867957\n 9 Afghanistan  1992 16317921\n10 Afghanistan  1997 22227415\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-04-select.html#select-columns-with-select-1",
    "href": "content/slides/02-04-select.html#select-columns-with-select-1",
    "title": "Selecting Relevant Columns",
    "section": "Select columns with select()",
    "text": "Select columns with select()\n\nselect(gapminder, country:pop)\n\n# A tibble: 1,704 × 5\n   country     continent  year lifeExp      pop\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;\n 1 Afghanistan Asia       1952    28.8  8425333\n 2 Afghanistan Asia       1957    30.3  9240934\n 3 Afghanistan Asia       1962    32.0 10267083\n 4 Afghanistan Asia       1967    34.0 11537966\n 5 Afghanistan Asia       1972    36.1 13079460\n 6 Afghanistan Asia       1977    38.4 14880372\n 7 Afghanistan Asia       1982    39.9 12881816\n 8 Afghanistan Asia       1987    40.8 13867957\n 9 Afghanistan Asia       1992    41.7 16317921\n10 Afghanistan Asia       1997    41.8 22227415\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-04-select.html#select-columns-with-select-2",
    "href": "content/slides/02-04-select.html#select-columns-with-select-2",
    "title": "Selecting Relevant Columns",
    "section": "Select columns with select()",
    "text": "Select columns with select()\n\nselect(gapminder, -(lifeExp:pop))\n\n# A tibble: 1,704 × 4\n   country     continent  year gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952      779.\n 2 Afghanistan Asia       1957      821.\n 3 Afghanistan Asia       1962      853.\n 4 Afghanistan Asia       1967      836.\n 5 Afghanistan Asia       1972      740.\n 6 Afghanistan Asia       1977      786.\n 7 Afghanistan Asia       1982      978.\n 8 Afghanistan Asia       1987      852.\n 9 Afghanistan Asia       1992      649.\n10 Afghanistan Asia       1997      635.\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-05-mutate.html#add-new-variables-with-mutate",
    "href": "content/slides/02-05-mutate.html#add-new-variables-with-mutate",
    "title": "Creating or changing columns of data",
    "section": "Add new variables with mutate()",
    "text": "Add new variables with mutate()\n\nmutate(gapminder, gdp = gdpPercap * pop)\n\n# A tibble: 1,704 × 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-05-mutate.html#change-existing-columns",
    "href": "content/slides/02-05-mutate.html#change-existing-columns",
    "title": "Creating or changing columns of data",
    "section": "Change existing columns",
    "text": "Change existing columns\n\nmutate(gapminder, gdpPercap = log(gdpPercap))\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      6.66\n 2 Afghanistan Asia       1957    30.3  9240934      6.71\n 3 Afghanistan Asia       1962    32.0 10267083      6.75\n 4 Afghanistan Asia       1967    34.0 11537966      6.73\n 5 Afghanistan Asia       1972    36.1 13079460      6.61\n 6 Afghanistan Asia       1977    38.4 14880372      6.67\n 7 Afghanistan Asia       1982    39.9 12881816      6.89\n 8 Afghanistan Asia       1987    40.8 13867957      6.75\n 9 Afghanistan Asia       1992    41.7 16317921      6.48\n10 Afghanistan Asia       1997    41.8 22227415      6.45\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-05-mutate.html#select-transform-and-add-new-variables-with-transmute",
    "href": "content/slides/02-05-mutate.html#select-transform-and-add-new-variables-with-transmute",
    "title": "Creating or changing columns of data",
    "section": "Select, transform, and add new variables with transmute()",
    "text": "Select, transform, and add new variables with transmute()\n\ntransmute(gapminder, country, year, gdp = gdpPercap * pop)\n\n# A tibble: 1,704 × 3\n   country      year          gdp\n   &lt;fct&gt;       &lt;int&gt;        &lt;dbl&gt;\n 1 Afghanistan  1952  6567086330.\n 2 Afghanistan  1957  7585448670.\n 3 Afghanistan  1962  8758855797.\n 4 Afghanistan  1967  9648014150.\n 5 Afghanistan  1972  9678553274.\n 6 Afghanistan  1977 11697659231.\n 7 Afghanistan  1982 12598563401.\n 8 Afghanistan  1987 11820990309.\n 9 Afghanistan  1992 10595901589.\n10 Afghanistan  1997 14121995875.\n# ℹ 1,694 more rows"
  },
  {
    "objectID": "content/slides/02-06-summarise.html#create-summaries-with-summarise",
    "href": "content/slides/02-06-summarise.html#create-summaries-with-summarise",
    "title": "Summarising your data",
    "section": "Create summaries with summarise()",
    "text": "Create summaries with summarise()\n\nsummarise(\n  gapminder, avg_pop = mean(pop), avg_gdp_per_cap = mean(gdpPercap)\n)\n\n# A tibble: 1 × 2\n    avg_pop avg_gdp_per_cap\n      &lt;dbl&gt;           &lt;dbl&gt;\n1 29601212.           7215."
  },
  {
    "objectID": "content/slides/02-06-summarise.html#create-summaries-with-summarise-1",
    "href": "content/slides/02-06-summarise.html#create-summaries-with-summarise-1",
    "title": "Summarising your data",
    "section": "Create summaries with summarise()",
    "text": "Create summaries with summarise()\n\nsummarise(\n  gapminder, \n  avg_pop = mean(pop), \n  median_pop = median(pop), \n  avg_gdp_per_cap = mean(gdpPercap),\n  median_gdp_per_cap = median(gdpPercap)\n)\n\n# A tibble: 1 × 4\n    avg_pop median_pop avg_gdp_per_cap median_gdp_per_cap\n      &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;              &lt;dbl&gt;\n1 29601212.   7023596.           7215.              3532."
  },
  {
    "objectID": "content/slides/02-06-summarise.html#creating-grouped-summaries-with-group_by-and-summarise",
    "href": "content/slides/02-06-summarise.html#creating-grouped-summaries-with-group_by-and-summarise",
    "title": "Summarising your data",
    "section": "Creating grouped summaries with group_by() and summarise()",
    "text": "Creating grouped summaries with group_by() and summarise()\n\ngapminder_continent &lt;- group_by(gapminder, continent)\n\nsummarise(\n  gapminder_continent, \n  avg_pop = mean(pop), \n  avg_gdp_per_cap = mean(gdpPercap)\n)\n\n# A tibble: 5 × 3\n  continent   avg_pop avg_gdp_per_cap\n  &lt;fct&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 Africa     9916003.           2194.\n2 Americas  24504795.           7136.\n3 Asia      77038722.           7902.\n4 Europe    17169765.          14469.\n5 Oceania    8874672.          18622."
  },
  {
    "objectID": "content/slides/02-07-pipe.html#combine-multiple-operations-with-the-pipe",
    "href": "content/slides/02-07-pipe.html#combine-multiple-operations-with-the-pipe",
    "title": "The pipe",
    "section": "Combine multiple operations with the pipe",
    "text": "Combine multiple operations with the pipe\nThat got messy!\n\nWe had a lot of different objects representing intermediate steps in our calculations.\nWe never need those objects again. Can we avoid creating them?\n\nLet’s introduce perhaps the defining feature of the tidyverse: the pipe."
  },
  {
    "objectID": "content/slides/02-07-pipe.html#combine-multiple-operations-with-the-pipe-1",
    "href": "content/slides/02-07-pipe.html#combine-multiple-operations-with-the-pipe-1",
    "title": "The pipe",
    "section": "Combine multiple operations with the pipe",
    "text": "Combine multiple operations with the pipe\nRead the pipe as:\nTake this |&gt; (and then…)      do this |&gt; (and then…)      do this\n\ngapminder |&gt; \n  group_by(continent) |&gt; \n  summarise(avg_pop = mean(pop), avg_gdp_per_cap = mean(gdpPercap)) |&gt; \n  arrange(avg_gdp_per_cap)\n\n# A tibble: 5 × 3\n  continent   avg_pop avg_gdp_per_cap\n  &lt;fct&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n1 Africa     9916003.           2194.\n2 Americas  24504795.           7136.\n3 Asia      77038722.           7902.\n4 Europe    17169765.          14469.\n5 Oceania    8874672.          18622."
  },
  {
    "objectID": "content/slides/02-07-pipe.html#combine-multiple-operations-with-the-pipe-2",
    "href": "content/slides/02-07-pipe.html#combine-multiple-operations-with-the-pipe-2",
    "title": "The pipe",
    "section": "Combine multiple operations with the pipe",
    "text": "Combine multiple operations with the pipe\n\ngapminder |&gt; \n  group_by(continent) |&gt; \n  summarise(avg_pop = mean(pop), avg_gdp_per_cap = mean(gdpPercap)) |&gt; \n  ggplot(aes(x = continent, y = avg_gdp_per_cap)) + \n  geom_col() + \n  theme_minimal()"
  },
  {
    "objectID": "content/slides/02-07-pipe.html#a-note-on-the-pipe",
    "href": "content/slides/02-07-pipe.html#a-note-on-the-pipe",
    "title": "The pipe",
    "section": "A note on the pipe",
    "text": "A note on the pipe\n\n\nBase pipe:\n\n|&gt;\nCan be used without loading any packages\nRelatively new: introduced in 2021\n\n\nTidyverse pipe:\n\n%&gt;%\nMust load dplyr or magrittr to use"
  },
  {
    "objectID": "content/slides/02-07-pipe.html#summary",
    "href": "content/slides/02-07-pipe.html#summary",
    "title": "The pipe",
    "section": "Summary",
    "text": "Summary\nThis session you have:\n\nLearnt R basic syntax\nLearnt how to transform your data\nWritten concise code that is easy to follow"
  },
  {
    "objectID": "content/04-02-linear_regression.html",
    "href": "content/04-02-linear_regression.html",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "",
    "text": "Generally, we - political scientists - want to understand what factors shape important political outcomes. We can use empirical research to help build and bolster this understanding. Many of the questions we ask cannot be answered using experiments. We are left, instead, to look back at the history of our outcome of interest (for example, global conflicts, democratic backsliding, elections), and attempt to tease out the role various factors played in shaping those outcomes. This section focuses on developing your ability to do this."
  },
  {
    "objectID": "content/04-02-linear_regression.html#set-up",
    "href": "content/04-02-linear_regression.html#set-up",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "Set up",
    "text": "Set up\nTo complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"marginaleffects\", \"janitor\", \"ggdist\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(modelsummary)\nlibrary(marginaleffects)\nlibrary(janitor)\nlibrary(ggdist)\nlibrary(polisciols)"
  },
  {
    "objectID": "content/04-02-linear_regression.html#introduction",
    "href": "content/04-02-linear_regression.html#introduction",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "Introduction",
    "text": "Introduction\nSpecifically, this section develops your ability to estimate average treatment effects using observational data."
  },
  {
    "objectID": "content/04-02-linear_regression.html#the-economic-benefits-of-justice",
    "href": "content/04-02-linear_regression.html#the-economic-benefits-of-justice",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "The economic benefits of justice",
    "text": "The economic benefits of justice\nAppel and Loyle (2012) (two wonderful UMD alumni) explore the determinants of foreign direct investment (FDI) flows into and out of post-conflict states. States that are emerging from civil war often have an acute need for foreign and stable sources of capital. However, multinational corporations and other foreign commercial actors are likely to view post-conflict states as high risk countries in which to invest: the risk of a return to violence and instability is often high in the immediate aftermath of a civil war. Understanding this, leaders of post-conflict states often attempt to decrease this perceived risk.\nAppel and Loyle argue that leaders can successfully do this by establishing post-conflict justice (PCJ) institutions. These institutions impose both domestic and reputational costs on post-conflict leaders. These costs allow leaders to signal their commitment to minimizing the risk of a return to violence and instability to foreign commercial actors. This is a great paper and I highly encourage you to take a look at their argument in detail.\nTheir argument focuses on leaders’ attempts to change foreign commercial actors’ perceptions of the risk of a return to violence. We cannot directly observe these commercial actors’ perceptions. However, we can observe the outcome of these perceptions: investment. If Appel and Loyle’s argument is correct, we should observe higher levels of FDI investment coming into post-conflict states that establish PCJ institutions compared to those that do not, on average and holding all else constant.\nAppel and Loyle find strong evidence of this. We will replicate and modify this empirical work. In doing so, we will become more familiar with the underlying mechanics of multiple linear regression and strengthen our ability to interpret these models.\nLet’s get started!"
  },
  {
    "objectID": "content/04-02-linear_regression.html#net-fdi-inflows-to-post-conflict-states",
    "href": "content/04-02-linear_regression.html#net-fdi-inflows-to-post-conflict-states",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "Net FDI inflows to post-conflict states",
    "text": "Net FDI inflows to post-conflict states\nAppel and Loyle provide us with data on 95 different post-conflict states. These include all states that had internal armed conflicts, including internationalized conflicts, that resulted in at least 25 battle-related deaths and were settled between 1970 and 2001.\nWe can access these data through polisciols::ebj:\n\nhead(ebj)\n\n   id ccode      country_name              pcj net_fdi_inflows gdp_per_capita\n1  71    41             Haiti  No institutions         -9.8000       1182.498\n2  71    41             Haiti  No institutions          6.6000       1088.680\n3 154    52 Trinidad & Tobago  No institutions        510.1589       7742.736\n4 102    70            Mexico  No institutions       -340.6904       6894.704\n5 102    70            Mexico  No institutions       6460.7998       7780.053\n6  67    90         Guatemala PCJ institutions        431.3800       3061.873\n           gdp gdp_per_capita_growth ex_rate_fluc cap_account_openness labor\n1   8407079981            -2.1324685     0.000000           -0.7681904  68.5\n2   8055393763           -14.8832922     1.776603           -0.0871520  67.9\n3   9542938026             1.9370972     0.000000           -1.1305820  55.2\n4 628418000000            -7.8634830     1.978028            1.1804080  59.8\n5 730752000000             5.2345648     1.129686            1.1804080  61.3\n6  31339424077             0.6277104     1.046489            1.2642760  63.1\n  f_life_exp polity2 pol_constraints conflict_duration     damage\n1   55.02233       7            0.00                 1   0.000000\n2   56.09750      -7            0.00                 1  12.855902\n3   72.61483       9            0.84                 1  -2.787351\n4   74.67104       4            0.39                 1   0.000000\n5   75.23493       6            0.39                 1  -8.949999\n6   67.46067       8            0.43                31 -43.714600\n  peace_agreement    victory      cold_war\n1    No agreement    Victory Post-Cold War\n2    No agreement    Victory Post-Cold War\n3    No agreement    Victory Post-Cold War\n4 Peace agreement No victory Post-Cold War\n5    No agreement No victory Post-Cold War\n6 Peace agreement No victory Post-Cold War\n\n\nThey focus on the 10-year period immediately following the conflict’s conclusion. This is the period in which we would expect foreign commercial actors to perceive the risk of a return to violence and instability to be greatest and, therefore, the period in which leaders’ attempts to quash these perceptions to be most relevant.\nTherefore, each row in this data set represents a single post-conflict state. The data is generally a summary of the 10-years post-conflict. For example net_fdi_inflows provides us with the total net FDI inflows each post-conflict state received in that 10-year period.\n\n\n\n\n\n\nTip\n\n\n\nYou can learn more about each variable using the following command:\n\n?ebj\n\n\n\nTheir outcome of interest is net FDI inflows. Remember, if their argument is correct we would expect post-conflict states that have established a PCJ institution to have higher net FDI inflows than than states that did not. Let’s take a look at those net inflows:\n\nsummary(ebj$net_fdi_inflows)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-1858.914    -0.572    38.290   759.146   408.250 24836.787 \n\n\n\nggplot(ebj, aes(x = net_fdi_inflows)) + \n  geom_histogram() + \n  theme_minimal() + \n  scale_x_continuous(labels = scales::dollar)\n\n\n\n\n\n\n\nThere appears to be a clear outlier: a net FDI inflow of $24,836.79 million for Russia. You can see that this is pulling up the average net FDI inflows well above the median inflow across our group of post-conflict states. We will keep this in because this is not the focus of this session, but I would encourage you to explore whether these findings are sensitive to its inclusion.\nWe learn from this that some states have greater FDI outflows than inflows (resulting in negative net FDI inflows). Indonesia had the greatest negative inflow, with net inflows of -$1,858.91 million.\nOther states received greater foreign investments than they invested elsewhere, resulting in positive net FDI inflows. In fact, on average, post-conflict states received more inflows than outflows."
  },
  {
    "objectID": "content/04-02-linear_regression.html#pcj-institutions",
    "href": "content/04-02-linear_regression.html#pcj-institutions",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "PCJ institutions",
    "text": "PCJ institutions\nAppel and Loyle focus on whether states that have PCJ institutions successfully attract greater net FDI inflows than those that do not. Therefore, their main explanatory variable is the existance of PCJ institutions.\nThis variable, pcj, indicates whether the the state established a PCJ institution within five years following the end of the conflict. What proportion of states did this?\n\ntabyl(ebj, pcj)\n\n              pcj  n   percent\n  No institutions 77 0.8105263\n PCJ institutions 18 0.1894737\n\n\nThe majority of post-conflict states did not have PCJ institutions."
  },
  {
    "objectID": "content/04-02-linear_regression.html#relationship-between-pcj-institutions-and-net-fdi-inflows",
    "href": "content/04-02-linear_regression.html#relationship-between-pcj-institutions-and-net-fdi-inflows",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "Relationship between PCJ institutions and net FDI inflows",
    "text": "Relationship between PCJ institutions and net FDI inflows\nOf the states that do have a PCJ institution, do they tend to receive higher net FDI inflows than their less reconciliatory counterparts?\n\nebj |&gt; \n  group_by(pcj) |&gt; \n  summarise(avg_net_fdi = mean(net_fdi_inflows))\n\n# A tibble: 2 × 2\n  pcj              avg_net_fdi\n  &lt;fct&gt;                  &lt;dbl&gt;\n1 No institutions         425.\n2 PCJ institutions       2189.\n\n\nYes! States that established a PCJ institution received higher net FDI inflows, on average, than those states that did not. This difference looks large! It’s $1,763.52 million in net inflows!\nBut what are the chances this difference is simply the product of chance? We can formally test this question using linear regression:\n\nm &lt;- lm(net_fdi_inflows ~ pcj, data = ebj)\n\nmodelsummary(m, \n             coef_rename = c(\"pcjPCJ institutions\" = \"PCJ institutions established\"),\n             stars = T)\n\n\n\n    \n\n      \n\n \n                (1)\n              \n+ p \n\n\n(Intercept)                 \n                  425.006  \n                \n\n                            \n                  (323.874)\n                \n\nPCJ institutions established\n                  1763.517*\n                \n\n                            \n                  (744.049)\n                \n\nNum.Obs.                    \n                  95       \n                \n\nR2                          \n                  0.057    \n                \n\nR2 Adj.                     \n                  0.047    \n                \n\nAIC                         \n                  1784.5   \n                \n\nBIC                         \n                  1792.2   \n                \n\nLog.Lik.                    \n                  -889.253 \n                \n\nRMSE                        \n                  2811.91  \n                \n\n\n\n\n\n\nAccording to this model, what is the average predicted net FDI inflows for countries that did not establish PCJ institution?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPost-conflict states that did not establish a PCJ institution received, on average, net FDI inflows of $425.01 million in the 10-year period after conflict.\nTo get this, I looked at the intercept coefficient which tells us the average predicted value of our outcome variable when all explanatory variables are equal to zero or their baseline category.\n\n\n\nAccording to this model, what is the average predicted net FDI inflows for countries that did establish PCJ institution?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn contrast, states that did establish PCJ institution received, on average, net FDI inflows of $2,188.52 million.\nIn other words:\n\\[\nAverage\\ net\\ FDI\\ inflows = \\beta_0 + \\beta_1 Institution\\ established + \\epsilon\n\\]\nWhen an institution was established (i.e. \\(Institution\\ established = 1\\)):\n\\[\nAverage\\ net\\ FDI\\ inflows = 425.01 + 1763.52 * 1 + \\epsilon \\\\\n\\]\n\\[\nAverage\\ net\\ FDI\\ inflows = 2188.52\n\\]\n\n\n\nSubstantive significance\nThis finding is substantively significant. These countries are recovering from conflict: their economies are really weak. Leaders are often very keen to find stable and reliable sources of funding to promote and strengthen their battered economies. This average difference of $1,763.52 million is; therefore, likely to incentivize this policy.\nFurther, if we look at the range of plausible values of the coefficient on the existence of a PCJ institution (i.e. the confidence interval) we can see states that did not establish a commission plausibly receive no net FDI inflows in this post-conflict period. In fact, it is plausible that investment leaves their economies: this net inflow can be negative. On the other hand, states that do establish a commission enjoy, on average, billions in net FDI inflows. For an economy struggling to establish indigenous production in a post-conflict setting, this can be critical to their long-term economic development. Again, this is further proof of the substantive significance of this relationship.\n\n\n\n\n\n\nTip\n\n\n\nVisualizing the full range of plausible coefficients can be a great way to communicate your findings:\n\nplot_predictions(m, condition = \"pcj\") + \n  geom_hline(yintercept = 0, colour = \"grey\") + \n  labs(x = NULL,\n       y = \"Net FDI inflows (USD million)\") + \n  scale_y_continuous(labels = scales::dollar) + \n  theme_minimal()"
  },
  {
    "objectID": "content/04-02-linear_regression.html#but-what-about-other-factors-that-shape-net-fdi-inflows",
    "href": "content/04-02-linear_regression.html#but-what-about-other-factors-that-shape-net-fdi-inflows",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "But what about other factors that shape net FDI inflows?",
    "text": "But what about other factors that shape net FDI inflows?\nOne of Appel and Loyle’s major contributions is their critique of approaches to estimating net FDI inflows that focus only on economic factors. They argue that there are several political factors that are significant determinants of other countries’ and foreign firms’ willingness to invest in these war-torn countries.\nThis critique is very valid, but it suggests that there are many different things influencing this outcome of interest, including economic factors. We have only looked at the political! The economists might turn around and accuse us of doing the very thing Appel and Loyle accused them of!\nLet’s add some of those economic factors into our model. We will start with an intuitive one: individuals’ economic wealth (measured as GDP per capita). I expect that foreign firms will be more willing to invest larger sums of money into economies with richer citizens. These citizens will be more willing and able to purchase the goods and services provided by those firms.\nTherefore, I hypothesize that the greater a state’s GDP per capita, the larger its net FDI inflows. I expect this to be the case regardless of whether the state has established a PCJ institution. Let’s test this claim:\n\nm &lt;- lm(net_fdi_inflows ~ pcj + gdp_per_capita, data = ebj)\n\nmodelsummary(m, \n             coef_rename = c(\"pcjPCJ institutions\" = \"PCJ institutions established\",\n                             \"gdp_per_capita\" = \"GDP per capita (current USD)\"),\n             stars = T)\n\n\n\n    \n\n      \n\n \n                (1)\n              \n+ p \n\n\n(Intercept)                 \n                  -319.173 \n                \n\n                            \n                  (396.052)\n                \n\nPCJ institutions established\n                  1673.288*\n                \n\n                            \n                  (714.015)\n                \n\nGDP per capita (current USD)\n                  0.318**  \n                \n\n                            \n                  (0.105)  \n                \n\nNum.Obs.                    \n                  95       \n                \n\nR2                          \n                  0.142    \n                \n\nR2 Adj.                     \n                  0.124    \n                \n\nAIC                         \n                  1777.5   \n                \n\nBIC                         \n                  1787.7   \n                \n\nLog.Lik.                    \n                  -884.742 \n                \n\nRMSE                        \n                  2681.52  \n                \n\n\n\n\n\n\nWe continue to find a positive and statistically significant relationship between net FDI inflows and the establishment of a PCJ institution. This model also accounts for the association between the state’s GDP per capita and those inflows.\nThe intercept here is not informative on its own. It tells us the estimated average net FDI inflows for states that do not have PCJ institutions and in which citizens had a GDP per capita of $0. Although the majority of states did not establish an institution, there are no states in the world that have a GDP per capita of $0.\nLet’s instead focus on the other coefficients. We find that states that established a PCJ institution received, on average, net FDI inflows of $1,673.29 million more than states that did not in the 10-year period after conflict. This is a slightly smaller estimated difference than we found in the model that did not account for individuals’ average wealth, but it remains large.\nWe also find that an increase in the GDP per capita of a state of $1,000 is associated with an increase of $318.45 million in net FDI inflow. This is consistent with our expectations that, holding all else constant, a country with a richer population is a more attractive investment destination than a country that has poorer citizens.\nUsing this richer model\nWe now have a richer understanding of the determinants of net FDI inflows to post-conflict countries. We have accounted for both economic and political determinants of those flows. Although it is often useful to look at the estimated relationship of each of those variables individually (as we did just above), we often learn more by looking at the whole model in context.\nAs usual, one of the easiest ways to communicate this is through a visualization. Let’s look at the predicted net FDI inflows for post-conflict countries that established and did not establish PCJ institutions across a range of plausible GDP per capita values:\n\nplot_predictions(m, condition = c(\"gdp_per_capita\", \"pcj\")) + \n  labs(x = \"GDP per capita (USD)\",\n       y = \"Net FDI inflows (USD million)\") + \n  scale_y_continuous(labels = scales::dollar) + \n  scale_x_continuous(labels = scales::dollar) + \n  theme_minimal()\n\n\n\n\n\n\n\nWe can see the positive relationship between GDP per capita and net FDI inflows and that across any given value of GDP per capita states that have established a PCJ institution start and stay at a higher predicted inflow compared to those that did not.\nThe full model\nAppel and Loyle control for many more economic and political factors shaping net FDI inflows. Remember, they are arguing that the extensive literature that looks at the determinants of FDI flows to post-conflict states failed to account for this important political factor. However, that same literature did a very good job of identifying the economic factors, including countries’ economic development, size, and growth rates, that shape this outcome. They don’t dispute that these factors are also important, they just argue that we should also think about the role PCJ institutions play in shaping foreign firms’ beliefs about the risk of returning to violence.\nSo, let’s account for these other factors:\n\nm &lt;- lm(net_fdi_inflows ~ pcj + gdp_per_capita + gdp + gdp_per_capita_growth + \n          cap_account_openness + ex_rate_fluc + labor + f_life_exp + \n          pol_constraints + polity2 + damage + conflict_duration + peace_agreement + \n          victory + cold_war, \n        data = ebj)\n\nmodelsummary(m, \n             coef_rename = c(\"pcjPCJ institutions\" = \"PCJ institutions established\",\n                             \"gdp_per_capita\" = \"GDP per capita (current USD)\",\n                             \"gdp\" = \"GDP (current USD)\",\n                             \"gdp_per_capita_growth\" = \"GDP per capita growth rate (%)\",\n                             \"cap_account_openness\" = \"Capital account openness\",\n                             \"ex_rate_fluc\" = \"Exchange rate fluctuation\",\n                             \"labor\" = \"Labor force participation (%)\",\n                             \"f_life_exp\" = \"Average female life expectancy (years)\",\n                             \"pol_constraints\" = \"Political constraints\",\n                             \"polity2\" = \"Regime type (Polity score)\",\n                             \"damage\" = \"Pre-conflict GDP lost\",\n                             \"conflict_duration\" = \"Conflict duration (years)\",\n                             \"peace_agreementPeace agreement\" = \"Peace agreement\",\n                             \"victoryVictory\" = \"Decisive victory\",\n                             \"cold_warCold War\" = \"Cold War\"),\n             stars = T)\n\n\n\n    \n\n      \n\n \n                (1)\n              \n+ p \n\n\n(Intercept)                           \n                  -1278.322 \n                \n\n                                      \n                  (2852.294)\n                \n\nPCJ institutions established          \n                  1960.282**\n                \n\n                                      \n                  (702.992) \n                \n\nGDP per capita (current USD)          \n                  -0.111    \n                \n\n                                      \n                  (0.133)   \n                \n\nGDP (current USD)                     \n                  0.000***  \n                \n\n                                      \n                  (0.000)   \n                \n\nGDP per capita growth rate (%)        \n                  37.400    \n                \n\n                                      \n                  (23.239)  \n                \n\nCapital account openness              \n                  198.823   \n                \n\n                                      \n                  (201.590) \n                \n\nExchange rate fluctuation             \n                  -42.516** \n                \n\n                                      \n                  (13.888)  \n                \n\nLabor force participation (%)         \n                  9.844     \n                \n\n                                      \n                  (25.528)  \n                \n\nAverage female life expectancy (years)\n                  3.475     \n                \n\n                                      \n                  (32.993)  \n                \n\nPolitical constraints                 \n                  2557.954+ \n                \n\n                                      \n                  (1459.599)\n                \n\nRegime type (Polity score)            \n                  -90.169   \n                \n\n                                      \n                  (56.309)  \n                \n\nPre-conflict GDP lost                 \n                  28.379**  \n                \n\n                                      \n                  (10.242)  \n                \n\nConflict duration (years)             \n                  0.811     \n                \n\n                                      \n                  (35.543)  \n                \n\nPeace agreement                       \n                  -1215.137 \n                \n\n                                      \n                  (793.826) \n                \n\nDecisive victory                      \n                  -33.969   \n                \n\n                                      \n                  (650.725) \n                \n\nCold War                              \n                  81.531    \n                \n\n                                      \n                  (654.092) \n                \n\nNum.Obs.                              \n                  95        \n                \n\nR2                                    \n                  0.514     \n                \n\nR2 Adj.                               \n                  0.422     \n                \n\nAIC                                   \n                  1749.5    \n                \n\nBIC                                   \n                  1792.9    \n                \n\nLog.Lik.                              \n                  -857.752  \n                \n\nRMSE                                  \n                  2018.34   \n                \n\n\n\n\n\n\nEven when we account for all the political, economic, and conflict-related factors that the literature previously identified to be important, we still find that the existence of PCJ institution substantively and statistically significantly shapes the net FDI inflows of post-conflict states."
  },
  {
    "objectID": "content/04-02-linear_regression.html#including-categorical-variables-with-multiple-categories",
    "href": "content/04-02-linear_regression.html#including-categorical-variables-with-multiple-categories",
    "title": "Estimating Causal Effects with Observational Data",
    "section": "Including categorical variables with multiple categories",
    "text": "Including categorical variables with multiple categories\nAppel and Loyle look at a number of political factors driving net FDI inflows to post-conflict states. They include a measure of regime type: the country’s Polity score. This score measures a state’s regime type along a 21-point scale from -10 (perfect autocracy) to 10 (perfect democracy). Broadly speaking, political scientists have usefully broken this spectrum down into three regime types: democracies, hybrid regimes, and autocracies.\nLet’s modify their measure of regime type to reflect these broad categories, instead of treating it as a continuous variable:\n\nebj &lt;- ebj |&gt; \n  mutate(regime_type = case_when(polity2 &gt; 5 ~ \"Democracy\",\n                                 polity2 &lt; -5 ~ \"Autocracy\",\n                                 TRUE ~ \"Hybrid regime\"),\n         regime_type = factor(regime_type, levels = c(\"Autocracy\",\n                                                      \"Hybrid regime\",\n                                                      \"Democracy\")))\n\nI have a theoretical reason to do this. I suspect that there is not a clear linear relationship between investors’ confidence in a post-conflict state and its regime type when we treat regime type as a continuous spectrum moving linearly from autocracies to democracies. In other words, I don’t think that moving one Polity score away from being an autocracy to being a democracy would have a consistent effect on investor confidence (and; therefore, net FDI inflows). Appel and Loyle’s model agrees with me: the regime type variable is not statistically significant.\nRather, I suspect that strong democracies and strong autocracies provide the political stability required to comfort foreign investors. These investors believe that the strong control democrats and autocrats have over their citizens and institutions reduces the risk that the country will re-enter into conflict. However, hybrid regimes do not tend to have this level of control. Investors are; therefore, less likely to invest in post-conflict countries with hybrid regimes.\nLet’s test this!\nWe now have a categorical variable with three categories: democracy, hybrid regime, and autocracy. We have thus far largely dealt with binary categorical variables (voted or not, Southern or not, female or not). How do we use and interpret multiple categorical variables in regression analysis?\nHappily, the intuition remains the same as with our binary categorical variables. We hold one category out as our baseline category and then compare the associated effects of the other categories to this one.\nLet’s step through that using a stripped back version of our model:\n\nm &lt;- lm(net_fdi_inflows ~ pcj + regime_type, data = ebj)\n\nmodelsummary(m, \n             coef_rename = c(\"pcjPCJ institutions\" = \"PCJ institutions established\",\n                             \"regime_typeDemocracy\" = \"Democracy\",\n                             \"regime_typeHybrid regime\" = \"Hybrid\"),\n             stars = T)\n\n\n\n    \n\n      \n\n \n                (1)\n              \n+ p \n\n\n(Intercept)                 \n                  214.555  \n                \n\n                            \n                  (497.984)\n                \n\nPCJ institutions established\n                  1816.169*\n                \n\n                            \n                  (764.093)\n                \n\nHybrid                      \n                  553.893  \n                \n\n                            \n                  (667.644)\n                \n\nDemocracy                   \n                  -148.124 \n                \n\n                            \n                  (809.623)\n                \n\nNum.Obs.                    \n                  95       \n                \n\nR2                          \n                  0.068    \n                \n\nR2 Adj.                     \n                  0.037    \n                \n\nAIC                         \n                  1787.4   \n                \n\nBIC                         \n                  1800.1   \n                \n\nLog.Lik.                    \n                  -888.688 \n                \n\nRMSE                        \n                  2795.25  \n                \n\n\n\n\n\n\nYou’ll note that autocracies are missing from our regression table. This is because they are being held out as our baseline category. Their effect on net FDI inflows is captured by the intercept coefficient.\n\n\n\n\n\n\nTip\n\n\n\nWe often say that the intercept coefficient represents the predicted average value of our outcome of interest when all independent variables are set to zero. It might be useful for you to think of your baseline category as taking on the value zero. For example, we can think of autocracy = 0.\n\n\nOur model suggests that autocracies (regime_type = \"Autocracy\") that have not established a commission (pcj = \"No institutions\") have a predicted average net FDI inflow of $214.55 million.\nThe coefficients on democracies and hybrid regimes need to be interpreted in relation to autocracies (their baseline category). From our model, we can see that the coefficient for democracies is negative and the coefficient for hybrid regimes is positive. That means that, on average, democracies tend to receive less net FDI inflows than autocracies and hybrid regimes tend to receive more net FDI inflows than autocracies.\nPredictions with multiple categorical variables\nUsing our model, what do we predict to be the net FDI inflows for democracies, autocracies, and hybrid regimes that either have a PCJ institutions or do not?\nFirst, let’s create a table with each possible combination of these two variables of interest:\n\nnew_data &lt;- tibble(pcj = factor(c(\"No institutions\", \n                                  \"PCJ institutions\"))) |&gt; \n  cross_join(\n    tibble(regime_type = factor(c(\"Autocracy\", \"Democracy\", \"Hybrid regime\")))\n  )\n\nnew_data\n\n# A tibble: 6 × 2\n  pcj              regime_type  \n  &lt;fct&gt;            &lt;fct&gt;        \n1 No institutions  Autocracy    \n2 No institutions  Democracy    \n3 No institutions  Hybrid regime\n4 PCJ institutions Autocracy    \n5 PCJ institutions Democracy    \n6 PCJ institutions Hybrid regime\n\n\nThen we can use our model to predict what we expect a hypothetical state with each of these combinations of characteristics to receive in net FDI inflows:\n\npred &lt;- augment(m, newdata = new_data)\n\npred\n\n# A tibble: 6 × 3\n  pcj              regime_type   .fitted\n  &lt;fct&gt;            &lt;fct&gt;           &lt;dbl&gt;\n1 No institutions  Autocracy       215. \n2 No institutions  Democracy        66.4\n3 No institutions  Hybrid regime   768. \n4 PCJ institutions Autocracy      2031. \n5 PCJ institutions Democracy      1883. \n6 PCJ institutions Hybrid regime  2585. \n\n\nThat’s a bit unweildy. Let’s visualize it!\n\nggplot(pred, aes(x = .fitted, y = pcj, colour = regime_type)) + \n  geom_point(size = 5) + \n  theme_minimal() + \n  labs(x = \"Predicted net FDI inflows (USD, million)\",\n       y = NULL, \n       colour = \"Regime type\")\n\n\n\n\n\n\n\nWe can clearly see that states that established PCJ institutions received, on average, larger net FDI inflows than states that did not, no matter their regime type. Further and completely counter to my hypothesis, hybrid regimes have, on average, the highest net FDI inflows compared to democracies and autocracies even when we account for whether the state has a PCJ institution.\nI’m not too worried: none of these coefficients are anywhere close to being statistically significant. I suspect that there is a more complex relationship underlying commercial actors’ beliefs about the stability of hybrid regimes, democracies, and autocracies and its effect on net investment flows. But I hope this serves as a good illustration of how we can use multiple categorical variables in our analyses."
  },
  {
    "objectID": "content/03-01-wrangling.html",
    "href": "content/03-01-wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"tidyverse\", \"janitor\", \"scales\", \"wbstats\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(scales)\nlibrary(wbstats)",
    "crumbs": [
      "Content",
      "Session 3",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "content/03-01-wrangling.html#set-up",
    "href": "content/03-01-wrangling.html#set-up",
    "title": "Data Wrangling",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"tidyverse\", \"janitor\", \"scales\", \"wbstats\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(scales)\nlibrary(wbstats)",
    "crumbs": [
      "Content",
      "Session 3",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "content/03-01-wrangling.html#introduction",
    "href": "content/03-01-wrangling.html#introduction",
    "title": "Data Wrangling",
    "section": "Introduction",
    "text": "Introduction\nI am now going to introduce you to a set of important tools for tidying your data. Oftentimes, the data we want to work with does not come to us in a format that is easy for us to use. We need to wrangle it into a better structure and remove inconsistencies.\nWe will continue to work with the variables the Gapminder Project is interested in: health and wealth. However, instead of accessing the lovely clean data set provided to you in the gapminder R package, we are going to go straight to the source and collect data on countries’ GDP per capita and average life expectancy from the World Bank. Let’s get started!",
    "crumbs": [
      "Content",
      "Session 3",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "content/03-01-wrangling.html#collecting-your-data",
    "href": "content/03-01-wrangling.html#collecting-your-data",
    "title": "Data Wrangling",
    "section": "Collecting your data",
    "text": "Collecting your data\nThe World Bank provides us with access to a trove of official country- and sub-national level data that are very useful for political analysis. I use their data in nearly all of my research. Sadly, they tend to provide their data in a messy format. We will now collect that messy data so we can learn how to tidy it up.\nTo access their data and some wonderful data visualizations, you can head over to their data portal: https://data.worldbank.org/. From there, you can browse which data sets they have or search for ones you are interested in.\nWe are going to start by collecting data on countries’ GDP per capita (current US$). It can be accessed here: https://data.worldbank.org/indicator/NY.GDP.PCAP.CD.\nReading in an external file\nYou can download the data directly from this web page, save it in the appropriate place in your RProject, and read it in from there.\n\n\n\n\n\n\nNote\n\n\n\nThis process is similar to the one we used in Session 2: From Samples to the Population.\n\n\nI saved the CSV in the data folder (which is the in the content folder because this is a website), so I will use here::here() to adaptively find the correct file path and read the file in using read_csv().\n\ngdp_per_cap_raw &lt;- read_csv(here::here(\"content\", \"data\", \n                                       \"API_NY.GDP.PCAP.CD_DS2_en_csv_v2_76.csv\"))\n\nAfter running this yourself, you will see an ominous warning. Let’s take a look at our data:\n\ngdp_per_cap_raw\n\n# A tibble: 268 × 3\n   `Data Source`               `World Development Indicators` ...3              \n   &lt;chr&gt;                       &lt;chr&gt;                          &lt;chr&gt;             \n 1 Last Updated Date           2024-12-16                      &lt;NA&gt;             \n 2 Country Name                Country Code                   \"Indicator Name,I…\n 3 Aruba                       ABW                            \"GDP per capita (…\n 4 Africa Eastern and Southern AFE                            \"GDP per capita (…\n 5 Afghanistan                 AFG                            \"GDP per capita (…\n 6 Africa Western and Central  AFW                            \"GDP per capita (…\n 7 Angola                      AGO                            \"GDP per capita (…\n 8 Albania                     ALB                            \"GDP per capita (…\n 9 Andorra                     AND                            \"GDP per capita (…\n10 Arab World                  ARB                            \"GDP per capita (…\n# ℹ 258 more rows\n\n\nWe have only three columns, none of which appear to have the right names. It also looks like the first few rows may, in fact, not be rows in our data set. Rather, they are metadata, including the last time the data were updated.\nThe second row in our data set looks like the real column headings. This is good! We can skip the first few rows using read_csv()’s skip argument. Just provide it with the number of rows you want to skip when reading in the CSV.\n\ngdp_per_cap_raw &lt;- read_csv(here::here(\"content\", \"data\", \n                                       \"API_NY.GDP.PCAP.CD_DS2_en_csv_v2_76.csv\"),\n                            skip = 3)\n\ngdp_per_cap_raw\n\n# A tibble: 266 × 69\n   `Country Name` `Country Code` `Indicator Name` `Indicator Code` `1960` `1961`\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;            &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;\n 1 Aruba          ABW            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 2 Africa Easter… AFE            GDP per capita … NY.GDP.PCAP.CD     186.   187.\n 3 Afghanistan    AFG            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 4 Africa Wester… AFW            GDP per capita … NY.GDP.PCAP.CD     122.   127.\n 5 Angola         AGO            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 6 Albania        ALB            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 7 Andorra        AND            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 8 Arab World     ARB            GDP per capita … NY.GDP.PCAP.CD      NA    213.\n 9 United Arab E… ARE            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n10 Argentina      ARG            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n# ℹ 256 more rows\n# ℹ 63 more variables: `1962` &lt;dbl&gt;, `1963` &lt;dbl&gt;, `1964` &lt;dbl&gt;, `1965` &lt;dbl&gt;,\n#   `1966` &lt;dbl&gt;, `1967` &lt;dbl&gt;, `1968` &lt;dbl&gt;, `1969` &lt;dbl&gt;, `1970` &lt;dbl&gt;,\n#   `1971` &lt;dbl&gt;, `1972` &lt;dbl&gt;, `1973` &lt;dbl&gt;, `1974` &lt;dbl&gt;, `1975` &lt;dbl&gt;,\n#   `1976` &lt;dbl&gt;, `1977` &lt;dbl&gt;, `1978` &lt;dbl&gt;, `1979` &lt;dbl&gt;, `1980` &lt;dbl&gt;,\n#   `1981` &lt;dbl&gt;, `1982` &lt;dbl&gt;, `1983` &lt;dbl&gt;, `1984` &lt;dbl&gt;, `1985` &lt;dbl&gt;,\n#   `1986` &lt;dbl&gt;, `1987` &lt;dbl&gt;, `1988` &lt;dbl&gt;, `1989` &lt;dbl&gt;, `1990` &lt;dbl&gt;, …\n\n\nThat looks better! We have now read in the data set itself, skipping those rows of metadata.\nThe resulting data set is a wide one. Each observation is a country or region. The first two columns provide information on the country. The third and fourth describe the indicator. All other columns provide each country’s GDP per capita in all years from 1960 to 2023.\nNow, imagine you want to compare a country’s GDP per capita across many years. For example, you want to know how Australians’ wealth has grown over time. This is very difficult to do with this current format. We would need to work with all columns from 1960 to 2023!\nTo make these data easier to work with, we will lengthen the data set. Instead of each observation (row) describing a country, we will make each observation describe a country-year.\nTo do this, we need to use pivot_longer(). We need to let it know which columns we want to transpose using the col argument. Because the end year for these data will change each year I want to pull and clean up this data set (for example, next year the last column will be 2024, not 2023), I will use ! to negate the columns I don’t want to transpose. This code will, therefore, work after each annual update to the data set.\n\ngdp_per_cap &lt;- gdp_per_cap_raw |&gt; \n  pivot_longer(cols = !c(`Country Name`:`Indicator Code`),\n               names_to = \"year\",\n               values_to = \"gdp_per_cap\")\n\ngdp_per_cap\n\n# A tibble: 17,290 × 6\n   `Country Name` `Country Code` `Indicator Name`         `Indicator Code` year \n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;chr&gt;            &lt;chr&gt;\n 1 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1960 \n 2 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1961 \n 3 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1962 \n 4 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1963 \n 5 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1964 \n 6 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1965 \n 7 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1966 \n 8 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1967 \n 9 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1968 \n10 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1969 \n# ℹ 17,280 more rows\n# ℹ 1 more variable: gdp_per_cap &lt;dbl&gt;\n\n\nI have also told pivot_longer() what to call the column containing the previous column names (using names_to) and the column containing the values (using values_to).\nYou might have noticed that I needed to include some back ticks when referencing those column names. This is because these column names do not follow the rules put in place to help you work with R. Column names must:\n\nNot include spaces\nNot start with numbers or special characters\n\nThey should also be:\n\nShort\nMeaningful\nConsistently formatted\n\nThe World Bank uses spaces in its column names. We need to remove those so we can more easily work with them in R. Happily, the very handy janitor R package is here for all of your cleaning needs!\nI use the clean_names() function to ensure names are clean and consistent:\n\ngdp_per_cap &lt;- clean_names(gdp_per_cap)\ngdp_per_cap\n\n# A tibble: 17,290 × 6\n   country_name country_code indicator_name     indicator_code year  gdp_per_cap\n   &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;          &lt;chr&gt;       &lt;dbl&gt;\n 1 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1960           NA\n 2 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1961           NA\n 3 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1962           NA\n 4 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1963           NA\n 5 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1964           NA\n 6 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1965           NA\n 7 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1966           NA\n 8 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1967           NA\n 9 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1968           NA\n10 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1969           NA\n# ℹ 17,280 more rows\n\n\nGreat! We’re almost there. Next, we need to check that R has correctly classified our data types. For example, we want to make sure that the years are coded as numbers not strings of characters.\n\nglimpse(gdp_per_cap)\n\nRows: 17,290\nColumns: 6\n$ country_name   &lt;chr&gt; \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"…\n$ country_code   &lt;chr&gt; \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\",…\n$ indicator_name &lt;chr&gt; \"GDP per capita (current US$)\", \"GDP per capita (curren…\n$ indicator_code &lt;chr&gt; \"NY.GDP.PCAP.CD\", \"NY.GDP.PCAP.CD\", \"NY.GDP.PCAP.CD\", \"…\n$ year           &lt;chr&gt; \"1960\", \"1961\", \"1962\", \"1963\", \"1964\", \"1965\", \"1966\",…\n$ gdp_per_cap    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\n\nHmm, it does appear to have read the years in as characters. Why?\n\nunique(gdp_per_cap$year)\n\n [1] \"1960\"  \"1961\"  \"1962\"  \"1963\"  \"1964\"  \"1965\"  \"1966\"  \"1967\"  \"1968\" \n[10] \"1969\"  \"1970\"  \"1971\"  \"1972\"  \"1973\"  \"1974\"  \"1975\"  \"1976\"  \"1977\" \n[19] \"1978\"  \"1979\"  \"1980\"  \"1981\"  \"1982\"  \"1983\"  \"1984\"  \"1985\"  \"1986\" \n[28] \"1987\"  \"1988\"  \"1989\"  \"1990\"  \"1991\"  \"1992\"  \"1993\"  \"1994\"  \"1995\" \n[37] \"1996\"  \"1997\"  \"1998\"  \"1999\"  \"2000\"  \"2001\"  \"2002\"  \"2003\"  \"2004\" \n[46] \"2005\"  \"2006\"  \"2007\"  \"2008\"  \"2009\"  \"2010\"  \"2011\"  \"2012\"  \"2013\" \n[55] \"2014\"  \"2015\"  \"2016\"  \"2017\"  \"2018\"  \"2019\"  \"2020\"  \"2021\"  \"2022\" \n[64] \"2023\"  \"...69\"\n\n\nLooking at all unique values included in the year column, we can see the culprit: \"...69\". It looks like the CSV includes a rouge last column with no data in it. read_csv() read that column in and coded all its values as NA:\n\ngdp_per_cap |&gt; \n  filter(year == \"...69\") |&gt; \n  distinct(gdp_per_cap)\n\n# A tibble: 1 × 1\n  gdp_per_cap\n        &lt;dbl&gt;\n1          NA\n\n\nWe can simply filter this out of our data set to get rid of it and convert the remaining values to numbers using mutate():\n\ngdp_per_cap &lt;- gdp_per_cap |&gt; \n  filter(year != \"...69\") |&gt; \n  mutate(year = as.numeric(year))\ngdp_per_cap\n\n# A tibble: 17,024 × 6\n   country_name country_code indicator_name     indicator_code  year gdp_per_cap\n   &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n 1 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1960          NA\n 2 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1961          NA\n 3 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1962          NA\n 4 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1963          NA\n 5 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1964          NA\n 6 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1965          NA\n 7 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1966          NA\n 8 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1967          NA\n 9 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1968          NA\n10 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1969          NA\n# ℹ 17,014 more rows\n\n\nWe now have a nice and clean data set that is easy to work with. Let’s take a look at Australia’s growth over time:\n\ngdp_per_cap |&gt; \n  filter(country_name == \"Australia\") |&gt; \n  ggplot(aes(x = year, y = gdp_per_cap)) + \n  geom_line() + \n  geom_point(size = 1) + \n  theme_minimal() + \n  labs(x = \"Year\",\n       y = \"GDP per capita (current US$)\") + \n  scale_y_continuous(labels = dollar)",
    "crumbs": [
      "Content",
      "Session 3",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html",
    "href": "content/02-02-surveys_to_pops.html",
    "title": "From Samples to the Population",
    "section": "",
    "text": "A lot the data we use in political science research are incomplete. Rarely do we have data on all actors in our population of interest. We, therefore, need to work out the degree to which our sample of actors resembles what we would see in the population. This session introduces you to the tools you need to do this.",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html#set-up",
    "href": "content/02-02-surveys_to_pops.html#set-up",
    "title": "From Samples to the Population",
    "section": "Set up",
    "text": "Set up\nTo complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"tidyverse\", \"wbstats\", \"scales\", \"here\", \"dataverse\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(wbstats)\nlibrary(scales)\nlibrary(here)\nlibrary(dataverse)",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html#introduction",
    "href": "content/02-02-surveys_to_pops.html#introduction",
    "title": "From Samples to the Population",
    "section": "Introduction",
    "text": "Introduction\nEntire populations are very difficult to collect data on. Even the census (which aims to account for every citizen living within a country) misses people. Happily, we do not need to learn information about the whole population to discover general trends within it. Instead, we can use good surveys of the population.\nWhat do I mean by “good”? The sample of your population surveyed must be representative of that population. This session focuses on defining what we mean by that.",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html#representative-samples",
    "href": "content/02-02-surveys_to_pops.html#representative-samples",
    "title": "From Samples to the Population",
    "section": "Representative samples",
    "text": "Representative samples\nSurveys are conducted on a subset of a our population of interest. This is because it is often unfeasible (or impossible) to ask these questions of our population.\nTo be able to infer from our sample information about our population, we need to ensure the sample is representative of that population. In other words, we need to try our best to make sure the sample looks very similar to our population.\nRemember back to the last session on experiments. In an ideal world, we would be able to create two parallel worlds (one with the treatment, one held as our control). These two worlds would be identical to each other prior to treatment. This allows us to confidently state that any differences in our outcome of interest were caused by the treatment. It was, after all, the only thing differentiating those two worlds.\nSadly, however, we have no time machine and cannot produce two parallel worlds. Instead, we needed to create two groups that are as identical to one another as possible prior to treatment. If they are (almost) identical, differences between their group-wide outcomes can be attributed to the treatment.\nOne very good way of getting two (almost) identical groups is to assign individuals to those groups randomly.\n\n\n\n\n\n\nTip\n\n\n\nFor more on why randomization works, please head back to Randomization in Causes and Effects.\n\n\nSimilarly, we can use randomization to pull a sample from our population that looks, on average, identical to that population. Drawing randomly from our population increases our chances of ending up with a sample that reflects that population.",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html#random-sampling",
    "href": "content/02-02-surveys_to_pops.html#random-sampling",
    "title": "From Samples to the Population",
    "section": "Random sampling",
    "text": "Random sampling\nTo sample randomly from your population, all individuals in the population need to have an equal chance of being selected for the sample. If this holds, you have a pure random sample.\nHowever, this is really hard to do! For example, think about how likely you are to answer a call from an unknown number. Pollsters rely on people picking up their calls. Imagine you do answer: how likely are you to sit through an interview with a pollster?\nThere are groups of people in the US voting population who are more likely to pick up a call from an unknown number. For example, people with land line phones are much more likely to answer that call (they cannot see it is from an unknown number). Similarly, there are groups of people who are more likely to sit through an interview with a pollster. For example, retired people who have the time to spare during their day. These people are systematically different from the population as a whole. People with land land phones tend to be older, on average, than the general population. Similarly, retired people tend to be older than the general population.\nThis is important because older people tend to be more conservative than the general population as well. Your survey (which will include a disproportionately large group of older people) is likely to overstate how conservative the population as a whole is.",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html#the-effects-of-an-unrepresentative-sample",
    "href": "content/02-02-surveys_to_pops.html#the-effects-of-an-unrepresentative-sample",
    "title": "From Samples to the Population",
    "section": "The effects of an unrepresentative sample",
    "text": "The effects of an unrepresentative sample\nLet’s step through this with some actual data. Consider trying to answer the question: what was the average GDP earned by countries globally in 2022?\nTo demonstrate the effects of a biased sample, we are going to download all available GDP values for 2022 using the World Bank’s application programming interface (API). We are going to use the wb_data() function from the wbstats R package to do this. I am going to assign the resulting data set to an object called gdp_df.\n\ngdp_df &lt;- wb_data(\"NY.GDP.MKTP.CD\", return_wide = F, start_date = 2022, end_date = 2022) |&gt; \n  # Select only the relevant data points\n  select(iso3c:value)\n\ngdp_df\n\n# A tibble: 217 × 4\n   iso3c country              date         value\n   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;\n 1 AFG   Afghanistan          2022  14497243872.\n 2 ALB   Albania              2022  19017242586.\n 3 DZA   Algeria              2022 225638456572.\n 4 ASM   American Samoa       2022    871000000 \n 5 AND   Andorra              2022   3380612573.\n 6 AGO   Angola               2022 104399746853.\n 7 ATG   Antigua and Barbuda  2022   1867733333.\n 8 ARG   Argentina            2022 632790070063.\n 9 ARM   Armenia              2022  19513506553.\n10 ABW   Aruba                2022   3279343544.\n# ℹ 207 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nRun ?wb_data in your console to see what arguments the function takes.\n\n\nWe are going to treat this data set as complete. In other words, we will assume that this data set includes the actual GDP values for all countries globally in 2022. This is cheeky for many reasons. Most obviously, we are missing a whole bunch of data points. Let’s identify those:\n\nfilter(gdp_df, is.na(value))\n\n# A tibble: 11 × 4\n   iso3c country                    date value\n   &lt;chr&gt; &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 VGB   British Virgin Islands     2022    NA\n 2 CUB   Cuba                       2022    NA\n 3 ERI   Eritrea                    2022    NA\n 4 GIB   Gibraltar                  2022    NA\n 5 GRL   Greenland                  2022    NA\n 6 IMN   Isle of Man                2022    NA\n 7 PRK   Korea, Dem. People's Rep.  2022    NA\n 8 SSD   South Sudan                2022    NA\n 9 MAF   St. Martin (French part)   2022    NA\n10 VEN   Venezuela, RB              2022    NA\n11 YEM   Yemen, Rep.                2022    NA\n\n\n\n\n\n\n\n\nSpoiler alert\n\n\n\nCan you identify anything these missing countries have in common?\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe is.na() function is a logical function (returns either TRUE or FALSE) that asks whether a value is NA, or missing. For example:\n\nis.na(1)\n\n[1] FALSE\n\nis.na(NA)\n\n[1] TRUE\n\n\nWhen supplied to the filter() function, it filters out all the values that are not NA (and are marked as FALSE by the is.na() function).\nTo exclude missing values, you can negate is.na():\n\nfilter(gdp_df, !is.na(value))\n\n# A tibble: 206 × 4\n   iso3c country              date         value\n   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;\n 1 AFG   Afghanistan          2022  14497243872.\n 2 ALB   Albania              2022  19017242586.\n 3 DZA   Algeria              2022 225638456572.\n 4 ASM   American Samoa       2022    871000000 \n 5 AND   Andorra              2022   3380612573.\n 6 AGO   Angola               2022 104399746853.\n 7 ATG   Antigua and Barbuda  2022   1867733333.\n 8 ARG   Argentina            2022 632790070063.\n 9 ARM   Armenia              2022  19513506553.\n10 ABW   Aruba                2022   3279343544.\n# ℹ 196 more rows\n\n\nAlternatively, you can use the drop_na() function from the tidyr package:\n\ndrop_na(gdp_df, value)\n\n# A tibble: 206 × 4\n   iso3c country              date         value\n   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;\n 1 AFG   Afghanistan          2022  14497243872.\n 2 ALB   Albania              2022  19017242586.\n 3 DZA   Algeria              2022 225638456572.\n 4 ASM   American Samoa       2022    871000000 \n 5 AND   Andorra              2022   3380612573.\n 6 AGO   Angola               2022 104399746853.\n 7 ATG   Antigua and Barbuda  2022   1867733333.\n 8 ARG   Argentina            2022 632790070063.\n 9 ARM   Armenia              2022  19513506553.\n10 ABW   Aruba                2022   3279343544.\n# ℹ 196 more rows\n\n\n\n\nNonetheless, let’s pretend gdp_df includes the actual GDP values for every country in 2022. I am, therefore, going to update the gdp_df object to exclude those missing values:\n\ngdp_df &lt;- drop_na(gdp_df, value)\n\nNow, imagine I - the researcher who wants to work out the average GDP earned by countries globally in 2022 - do not have access to these data. I need to go out and collect them myself. To do this, I intend to send a request for information to every country’s Department of Statistics, asking them for their country’s GDP in 2022. Annoyingly, however, I can only find contact details for some departments. Specifically, I can only find details for departments with very flashy websites that provide a lot of detail on how to contact teams of people whose whole job is to answer such requests for information.\nLet’s update the gdp_df data set to include which countries I found contact details for. We are going to use some simulation here, which I will explain below.\n\n# Find the GDP value the marks the lowest 25 percent of all GDP values in 2022\nfirst_quartile_gdp &lt;- quantile(gdp_df$value, na.rm = T)[[2]]\n\ngdp_df &lt;- gdp_df |&gt; \n  # Create a variable that simulates my finding the contact details for countries with flashy \n  # websites (i.e. rich countries)\n  rowwise() |&gt; \n  mutate(contact_details_found = if_else(value &lt; first_quartile_gdp, \n                                         rbinom(1, 1, 0.10), \n                                         rbinom(1, 1, 0.75))) |&gt; \n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\nI am doing a fair bit mechanically here that could distract from my broader point about biased sampling. If, starting to read this note, you find yourself getting a bit lost, please just move on. We will come back to these concepts later.\nJumping ahead to the end, richer countries are more likely than poorer ones to have well-funded, large departments of statistics. To simulate this, I first need a definition of rich countries. I took the 25th percentile as my cut off point. The 25th percentile is the value below which 25 percent of all of the values in a series (ordered from smallest to largest) sit. So, the 25th percentile of my 2022 GDP values is the GDP value below which 25 percent of all other GDP values sit.\nRicher countries are more likely to have departments with accessible teams of people able to field my request for information. This does not mean that they definitely do, nor does it mean no poorer countries do. To account for this, I determine randomly whether a country has contact details based on its GDP value. For poorer countries (those in the lowest 25 percent of all countries), I give them a 10 percent chance I find their contact details. For richer countries (those in the highest 75 percent of all countries), I give them a 75 percent chance I find their contact details. I use the rbinom() function to do this. We will talk about this probability distribution function later in the course.\nI have now simulated data that reflects the constraints I would face as a researcher trying to answer my question.\n\n\nUndeterred, I send out my requests to those departments I have contact details for. I receive some responses:\n\ngdp_responses_df &lt;- gdp_df |&gt; \n  # Only sample from the countries I contacted\n  filter(contact_details_found == 1) |&gt; \n  # Simulate the uneven likelihood I receive responses back (based on wealth)\n  mutate(response_received = if_else(value &lt; first_quartile_gdp,\n                                     rbinom(1, 1, 0.5),\n                                     rbinom(1, 1, 0.8))) |&gt;\n  filter(response_received == 1) |&gt; \n  select(iso3c:value)\n\ngdp_responses_df\n\n# A tibble: 116 × 4\n   iso3c country      date   value\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n 1 AFG   Afghanistan  2022 1.45e10\n 2 ALB   Albania      2022 1.90e10\n 3 DZA   Algeria      2022 2.26e11\n 4 AGO   Angola       2022 1.04e11\n 5 ARM   Armenia      2022 1.95e10\n 6 AUS   Australia    2022 1.69e12\n 7 AUT   Austria      2022 4.72e11\n 8 BHR   Bahrain      2022 4.67e10\n 9 BGD   Bangladesh   2022 4.60e11\n10 BEL   Belgium      2022 5.93e11\n# ℹ 106 more rows\n\n\nNow, if I use this sample to learn something about the average GDP in 2022 for all countries globally, I am going to be wrong.\n\n\n\n\n\n\nQuestion\n\n\n\nCan you guess which way I will be wrong? Will I overstate or understate the global average GDP?\n\n\nHere is the average GDP among my sample:\n\ngdp_responses_df |&gt; \n  summarise(avg_gdp = mean(value)) |&gt; \n  pull() |&gt; \n  dollar()\n\n[1] \"$506,556,083,940\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe scales package includes handy functions for formatting numbers. I have used its dollar() function to format the average GDP nicely.\n\n\nAnd here is the average GDP among the population:\n\ngdp_df |&gt; \n  summarise(avg_gdp = mean(value)) |&gt; \n  pull() |&gt; \n  dollar()\n\n[1] \"$487,688,575,556\"\n\n\nI am overstating the average by a lot! Why? Well, countries that have departments of statistics that are so well funded they can splash out for a fancy website and have a team of people dedicated to fielding requests for information from random academics tend to be wealthy. Poorer countries are less able to spare the funds required to meet my request. I am, therefore, less likely to have found a way to contact them and, even if I did, I am less likely to have received a response from them.\nThis is an example of sampling bias: my sample is systematically different from my population in ways important to my analysis. Wealth is what I am trying to measure, and wealth is influencing who gets into my sample and who does not. Because I do not have a representative sample, I cannot infer from that sample anything about my population.",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html#largeish-numbers",
    "href": "content/02-02-surveys_to_pops.html#largeish-numbers",
    "title": "From Samples to the Population",
    "section": "Large(ish) numbers",
    "text": "Large(ish) numbers\nIt is not sufficient to have a pure random sample of your population. You also need a sufficiently large sample. To illustrate, consider drawing just one person from your population. Even if you did so entirely randomly, it is unlikely they will reflect the diversity (or even the average view) of the population.\nLet’s return to our attempt to find the average GDP earned by countries globally in 2022 to illustrate this. I am going to select completely randomly five countries from the (cheeky) population using dplyr’s sample_n() function:\n\ngdp_5_df &lt;- sample_n(gdp_df, size = 5)\ngdp_5_df\n\n# A tibble: 5 × 5\n  iso3c country              date   value contact_details_found\n  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;                 &lt;int&gt;\n1 TTO   Trinidad and Tobago  2022 3.01e10                     1\n2 IDN   Indonesia            2022 1.32e12                     1\n3 XKX   Kosovo               2022 9.35e 9                     1\n4 MDV   Maldives             2022 6.18e 9                     0\n5 MCO   Monaco               2022 8.80e 9                     1\n\n\nThe average GDP among this very small but pure random sample is $274,692,433,009, which is $212,996,142,547 dollars away from the population average.\nWe can do this again to see that it wasn’t just a fluke:\n\ngdp_5_df &lt;- sample_n(gdp_df, size = 5)\ngdp_5_df\n\n# A tibble: 5 × 5\n  iso3c country         date        value contact_details_found\n  &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;                 &lt;int&gt;\n1 KIR   Kiribati        2022   270841698.                     0\n2 CUW   Curacao         2022  3075180835.                     0\n3 LCA   St. Lucia       2022  2342703704.                     1\n4 CIV   Cote d'Ivoire   2022 70173140101.                     1\n5 ASM   American Samoa  2022   871000000                      0\n\n\nThe average GDP among this small pure random sample is $15,346,573,268, a $472,342,002,288 dollar difference from the population average.\nIf we increase our sample size, we get closer to the population average:\n\ngdp_175_df &lt;- sample_n(gdp_df, size = 175)\ngdp_175_df\n\n# A tibble: 175 × 5\n   iso3c country                         date   value contact_details_found\n   &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;   &lt;dbl&gt;                 &lt;int&gt;\n 1 TTO   Trinidad and Tobago             2022 3.01e10                     1\n 2 OMN   Oman                            2022 1.12e11                     0\n 3 KNA   St. Kitts and Nevis             2022 9.81e 8                     0\n 4 PAN   Panama                          2022 7.63e10                     0\n 5 COL   Colombia                        2022 3.45e11                     1\n 6 VCT   St. Vincent and the Grenadines  2022 9.66e 8                     0\n 7 TZA   Tanzania                        2022 7.58e10                     0\n 8 ITA   Italy                           2022 2.10e12                     1\n 9 MHL   Marshall Islands                2022 2.53e 8                     0\n10 GRD   Grenada                         2022 1.22e 9                     0\n# ℹ 165 more rows\n\n\nThe average GDP among this small pure random sample is $546,787,923,128, a mere $59,099,347,572 dollar difference from the population average.\nThe larger your sample size, the closer you will get to the population average. You increase the likelihood you capture the diversity of the population as your sample size increases.",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/02-02-surveys_to_pops.html#us-presidential-elections",
    "href": "content/02-02-surveys_to_pops.html#us-presidential-elections",
    "title": "From Samples to the Population",
    "section": "US Presidential Elections",
    "text": "US Presidential Elections\nUS Presidential elections involve thousands of surveys of the US population. Pollsters ask a small subset of that population questions about the election (including which candidate they intend to vote for). They hope to learn from the answers provided by that sample the views of the broader population.\nWe will look at surveys run in the 2020 US Presidential Election. We will learn about overall support for the two candidates (Joe Biden and Donald Trump), and how this support shifted across different demographics. We will then compare that survey to the end result to learn how accurately the survey reflected the population’s views.\nA survey of votes cast\nWe are going to look at the American National Election Studies pre-election survey. The ANES conducts surveys on voting, public opinion, and political participation. You can learn more about them from their website.\nTo download the data, you will need to head over to the ANES website, download the relevant file, and save it in your RProject. The following video demonstrates how to do this.\nOnce you have collected the data, you can read it in using the readr package’s read_csv() function. It takes the file’s path as its first argument.\n\nanes_raw &lt;- read_csv(here(\"content\", \"data\", \"anes_timeseries_2020_csv_20220210.csv\"))\nanes_raw\n\n# A tibble: 8,280 × 1,771\n   version  V200001 V160001_orig V200002 V200003 V200004 V200005 V200006 V200007\n   &lt;chr&gt;      &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 ANES202…  200015       401318       3       2       3       0      -2      -2\n 2 ANES202…  200022       300261       3       2       3       0       4      -1\n 3 ANES202…  200039       400181       3       2       3       0      -2      -2\n 4 ANES202…  200046       300171       3       2       3       0      -2      -2\n 5 ANES202…  200053       405145       3       2       3       1      -2      -2\n 6 ANES202…  200060       400374       3       2       3       0      -2      -2\n 7 ANES202…  200084       407013       3       2       3       0      -2      -2\n 8 ANES202…  200091       407174       3       2       3       0      -2      -2\n 9 ANES202…  200107       406264       3       2       3       0      -2      -2\n10 ANES202…  200114       402782       3       2       3       1       4      -1\n# ℹ 8,270 more rows\n# ℹ 1,762 more variables: V200008 &lt;dbl&gt;, V200009 &lt;dbl&gt;, V200010a &lt;dbl&gt;,\n#   V200010b &lt;dbl&gt;, V200010c &lt;dbl&gt;, V200010d &lt;dbl&gt;, V200011a &lt;dbl&gt;,\n#   V200011b &lt;dbl&gt;, V200011c &lt;dbl&gt;, V200011d &lt;dbl&gt;, V200012a &lt;dbl&gt;,\n#   V200012b &lt;dbl&gt;, V200012c &lt;dbl&gt;, V200012d &lt;dbl&gt;, V200013a &lt;dbl&gt;,\n#   V200013b &lt;dbl&gt;, V200013c &lt;dbl&gt;, V200013d &lt;dbl&gt;, V200014a &lt;dbl&gt;,\n#   V200014b &lt;dbl&gt;, V200014c &lt;dbl&gt;, V200014d &lt;dbl&gt;, V200015a &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe here R package makes saving data in a robust way very easy. Using here::here(), you can automatically update file paths to reflect the computer you are currently using. To demonstrate, run the following code:\n\nhere::here()\n\n[1] \"/Users/harrietgoers/Documents/GVPT399F\"\n\n\nYour output will be different to mine. here::here() locates the top level of the file directory in which you are located. This is helpful when you share your code with others (or switch to a new computer). Hard coded file paths will cause annoying errors.\nI like to save my data in a folder called data. You can use a structure you find works for you.\n\n\nEach row of this data set represents a single respondent. Therefore, we can quickly note that in 2020, the ANES surveyed 8,280 people.\nThe ANES asks a lot of questions of its respondents. Full details of these questions can be found in their survey questionnaire document. We are interested in learning whether the survey respondents reflect the behavior of all US voters in the 2020 US Presidential election. To answer this question, we are going to focus on their response to the question: which Presidential candidate did you vote for?\nThis question was only asked of respondents who had already told the interviewer that they voted for a US president. Not all respondents voted, so we need to remove those who did not from our data set.\nWe will then match these data to the total vote count each candidate won in the election to see if they are similar.\nLet’s start by transforming our data set into one that is more suitable for this analysis:\n\nanes_df &lt;- anes_raw |&gt; \n  select(respondent_id = V200001,\n         voted_for_pres = V202072,\n         pres_vote = V202073)\n\nanes_df\n\n# A tibble: 8,280 × 3\n   respondent_id voted_for_pres pres_vote\n           &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1        200015             -1        -1\n 2        200022              1         3\n 3        200039              1         1\n 4        200046              1         1\n 5        200053              1         2\n 6        200060              1         1\n 7        200084              1         2\n 8        200091             -1        -1\n 9        200107             -1        -1\n10        200114              1         1\n# ℹ 8,270 more rows\n\n\nIndividuals’ responses are coded as numbers, which are easily interpreted by the computer, but not by us humans. Let’s recode the responses so we know what they are. They are categorical variables (which R refers to as factors). Currently, they are coded as numbers (&lt;dbl&gt;). To convert them to factors, we need to use factor() within mutate():\n\nanes_df &lt;- anes_df |&gt; \n  mutate(voted_for_pres = factor(voted_for_pres, levels = 1:2, \n                                 labels = c(\"Yes, voted for President\",\n                                            \"No, didn’t vote for President\")),\n         pres_vote = factor(pres_vote, levels = 1:5,\n                            labels = c(\"DEMOCRAT\",\n                                       \"REPUBLICAN\",\n                                       \"LIBERTARIAN\",\n                                       \"GREENS\",\n                                       \"OTHER\")))\n\nanes_df\n\n# A tibble: 8,280 × 3\n   respondent_id voted_for_pres           pres_vote  \n           &lt;dbl&gt; &lt;fct&gt;                    &lt;fct&gt;      \n 1        200015 &lt;NA&gt;                     &lt;NA&gt;       \n 2        200022 Yes, voted for President LIBERTARIAN\n 3        200039 Yes, voted for President DEMOCRAT   \n 4        200046 Yes, voted for President DEMOCRAT   \n 5        200053 Yes, voted for President REPUBLICAN \n 6        200060 Yes, voted for President DEMOCRAT   \n 7        200084 Yes, voted for President REPUBLICAN \n 8        200091 &lt;NA&gt;                     &lt;NA&gt;       \n 9        200107 &lt;NA&gt;                     &lt;NA&gt;       \n10        200114 Yes, voted for President DEMOCRAT   \n# ℹ 8,270 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nI got the response labels from the survey questionnaire linked above.\n\n\n\n\n\n\n\n\nTip\n\n\n\nfactor() takes as its first argument the name of the column you would like to convert to a factor. You then specify which numbers you need to code as your values using the levels argument. Finally, you supply the more human-friendly name of those values in the labels argument.\n\n\nI now have a much cleaner version of my data set. Next, we need to exclude those respondents who did not vote for any Presidential candidate or who did not respond to the interviewer’s question about which candidate they voted for:\n\npres_voted_df &lt;- anes_df |&gt; \n  filter(voted_for_pres == \"Yes, voted for President\") |&gt; \n  drop_na(pres_vote)\n\npres_voted_df\n\n# A tibble: 5,877 × 3\n   respondent_id voted_for_pres           pres_vote  \n           &lt;dbl&gt; &lt;fct&gt;                    &lt;fct&gt;      \n 1        200022 Yes, voted for President LIBERTARIAN\n 2        200039 Yes, voted for President DEMOCRAT   \n 3        200046 Yes, voted for President DEMOCRAT   \n 4        200053 Yes, voted for President REPUBLICAN \n 5        200060 Yes, voted for President DEMOCRAT   \n 6        200084 Yes, voted for President REPUBLICAN \n 7        200114 Yes, voted for President DEMOCRAT   \n 8        200121 Yes, voted for President DEMOCRAT   \n 9        200138 Yes, voted for President DEMOCRAT   \n10        200152 Yes, voted for President REPUBLICAN \n# ℹ 5,867 more rows\n\n\nWe now have data on 5,877 individuals who voted for a Presidential candidate and provided their vote to the interviewer. Let’s take a look at the total number of votes each candidate received:\n\npres_voted_df |&gt; \n  count(pres_vote) |&gt; \n  ggplot(aes(x = n, y = reorder(pres_vote, n))) + \n  geom_col() + \n  theme_minimal() + \n  labs(x = \"Votes received\",\n       y = NULL)\n\n\n\n\n\n\n\nJoe Biden (the Democratic candidate) received the most votes among the ANES survey respondents. Let’s represent this as vote proportions so we can more easily compare it to the votes received by each candidate nationally:\n\npres_voted_df |&gt; \n  count(pres_vote) |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  ggplot(aes(x = prop, y = reorder(pres_vote, prop))) + \n  geom_col() + \n  theme_minimal() + \n  labs(x = \"Precentage of total votes\",\n       y = NULL) + \n  scale_x_continuous(labels = percent)\n\n\n\n\n\n\n\nThe population of votes cast\nSo, were they right? To answer this question, we need to get data on the total number of votes each Presidential candidate received in 2020. The MIT Election Data + Science Lab provides these returns to the public. To access their data, we will use the Harvard Dataverse API. We will access it using the R package dataverse.\n\n\n\n\n\n\nNote\n\n\n\nThe dataverse package accesses the Harvard Dataverse Application Programming Interface (API) in the background. To learn more about how to access this API directly, check out the Harvard Dataverse documentation.\n\n\nWe will be accessing the U.S. President 1976–2020 data set. To do this, we need three pieces of information:\n\nThe name of the file we want to download\nThe data set’s DOI\nThe data set’s format\n\nWe can get all of this information from the data set’s page on the Harvard Dataverse website.\n\npres_results_df &lt;- get_dataframe_by_name(\n  filename = \"1976-2020-president.tab\",\n  dataset = \"10.7910/DVN/42MVDX\",\n  server = \"dataverse.harvard.edu\",\n  original = T,\n  .f = readr::read_csv\n)\n\nThis code programmatically pulls the most up-to-date data set from the API. Once the MIT Election Lab publishes the 2024 Presidential Election data, you will only need to update the file name to be able to access it.\nWe are interested in looking at the 2020 Presidential Election, so we will transform our data to exclude all others. Also, these data are at the state-level. We need to aggregate them up to the national level.\nWe do both of these things in the following code chunk:\n\npres_results_2020_df &lt;- pres_results_df |&gt; \n  filter(year == 2020) |&gt; \n  group_by(party_simplified) |&gt; \n  summarise(candidatevotes = sum(candidatevotes)) |&gt; \n  ungroup()\n\npres_results_2020_df\n\n# A tibble: 4 × 2\n  party_simplified candidatevotes\n  &lt;chr&gt;                     &lt;dbl&gt;\n1 DEMOCRAT               81268908\n2 LIBERTARIAN             1797355\n3 OTHER                   1246094\n4 REPUBLICAN             74216146\n\n\nFinally, we will calculate the proportion of votes each candidate received to make it comparable to the survey results:\n\npres_results_national_df &lt;- pres_results_2020_df |&gt; \n  mutate(prop_pop = candidatevotes / sum(candidatevotes))\n\nggplot(pres_results_national_df, aes(x = prop_pop, y = reorder(party_simplified, prop_pop))) + \n  geom_col() +\n  theme_minimal() + \n  labs(x = \"Percentage of total votes\",\n       y = NULL) + \n  scale_x_continuous(labels = percent)\n\n\n\n\n\n\n\nThe MIT Election Lab folds the Greens party into the “other” category, whereas the ANES separates them out. To make these comparable, we need to fold the Greens votes into the “other” category. We can do this using the forcats package’s (loaded in with the tidyverse) fct_recode() function:\n\nanes_df &lt;- mutate(anes_df, pres_vote = fct_recode(pres_vote, OTHER = \"GREENS\"))\n\nanes_national_results &lt;- anes_df |&gt; \n  filter(voted_for_pres == \"Yes, voted for President\" & !is.na(pres_vote)) |&gt; \n  count(pres_vote) |&gt; \n  transmute(party_simplified = pres_vote, prop_survey = n / sum(n))\n\nNow we can compare these two:\n\npres_results_national_df |&gt; \n  left_join(anes_national_results, by = join_by(party_simplified)) |&gt; \n  pivot_longer(prop_pop:prop_survey) |&gt; \n  mutate(name = case_when(name == \"prop_pop\" ~ \"Population\",\n                          name == \"prop_survey\" ~ \"Survey\")) |&gt; \n  ggplot(aes(x = value, y = reorder(party_simplified, value), fill = name)) + \n  geom_col(position = \"dodge\") + \n  theme_minimal() + \n  labs(x = \"Percentage of total votes\",\n       y = NULL, \n       fill = NULL) + \n  scale_x_continuous(labels = percent)\n\n\n\n\n\n\n\nIt looks like the ANES did a fairly good job of capturing the US voting population’s behavior. The proportion of survey respondents who said they voted for each candidate (represented by the blue bar) is roughly equal to the proportion of votes won by each candidate (represented by the pink bar).\nOne interesting thing to note is that the survey did overstate support for Joe Biden and understated support for Donald Trump. We might see this despite having a representative sample. For example, people - when asked who they voted for - may be inclined to say they voted for the winner (regardless of who that winner was). Also, individuals may be hesitant to tell a pollster that they voted for Donald Trump given how divisive he and his campaign were.\nIt is; however, very likely that the ANES did not reach a representative sample of the US voting population. As we discussed above: this is very difficult (if not impossible) to do. ANES runs very good surveys precisely because they acknowledge and, to the best of their ability, account for this. Generally, surveys will compare the demographics of their respondents to those of the voting population (or population more generally). If they find that some individuals are under-represented in their sample (for example, young black women make up a smaller proportion of their sample than they make up in the population), they will make the responses of individuals who fit those demographics count for more than one response in their calculations. Similarly, if they find a demographic is over-represented in their sample, they will make their responses count for less than one response in their calculations. This practice is called weighting and it is standard across all major and respected surveys.",
    "crumbs": [
      "Content",
      "Session 2",
      "From Samples to the Population"
    ]
  },
  {
    "objectID": "content/slides/02-09-surveys.html#surveys",
    "href": "content/slides/02-09-surveys.html#surveys",
    "title": "From Surveys to Populations",
    "section": "Surveys",
    "text": "Surveys\n\nPopulations are very difficult to collect data on\n\nEven the census misses people!\n\nHappily, we can use surveys of a sample of our population to learn things about our population\nHowever, our ability to do this is conditional on how good our sample is\nWhat do I mean by “good”?"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#the-2024-us-presidential-election",
    "href": "content/slides/02-09-surveys.html#the-2024-us-presidential-election",
    "title": "From Surveys to Populations",
    "section": "The 2024 US Presidential Election",
    "text": "The 2024 US Presidential Election\n\nElections are preceded by a flood of surveys"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#surveys-1",
    "href": "content/slides/02-09-surveys.html#surveys-1",
    "title": "From Surveys to Populations",
    "section": "Surveys",
    "text": "Surveys\n\nSurveys are conducted on a subset (sample) of the population of interest\nOur population of interest: individuals who voted in the 2024 US Presidential Election"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#a-good-sample",
    "href": "content/slides/02-09-surveys.html#a-good-sample",
    "title": "From Surveys to Populations",
    "section": "A good sample",
    "text": "A good sample\n\nA good sample is a representative one\nHow closely does our sample reflect our population"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#parallel-worlds",
    "href": "content/slides/02-09-surveys.html#parallel-worlds",
    "title": "From Surveys to Populations",
    "section": "Parallel worlds",
    "text": "Parallel worlds\n\nRemember back to last session on experiments\nIn an ideal world, we would be able to create two parallel worlds (one with the treatment, one held as our control)\n\nOne version of the election booth run without monitors (the control)\nOne version with monitors (the treatment)\n\nThese worlds are perfectly identical to each other prior to treatment\nWe cannot do this :("
  },
  {
    "objectID": "content/slides/02-09-surveys.html#the-next-best-thing",
    "href": "content/slides/02-09-surveys.html#the-next-best-thing",
    "title": "From Surveys to Populations",
    "section": "The next best thing",
    "text": "The next best thing\n\nOur next best option is to create two groups that were as identical to one another as possible prior to treatment\nIf they are (almost) identical, differences between their group-wide outcomes can be attributed to the treatment\nOne good way of getting two (almost) identical groups is to assign individuals to those groups randomly\n\nThink back to our 1,000 hypothetical people!"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#randomization",
    "href": "content/slides/02-09-surveys.html#randomization",
    "title": "From Surveys to Populations",
    "section": "Randomization",
    "text": "Randomization\n\nRandomization continues to pop its chaotic head up\nWe can use it to create a sample that is (almost) identical to our population, on average\nDrawing randomly from our population increases our chances of ending up with a sample that reflects that population\nThis would be referred to as a representative sample"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#random-sampling",
    "href": "content/slides/02-09-surveys.html#random-sampling",
    "title": "From Surveys to Populations",
    "section": "Random sampling",
    "text": "Random sampling\n\nAll individuals in the population need to have an equal chance of being selected for the sample\n\nIf this holds, you have a pure random sample\n\nThis is really hard to do!\n\nHow likely were you to answer the pollster’s unknown number, calling you in the middle of the day?\nEven if you did answer, how likely were you to answer all their questions?"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#to-illustrate",
    "href": "content/slides/02-09-surveys.html#to-illustrate",
    "title": "From Surveys to Populations",
    "section": "To illustrate",
    "text": "To illustrate\nCountries’ GDP in 2022:"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#countries-gdp",
    "href": "content/slides/02-09-surveys.html#countries-gdp",
    "title": "From Surveys to Populations",
    "section": "Countries’ GDP",
    "text": "Countries’ GDP\nI want to estimate the average GDP across all countries in 2022.\n\nI send out a survey to all countries’ Departments of Statistics and ask for their GDP figures for 2022.\nI get 60 responses:\n\n\nsample_df &lt;- gdp_df |&gt; \n  drop_na(sample_value) |&gt; \n  sample_n(size = 60) |&gt; \n  transmute(country, gdp = sample_value)\n\nsample_df\n\n# A tibble: 60 × 2\n   country                    gdp\n   &lt;chr&gt;                    &lt;dbl&gt;\n 1 Sweden           590409594949.\n 2 Moldova           14510490660.\n 3 Turkmenistan      56542857143.\n 4 Guinea            20999229260.\n 5 Nepal             41182939601.\n 6 Colombia         345329875079.\n 7 Jordan            48653381831.\n 8 Curacao            3073840325.\n 9 Belize             2830507576.\n10 Congo, Dem. Rep.  65801547620.\n# ℹ 50 more rows"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#countries-gdp-1",
    "href": "content/slides/02-09-surveys.html#countries-gdp-1",
    "title": "From Surveys to Populations",
    "section": "Countries’ GDP",
    "text": "Countries’ GDP\nI now calculate the average of these responses, which I find to be:\n\nsample_df |&gt; \n  summarise(avg_gdp = scales::dollar(mean(gdp, na.rm = T)))\n\n# A tibble: 1 × 1\n  avg_gdp         \n  &lt;chr&gt;           \n1 $204,457,683,828\n\n\nNow, imagine that we knew definitively that it was NA. Why such a large difference?"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#non-response-bias",
    "href": "content/slides/02-09-surveys.html#non-response-bias",
    "title": "From Surveys to Populations",
    "section": "Non-response bias",
    "text": "Non-response bias\nPoorer countries are far less likely to be able or willing to provide these economic data to academics or international organizations.\n\nThey tend to be underrepresented in a lot of data\n\nMy sample was biased against poorer countries.\n\nThey were not equally likely to respond to my request for data as rich countries"
  },
  {
    "objectID": "content/slides/02-09-surveys.html#large-numbers",
    "href": "content/slides/02-09-surveys.html#large-numbers",
    "title": "From Surveys to Populations",
    "section": "Large numbers",
    "text": "Large numbers\n\nRandomization isn’t enough: we also need to draw a sufficiently large sample from our population\n\nOne person pulled randomly from the class isn’t going to be very reflective of the class!"
  },
  {
    "objectID": "content/03-01-wrangling.html#lengthening-messy-data",
    "href": "content/03-01-wrangling.html#lengthening-messy-data",
    "title": "Data Wrangling",
    "section": "Lengthening messy data",
    "text": "Lengthening messy data\nThe World Bank provides us with access to a trove of official country- and sub-national level data that are very useful for political analysis. I use their data in nearly all of my research. Sadly, they tend to provide their data in a messy format. We will now collect that messy data so we can learn how to tidy it up.\nTo access their data and some wonderful data visualizations, you can head over to their data portal: https://data.worldbank.org/. From there, you can browse which data sets they have or search for ones you are interested in.\nWe are going to start by collecting data on countries’ GDP per capita (current US$). It can be accessed here: https://data.worldbank.org/indicator/NY.GDP.PCAP.CD. You can download the data directly from this web page, save it in the appropriate place in your RProject, and read it in from there.\n\n\n\n\n\n\nNote\n\n\n\nThis process is similar to the one we used in Session 2: From Samples to the Population.\n\n\nI saved the CSV in the data folder (which is the in the content folder because this is a website), so I will use here::here() to adaptively find the correct file path and read the file in using read_csv().\n\ngdp_per_cap_raw &lt;- read_csv(here::here(\"content\", \"data\", \n                                       \"API_NY.GDP.PCAP.CD_DS2_en_csv_v2_76.csv\"))\n\nAfter running this yourself, you will see an ominous warning. Let’s take a look at our data:\n\ngdp_per_cap_raw\n\n# A tibble: 268 × 3\n   `Data Source`               `World Development Indicators` ...3              \n   &lt;chr&gt;                       &lt;chr&gt;                          &lt;chr&gt;             \n 1 Last Updated Date           2024-12-16                      &lt;NA&gt;             \n 2 Country Name                Country Code                   \"Indicator Name,I…\n 3 Aruba                       ABW                            \"GDP per capita (…\n 4 Africa Eastern and Southern AFE                            \"GDP per capita (…\n 5 Afghanistan                 AFG                            \"GDP per capita (…\n 6 Africa Western and Central  AFW                            \"GDP per capita (…\n 7 Angola                      AGO                            \"GDP per capita (…\n 8 Albania                     ALB                            \"GDP per capita (…\n 9 Andorra                     AND                            \"GDP per capita (…\n10 Arab World                  ARB                            \"GDP per capita (…\n# ℹ 258 more rows\n\n\nWe have only three columns, none of which appear to have the right names. It also looks like the first few rows may, in fact, not be rows in our data set. Rather, they are metadata, including the last time the data were updated.\nThe second row in our data set looks like the real column headings. This is good! We can skip the first few rows using read_csv()’s skip argument. Just provide it with the number of rows you want to skip when reading in the CSV.\n\ngdp_per_cap_raw &lt;- read_csv(here::here(\"content\", \"data\", \n                                       \"API_NY.GDP.PCAP.CD_DS2_en_csv_v2_76.csv\"),\n                            skip = 3)\n\ngdp_per_cap_raw\n\n# A tibble: 266 × 69\n   `Country Name` `Country Code` `Indicator Name` `Indicator Code` `1960` `1961`\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;            &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;\n 1 Aruba          ABW            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 2 Africa Easter… AFE            GDP per capita … NY.GDP.PCAP.CD     186.   187.\n 3 Afghanistan    AFG            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 4 Africa Wester… AFW            GDP per capita … NY.GDP.PCAP.CD     122.   127.\n 5 Angola         AGO            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 6 Albania        ALB            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 7 Andorra        AND            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n 8 Arab World     ARB            GDP per capita … NY.GDP.PCAP.CD      NA    213.\n 9 United Arab E… ARE            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n10 Argentina      ARG            GDP per capita … NY.GDP.PCAP.CD      NA     NA \n# ℹ 256 more rows\n# ℹ 63 more variables: `1962` &lt;dbl&gt;, `1963` &lt;dbl&gt;, `1964` &lt;dbl&gt;, `1965` &lt;dbl&gt;,\n#   `1966` &lt;dbl&gt;, `1967` &lt;dbl&gt;, `1968` &lt;dbl&gt;, `1969` &lt;dbl&gt;, `1970` &lt;dbl&gt;,\n#   `1971` &lt;dbl&gt;, `1972` &lt;dbl&gt;, `1973` &lt;dbl&gt;, `1974` &lt;dbl&gt;, `1975` &lt;dbl&gt;,\n#   `1976` &lt;dbl&gt;, `1977` &lt;dbl&gt;, `1978` &lt;dbl&gt;, `1979` &lt;dbl&gt;, `1980` &lt;dbl&gt;,\n#   `1981` &lt;dbl&gt;, `1982` &lt;dbl&gt;, `1983` &lt;dbl&gt;, `1984` &lt;dbl&gt;, `1985` &lt;dbl&gt;,\n#   `1986` &lt;dbl&gt;, `1987` &lt;dbl&gt;, `1988` &lt;dbl&gt;, `1989` &lt;dbl&gt;, `1990` &lt;dbl&gt;, …\n\n\nThat looks better! We have now read in the data set itself, skipping those rows of metadata.\nThe resulting data set is a wide one. Each observation is a country or region. The first two columns provide information on the country. The third and fourth describe the indicator. All other columns provide each country’s GDP per capita in all years from 1960 to 2023.\nNow, imagine you want to compare a country’s GDP per capita across many years. For example, you want to know how Australians’ wealth has grown over time. This is very difficult to do with this current format. We would need to work with all columns from 1960 to 2023!\nTo make these data easier to work with, we will lengthen the data set. Instead of each observation (row) describing a country, we will make each observation describe a country-year.\nTo do this, we need to use pivot_longer(). We need to let it know which columns we want to transpose using the col argument. Because the end year for these data will change each year I want to pull and clean up this data set (for example, next year the last column will be 2024, not 2023), I will use ! to negate the columns I don’t want to transpose. This code will, therefore, work after each annual update to the data set.\n\ngdp_per_cap &lt;- gdp_per_cap_raw |&gt; \n  pivot_longer(cols = !c(`Country Name`:`Indicator Code`),\n               names_to = \"year\",\n               values_to = \"gdp_per_cap\")\n\ngdp_per_cap\n\n# A tibble: 17,290 × 6\n   `Country Name` `Country Code` `Indicator Name`         `Indicator Code` year \n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;chr&gt;            &lt;chr&gt;\n 1 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1960 \n 2 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1961 \n 3 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1962 \n 4 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1963 \n 5 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1964 \n 6 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1965 \n 7 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1966 \n 8 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1967 \n 9 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1968 \n10 Aruba          ABW            GDP per capita (current… NY.GDP.PCAP.CD   1969 \n# ℹ 17,280 more rows\n# ℹ 1 more variable: gdp_per_cap &lt;dbl&gt;\n\n\nI have also told pivot_longer() what to call the column containing the previous column names (using names_to) and the column containing the values (using values_to).\nYou might have noticed that I needed to include some back ticks when referencing those column names. This is because these column names do not follow the rules put in place to help you work with R. Column names must:\n\nNot include spaces\nNot start with numbers or special characters\n\nThey should also be:\n\nShort\nMeaningful\nConsistently formatted\n\nThe World Bank uses spaces in its column names. We need to remove those so we can more easily work with them in R. Happily, the very handy janitor R package is here for all of your cleaning needs!\nI use the clean_names() function to ensure names are clean and consistent:\n\ngdp_per_cap &lt;- clean_names(gdp_per_cap)\ngdp_per_cap\n\n# A tibble: 17,290 × 6\n   country_name country_code indicator_name     indicator_code year  gdp_per_cap\n   &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;          &lt;chr&gt;       &lt;dbl&gt;\n 1 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1960           NA\n 2 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1961           NA\n 3 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1962           NA\n 4 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1963           NA\n 5 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1964           NA\n 6 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1965           NA\n 7 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1966           NA\n 8 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1967           NA\n 9 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1968           NA\n10 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD 1969           NA\n# ℹ 17,280 more rows\n\n\nGreat! We’re almost there. Next, we need to check that R has correctly classified our data types. For example, we want to make sure that the years are coded as numbers not strings of characters.\n\nglimpse(gdp_per_cap)\n\nRows: 17,290\nColumns: 6\n$ country_name   &lt;chr&gt; \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"…\n$ country_code   &lt;chr&gt; \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\",…\n$ indicator_name &lt;chr&gt; \"GDP per capita (current US$)\", \"GDP per capita (curren…\n$ indicator_code &lt;chr&gt; \"NY.GDP.PCAP.CD\", \"NY.GDP.PCAP.CD\", \"NY.GDP.PCAP.CD\", \"…\n$ year           &lt;chr&gt; \"1960\", \"1961\", \"1962\", \"1963\", \"1964\", \"1965\", \"1966\",…\n$ gdp_per_cap    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\n\nHmm, it does appear to have read the years in as characters. Why?\n\nunique(gdp_per_cap$year)\n\n [1] \"1960\"  \"1961\"  \"1962\"  \"1963\"  \"1964\"  \"1965\"  \"1966\"  \"1967\"  \"1968\" \n[10] \"1969\"  \"1970\"  \"1971\"  \"1972\"  \"1973\"  \"1974\"  \"1975\"  \"1976\"  \"1977\" \n[19] \"1978\"  \"1979\"  \"1980\"  \"1981\"  \"1982\"  \"1983\"  \"1984\"  \"1985\"  \"1986\" \n[28] \"1987\"  \"1988\"  \"1989\"  \"1990\"  \"1991\"  \"1992\"  \"1993\"  \"1994\"  \"1995\" \n[37] \"1996\"  \"1997\"  \"1998\"  \"1999\"  \"2000\"  \"2001\"  \"2002\"  \"2003\"  \"2004\" \n[46] \"2005\"  \"2006\"  \"2007\"  \"2008\"  \"2009\"  \"2010\"  \"2011\"  \"2012\"  \"2013\" \n[55] \"2014\"  \"2015\"  \"2016\"  \"2017\"  \"2018\"  \"2019\"  \"2020\"  \"2021\"  \"2022\" \n[64] \"2023\"  \"...69\"\n\n\nLooking at all unique values included in the year column, we can see the culprit: \"...69\". It looks like the CSV includes a rouge last column with no data in it. read_csv() read that column in and coded all its values as NA:\n\ngdp_per_cap |&gt; \n  filter(year == \"...69\") |&gt; \n  distinct(gdp_per_cap)\n\n# A tibble: 1 × 1\n  gdp_per_cap\n        &lt;dbl&gt;\n1          NA\n\n\nWe can simply filter this out of our data set to get rid of it and convert the remaining values to numbers using mutate():\n\ngdp_per_cap &lt;- gdp_per_cap |&gt; \n  filter(year != \"...69\") |&gt; \n  mutate(year = as.numeric(year))\ngdp_per_cap\n\n# A tibble: 17,024 × 6\n   country_name country_code indicator_name     indicator_code  year gdp_per_cap\n   &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n 1 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1960          NA\n 2 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1961          NA\n 3 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1962          NA\n 4 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1963          NA\n 5 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1964          NA\n 6 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1965          NA\n 7 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1966          NA\n 8 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1967          NA\n 9 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1968          NA\n10 Aruba        ABW          GDP per capita (c… NY.GDP.PCAP.CD  1969          NA\n# ℹ 17,014 more rows\n\n\nWe now have a nice and clean data set that is easy to work with. Let’s take a look at Australia’s growth over time:\n\ngdp_per_cap |&gt; \n  filter(country_name == \"Australia\") |&gt; \n  ggplot(aes(x = year, y = gdp_per_cap)) + \n  geom_line() + \n  geom_point(size = 1) + \n  theme_minimal() + \n  labs(x = \"Year\",\n       y = \"GDP per capita (current US$)\") + \n  scale_y_continuous(labels = dollar)",
    "crumbs": [
      "Content",
      "Session 3",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "content/03-01-wrangling.html#widening-messy-data",
    "href": "content/03-01-wrangling.html#widening-messy-data",
    "title": "Data Wrangling",
    "section": "Widening messy data",
    "text": "Widening messy data\nSometimes you want to widen your data. tidyr provides a similar function, pivot_wider(), to do just this. Let’s start by getting some long data. We will again collect these data from the World Bank, but this time we will use wbstats to access it directly through the API.\nWe will add to our data set information on each country’s average life expectancy (ID: SP.DYN.LE00.IN).\n\ngapminder_raw &lt;- wb_data(\n  indicator = c(\"SP.DYN.LE00.IN\", \"NY.GDP.PCAP.CD\"),\n  return_wide = F\n)\n\ngapminder_raw\n\n# A tibble: 27,776 × 11\n   indicator_id   indicator     iso2c iso3c country  date value unit  obs_status\n   &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     \n 1 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2023  NA   &lt;NA&gt;  &lt;NA&gt;      \n 2 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2022  62.9 &lt;NA&gt;  &lt;NA&gt;      \n 3 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2021  62.0 &lt;NA&gt;  &lt;NA&gt;      \n 4 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2020  62.6 &lt;NA&gt;  &lt;NA&gt;      \n 5 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2019  63.6 &lt;NA&gt;  &lt;NA&gt;      \n 6 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2018  63.1 &lt;NA&gt;  &lt;NA&gt;      \n 7 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2017  63.0 &lt;NA&gt;  &lt;NA&gt;      \n 8 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2016  63.1 &lt;NA&gt;  &lt;NA&gt;      \n 9 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2015  62.7 &lt;NA&gt;  &lt;NA&gt;      \n10 SP.DYN.LE00.IN Life expecta… AF    AFG   Afghan…  2014  62.5 &lt;NA&gt;  &lt;NA&gt;      \n# ℹ 27,766 more rows\n# ℹ 2 more variables: footnote &lt;chr&gt;, last_updated &lt;date&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, the wonderful wb_data() function will return data to you in a clean (and wide) format. Therefore, to illustrate how to wrangle these data, I need to include the return_wide = F argument.\n\n\nWe now have data on each country-year-indicator. For example, let’s look at what we have for Afghanistan in 2018:\n\ngapminder_raw |&gt; \n  filter(country == \"Afghanistan\", date == 2018)\n\n# A tibble: 2 × 11\n  indicator_id   indicator      iso2c iso3c country  date value unit  obs_status\n  &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     \n1 SP.DYN.LE00.IN Life expectan… AF    AFG   Afghan…  2018  63.1 &lt;NA&gt;  &lt;NA&gt;      \n2 NY.GDP.PCAP.CD GDP per capit… AF    AFG   Afghan…  2018 491.  &lt;NA&gt;  &lt;NA&gt;      \n# ℹ 2 more variables: footnote &lt;chr&gt;, last_updated &lt;date&gt;\n\n\nThis is difficult to work with. For example, think about how you would plot each country’s GDP per capita against its average life expectancy for a single year.\nWe need to make these data wider. We want our observations to be country-year. We will therefore have a column for each country-year’s GDP per capita and its average life expectancy.\npivot_wider() works by creating a new column for each unique value in the column you tell it to draws names from (using the names_from argument). It will then populate that column with the corresponding value from the column you tell it to draw values from (using the values_from argument). It preserves all unique values in the other rows.\nThis is a little easier to understand in practice. Let’s step through widening our Gapminder data. I’ll start by diving straight in:\n\npivot_wider(gapminder_raw, names_from = indicator_id, values_from = value)\n\n# A tibble: 27,776 × 11\n   indicator    iso2c iso3c country  date unit  obs_status footnote last_updated\n   &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;date&gt;      \n 1 Life expect… AF    AFG   Afghan…  2023 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 2 Life expect… AF    AFG   Afghan…  2022 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 3 Life expect… AF    AFG   Afghan…  2021 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 4 Life expect… AF    AFG   Afghan…  2020 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 5 Life expect… AF    AFG   Afghan…  2019 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 6 Life expect… AF    AFG   Afghan…  2018 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 7 Life expect… AF    AFG   Afghan…  2017 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 8 Life expect… AF    AFG   Afghan…  2016 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 9 Life expect… AF    AFG   Afghan…  2015 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n10 Life expect… AF    AFG   Afghan…  2014 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n# ℹ 27,766 more rows\n# ℹ 2 more variables: SP.DYN.LE00.IN &lt;dbl&gt;, NY.GDP.PCAP.CD &lt;dbl&gt;\n\n\nWe now have two new columns: SP.DYN.LE00.IN for average life expectancy, and NY.GDP.PCAP.CD for GDP per capita. These columns contain the corresponding values for each country-year’s average life expectancy and GDP per capita.\nHowever, something has gone wrong. Our wider data set should have fewer rows than our longer one. This is because we are hoping to have one row for each country-year containing information on its average life expectancy and GDP per capita for each year, rather than two rows for each country-year (one for each indicator). Why is this happening?\nWell, the World Bank data set includes unique information about each indicator in the indicator column. Because this is country-year-indicator level information, pivot_wider() - in an attempt to preserve that information - creates a country-year-indicator level data set. To tidy and widen our data set, we need to remove all country-year-indicator level information and then pivot it.\n\ngapminder &lt;- gapminder_raw |&gt;\n  select(!indicator) |&gt; \n  pivot_wider(names_from = indicator_id, values_from = value)\ngapminder\n\n# A tibble: 13,897 × 10\n   iso2c iso3c country      date unit  obs_status footnote last_updated\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;date&gt;      \n 1 AF    AFG   Afghanistan  2023 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 2 AF    AFG   Afghanistan  2022 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 3 AF    AFG   Afghanistan  2021 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 4 AF    AFG   Afghanistan  2020 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 5 AF    AFG   Afghanistan  2019 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 6 AF    AFG   Afghanistan  2018 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 7 AF    AFG   Afghanistan  2017 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 8 AF    AFG   Afghanistan  2016 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n 9 AF    AFG   Afghanistan  2015 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n10 AF    AFG   Afghanistan  2014 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16  \n# ℹ 13,887 more rows\n# ℹ 2 more variables: SP.DYN.LE00.IN &lt;dbl&gt;, NY.GDP.PCAP.CD &lt;dbl&gt;\n\n\nMuch better! We now have a data set at the country-year level. Each country-year has information on its average life expectancy and GDP per capita.\nThose variable names are hard to work with and not very meaningful, so we need to clean them up:\n\ngapminder &lt;- rename(gapminder, avg_life_exp = SP.DYN.LE00.IN, gdp_per_cap = NY.GDP.PCAP.CD)\ngapminder\n\n# A tibble: 13,897 × 10\n   iso2c iso3c country  date unit  obs_status footnote last_updated avg_life_exp\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;date&gt;              &lt;dbl&gt;\n 1 AF    AFG   Afghan…  2023 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           NA  \n 2 AF    AFG   Afghan…  2022 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           62.9\n 3 AF    AFG   Afghan…  2021 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           62.0\n 4 AF    AFG   Afghan…  2020 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           62.6\n 5 AF    AFG   Afghan…  2019 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           63.6\n 6 AF    AFG   Afghan…  2018 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           63.1\n 7 AF    AFG   Afghan…  2017 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           63.0\n 8 AF    AFG   Afghan…  2016 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           63.1\n 9 AF    AFG   Afghan…  2015 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           62.7\n10 AF    AFG   Afghan…  2014 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;     2024-12-16           62.5\n# ℹ 13,887 more rows\n# ℹ 1 more variable: gdp_per_cap &lt;dbl&gt;\n\n\nThere is also a fair bit of information in this data set that I do not need, so I will remove it and reorder the columns so they are easier to view:\n\ngapminder &lt;- select(gapminder, country, iso3c, date, avg_life_exp, gdp_per_cap)\ngapminder\n\n# A tibble: 13,897 × 5\n   country     iso3c  date avg_life_exp gdp_per_cap\n   &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1 Afghanistan AFG    2023         NA          416.\n 2 Afghanistan AFG    2022         62.9        357.\n 3 Afghanistan AFG    2021         62.0        356.\n 4 Afghanistan AFG    2020         62.6        511.\n 5 Afghanistan AFG    2019         63.6        497.\n 6 Afghanistan AFG    2018         63.1        491.\n 7 Afghanistan AFG    2017         63.0        525.\n 8 Afghanistan AFG    2016         63.1        522.\n 9 Afghanistan AFG    2015         62.7        566.\n10 Afghanistan AFG    2014         62.5        625.\n# ℹ 13,887 more rows\n\n\nWe now have a nice, clean, and wide data set. You can easily look at the relationship between your two variables of interest over time:\n\ngapminder |&gt; \n  filter(date %in% 2017:2022) |&gt; \n  ggplot(aes(x = log(gdp_per_cap), y = avg_life_exp)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = F) + \n  facet_wrap(~ date) + \n  theme_minimal() + \n  labs(x = \"GDP per capita (logged current US$)\",\n       y = \"Average life expectancy\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nfacet_wrap() creates a unique plot for each value in the column you specify. Here, I have used it to create six plots for each of the six years from 2017 to 2022.",
    "crumbs": [
      "Content",
      "Session 3",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "content/03-01-wrangling.html#exercises",
    "href": "content/03-01-wrangling.html#exercises",
    "title": "Data Wrangling",
    "section": "Exercises",
    "text": "Exercises\nName three different types of cases you can use through janitor::clean_names() to format your column names.\n\n\n\n\n\n\nHINT\n\n\n\nRead the argument descriptions in the clean_names() function documentation (by running ?clean_names in your console.\n\n\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\nHere is the full list:\nc(\"snake\", \"small_camel\", \"big_camel\",\n  \"screaming_snake\", \"parsed\", \"mixed\", \"lower_upper\", \"upper_lower\",\n  \"swap\", \"all_caps\", \"lower_camel\", \"upper_camel\", \"internal_parsing\",\n  \"none\", \"flip\", \"sentence\", \"random\", \"title\")\nI like the default (snake case), but other common ones include big camel and all caps.\n\n\n\nHow would you lengthen the gapminder data set we created earlier?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\ngapminder |&gt; \n  pivot_longer(cols = avg_life_exp:gdp_per_cap, names_to = \"indicator\")\n\n# A tibble: 27,794 × 5\n   country     iso3c  date indicator    value\n   &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1 Afghanistan AFG    2023 avg_life_exp  NA  \n 2 Afghanistan AFG    2023 gdp_per_cap  416. \n 3 Afghanistan AFG    2022 avg_life_exp  62.9\n 4 Afghanistan AFG    2022 gdp_per_cap  357. \n 5 Afghanistan AFG    2021 avg_life_exp  62.0\n 6 Afghanistan AFG    2021 gdp_per_cap  356. \n 7 Afghanistan AFG    2020 avg_life_exp  62.6\n 8 Afghanistan AFG    2020 gdp_per_cap  511. \n 9 Afghanistan AFG    2019 avg_life_exp  63.6\n10 Afghanistan AFG    2019 gdp_per_cap  497. \n# ℹ 27,784 more rows",
    "crumbs": [
      "Content",
      "Session 3",
      "Data Wrangling"
    ]
  },
  {
    "objectID": "content/01-01-visualization.html",
    "href": "content/01-01-visualization.html",
    "title": "Introducing R Through Data Visualization",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(\"tidyverse\")\n\n\n\n\n\nlibrary(tidyverse)\n\nThis section focuses on introducing you to some new R skills. You will learn how to create your own data visualizations using real-world data.\nTo guide this process, we will use data visualization to answer the following question:\n\nDo cars with big engines use more fuel than cars with small engines?\n\nBefore we get started, answer the following questions:\n\nWhat do you think the answer to this question is?\nHow would you prove your answer? What information about cars would you need?\n\n\n\n\n\n\n\nNote\n\n\n\nI borrow (read: steal) heavily from Hadley Wickham’s R4DSin this and other introductory R sessions. This is a fantastic resource for anyone learning R. I encourage you to use it if you ever get stuck.\n\n\nData visualization is a critical skill for data analysis. You can learn a lot more about your data, including the relationships buried within them, from plots than you can from looking at the raw numbers (and even from complicated statistical models). We will use data visualization throughout this course to learn about our data.\nFor example, we can answer our question above using the following plot:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  theme(\n    legend.position = \"bottom\",\n    panel.grid = element_blank(),\n    panel.background = element_blank(),\n    plot.title.position = \"plot\",\n    plot.title = element_text(face = \"bold\")\n  ) + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )\n\n\n\n\n\n\n\nWe will now step through how to create this graph using R. During this explanation, you will be introduced to some fundamental elements of R.",
    "crumbs": [
      "Content",
      "Session 1",
      "Introducing R Through Data Visualization"
    ]
  },
  {
    "objectID": "content/01-01-visualization.html#set-up",
    "href": "content/01-01-visualization.html#set-up",
    "title": "Introducing R Through Data Visualization",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(\"tidyverse\")\n\n\n\n\n\nlibrary(tidyverse)\n\nThis section focuses on introducing you to some new R skills. You will learn how to create your own data visualizations using real-world data.\nTo guide this process, we will use data visualization to answer the following question:\n\nDo cars with big engines use more fuel than cars with small engines?\n\nBefore we get started, answer the following questions:\n\nWhat do you think the answer to this question is?\nHow would you prove your answer? What information about cars would you need?\n\n\n\n\n\n\n\nNote\n\n\n\nI borrow (read: steal) heavily from Hadley Wickham’s R4DSin this and other introductory R sessions. This is a fantastic resource for anyone learning R. I encourage you to use it if you ever get stuck.\n\n\nData visualization is a critical skill for data analysis. You can learn a lot more about your data, including the relationships buried within them, from plots than you can from looking at the raw numbers (and even from complicated statistical models). We will use data visualization throughout this course to learn about our data.\nFor example, we can answer our question above using the following plot:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  theme(\n    legend.position = \"bottom\",\n    panel.grid = element_blank(),\n    panel.background = element_blank(),\n    plot.title.position = \"plot\",\n    plot.title = element_text(face = \"bold\")\n  ) + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )\n\n\n\n\n\n\n\nWe will now step through how to create this graph using R. During this explanation, you will be introduced to some fundamental elements of R.",
    "crumbs": [
      "Content",
      "Session 1",
      "Introducing R Through Data Visualization"
    ]
  },
  {
    "objectID": "content/01-01-visualization.html#loading-in-and-exploring-your-data",
    "href": "content/01-01-visualization.html#loading-in-and-exploring-your-data",
    "title": "Introducing R Through Data Visualization",
    "section": "Loading in and exploring your data",
    "text": "Loading in and exploring your data\nFirst, we need to load into our R session the R packages we will use. Today, we will be using the R packages contained within the tidyverse.\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\nTip\n\n\n\nAlways load your packages into your R session at the top of your R script. These scripts run from top to bottom. Loading necessary libraries in at the start ensures you don’t get annoying, missing package errors later on.\n\n\nNext, we need to load in the data we will be using. The mpg data set (which includes lots of information on various car models) comes as part of the ggplot2 R package, which we loaded in with the tidyverse. You can access the data set by running the following:\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe will learn how to load your own data in later in the course.\n\n\nThis data set provides us with information on several different models of cars. Importantly, it includes information on each model’s engine size and average fuel use. We will use the following two variables to answer our question:\n\ndispl: engine displacement, in litres\nhwy: highway miles per gallon\n\n\n\n\n\n\n\nTip\n\n\n\nYou can learn more detail about this data set by running ?mpg from your console.\n\n\nEngine displacement is a useful proxy for a car’s engine size. The larger its displacement, the larger the engine. Similarly, the number of gallons of fuel the car uses on the highway is a useful proxy for its fuel efficiency.\nReturning to our question, do cars with big engines use more fuel than cars with small engines?, what is your hypothesis framed in terms of these two variables?\n\n\n\n\n\n\nHere’s mine:\n\n\n\n\n\nCars with larger engines will travel fewer miles on the highway for each gallon of fuel used than cars with smaller engines.\n\n\n\nExercise\nHow many rows are in mpg? How many columns?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\nThe number of rows and columns are printed at the top of the mpg output. There are 234 rows and 11 columns.\nAlternatively, you can run the following:\n\nnrow(mpg)\n\n[1] 234\n\nncol(mpg)\n\n[1] 11\n\n\n\n\n\nWhat does the drv variable describe?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\nFind the variable description by running the following:\n\n?mpg",
    "crumbs": [
      "Content",
      "Session 1",
      "Introducing R Through Data Visualization"
    ]
  },
  {
    "objectID": "content/01-01-visualization.html#plotting-your-data",
    "href": "content/01-01-visualization.html#plotting-your-data",
    "title": "Introducing R Through Data Visualization",
    "section": "Plotting your data",
    "text": "Plotting your data\nNext, we need to plot our data. We will use the ggplot2 package to do this. ggplot2 is a wonderfully intuitive and flexible data visualization tool. It is used widely.\nggplot2 works by building up data visualizations in layers. We will start with our blank canvas:\n\nggplot(data = mpg)\n\n\n\n\n\n\n\nHere, we have run the ggplot() function. We have included one argument, data. This is the data frame that includes all the data we want to visualize.\nNext, we need to let ggplot() know which variables we would like to visualize and where we would like them to go. We do this through ggplot()’s mapping argument:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\nggplot() has now added some structure to our blank canvas. The displ variable is mapped onto the x-axis and the hwy variable is mapped to the y-axis. The mapping argument took a function, aes(), as its value. These are the aesthetics of your plot.\nNext, we need to visualize each data point. We want to produce a scatter plot, so we will add the relevant `ggplot` geometric object to our plot:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point()\n\n\n\n\n\n\n\nAll geometric objects start with geom_. Here are some examples:\n\ngeom_line() plots a line graph\ngeom_col() plots a column graph\ngeom_histogram() plots a histogram.\n\nWe now have a basic plot of our data. We can see a distinct relationship between a car’s engine size and its fuel use: cars with larger engines tend to travel fewer miles on the highway for each gallon of fuel than cars with smaller engines. This supports my hypothesis. Happy days!\nWe can even use ggplot() to visualize this general trend:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nHere, I have used geom_smooth to add a line to my plot that summarizes the relationship between our two variables. I asked it to draw a straight line by setting the argument method to \"lm\" (which stands for linear model).\n\n\n\n\n\n\nNote\n\n\n\nWe will talk a lot more about linear models during this course. Sit tight!\n\n\nAlthough this general trend is interesting, I suspect there are some important differences in this relationship between the different classes of cars. We can quickly check if this is the case by adding a visual cue of those different classes to our plot:\nFirst, I will colour each car’s data point based on its class:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = class)) + \n  geom_point()\n\n\n\n\n\n\n\nNote that I have introduced a new aesthetic to the model: colour. In doing so, I have told ggplot() to vary each data point’s colour based on its class. Each car is classified into one of the following seven classes:\n\n\n# A tibble: 7 × 1\n  class     \n  &lt;chr&gt;     \n1 compact   \n2 midsize   \n3 suv       \n4 2seater   \n5 minivan   \n6 pickup    \n7 subcompact\n\n\n\n\n\n\n\n\nNote\n\n\n\nI, an Australian, am not afraid of my “u”s. Nor, is R! Both American English and “ahem” ~ proper ~ English work in R. For example, you can substitute my colour for color.\n\n\nWe can extend this grouping to all of our layers:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = class)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nSimiarly, we can isolate which aesthetics apply to which layers by moving the aes() mapping from ggplot() to the specific layer to which we would like to apply it. Remember, ggplot2 is very flexible!\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(aes(colour = class)) + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll aesthetics supplied to the top ggplot() function will be inherited by the layers that proceed it unless you specify otherwise.\n\n\nExercise\nMake a scatter plot of hwy vs cyl.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nggplot(mpg, mapping = aes(x = hwy, y = cyl)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\nWhat happens if you make a scatter plot of class vs drv? Why is the plot not useful?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\nScatter plots are best used to visualize the relationship between two continuous variables. These variables have an inherent order to them, allowing us to see how the relationship changes as each grows or shrinks. class and drv are unordered categorical variables, so their order in relation to each other is not meaningful.\n\nggplot(mpg, mapping = aes(x = class, y = drv)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\nWhy does the following give an error and how would you fix it?\n\nggplot(data = mpg) + \n  geom_point()\n\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\n\n\n\nAlways read error messages carefully. They often tell you - in plain language - what the problem is and how to fix it. Here, we can see that “geom_point() requires the following missing aesthetics: x and y”. So, to fix it, we need to supply those aesthetics. For example:\n\nggplot(mpg, mapping = aes(x = hwy, y = cyl)) + \n  geom_point()",
    "crumbs": [
      "Content",
      "Session 1",
      "Introducing R Through Data Visualization"
    ]
  },
  {
    "objectID": "content/01-01-visualization.html#styling-your-plot",
    "href": "content/01-01-visualization.html#styling-your-plot",
    "title": "Introducing R Through Data Visualization",
    "section": "Styling your plot",
    "text": "Styling your plot\nYou have now learnt how to plot your data using ggplot2. However, the default styling leaves a little to be desired. We will now learn how to personalize your plots.\nFirst, we need to add some more information to our plot to make it easier to interpret. We will start with some more useful labels:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )\n\n\n\n\n\n\n\nNext, we want to adjust what our plots look like. You can do this to highlight certain elements of your data:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class == \"2seater\")) + \n  geom_smooth(method = \"lm\") + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )\n\n\n\n\n\n\n\nOr to simply make the graph more appealing to look at:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(colour = \"pink\") + \n  geom_smooth(method = \"lm\") + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )\n\n\n\n\n\n\n\nLess is often more when it comes to data visualization. Your audience will find it easier to learn about the relationships you want to highlight when your plot is not cluttered with stylistic elements.\nWe can easily strip away a lot of the default ggplot() styling using the theme_minimal() function:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  theme_minimal() + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  ) \n\n\n\n\n\n\n\nThere are many preset ggplot2 themes available. You can check them out in the ggplot documentation.\nLike any R function, the ggplot2 theme_X() series of functions are running a more verbose set of R code in the background. You can add in this code directly using the theme() function to control the look of your plot. For example, here are some things I commonly do to my plots:\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  theme(\n    legend.position = \"bottom\",\n    panel.grid = element_blank(),\n    panel.background = element_blank(),\n    plot.title.position = \"plot\",\n    plot.title = element_text(face = \"bold\")\n  ) + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  ) \n\n\n\n\n\n\n\nHere, I have:\n\nMoved the legend to the bottom of the plot\nRemoved the grid lines\nRemoved the grey shading behind the plot\nPulled the plot title closer to the edge of the plot\nMade the plot title bold.\n\nYou can see the many, many different elements of a ggplot2 plot you can control by looking over the theme() function’s documentation:\n\n?theme\n\nExercises\nWhat has gone wrong with this code? Why are the points not blue?\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy, color = \"blue\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\nPlacing the color = \"blue\" argument in the aes() means that geom_point() will treat \"blue\" as a variable, not as a value. We need to move it out of aes() and make it a stand-alone argument of geom_point():\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy), color = \"blue\")\n\n\n\n\n\n\n\n\n\n\nName a categorical variable in mpg. Name a continuous one.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\n\nCategorical\n\nmanufacturer\nmodel\ntrans\ndrv\nfl\nclass\n\n\nContinuous\n\ndispl\nyear\ncyl\ncty\nhwy\n\n\n\n\n\n\nMap a continuous variable to color. How does this aesthetics behave differently for categorical vs. continuous variables?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\nggplot() will adapt to create a continuous colour palette for a continuous variable.\n\nggplot(mpg, aes(x = displ, y = hwy, colour = cyl)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\nMap class to the shape aesthetic. What does the warning tell you?\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\n\n\n\nThis warning lets us know that ggplot() can plot up to six different unique values under the shape argument. Our data include seven unique values. One (suv) is being dropped out of the visualization.",
    "crumbs": [
      "Content",
      "Session 1",
      "Introducing R Through Data Visualization"
    ]
  },
  {
    "objectID": "content/01-01-visualization.html#working-with-categorical-data",
    "href": "content/01-01-visualization.html#working-with-categorical-data",
    "title": "Introducing R Through Data Visualization",
    "section": "Working with categorical data",
    "text": "Working with categorical data\nSo far, we have looked at plotting the relationship between two continuous variables. We need different plot types to visualize categorical data.\nFirst, let’s take a look at some categorical variables in our mpg data set:\n\n\n# A tibble: 234 × 3\n   manufacturer model      drv  \n   &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;\n 1 audi         a4         f    \n 2 audi         a4         f    \n 3 audi         a4         f    \n 4 audi         a4         f    \n 5 audi         a4         f    \n 6 audi         a4         f    \n 7 audi         a4         f    \n 8 audi         a4 quattro 4    \n 9 audi         a4 quattro 4    \n10 audi         a4 quattro 4    \n# ℹ 224 more rows\n\n\nHere, we have information on each car’s manufacturer, its model name, and its drive train type (front-wheel, rear-wheel, or four-wheel drive).\nWhat is the most popular drive train type among our sample of car models? We can quickly answer this question by visualizing the count of the number of different models in each drive train type:\n\nggplot(mpg, aes(x = drv)) + \n  geom_bar()\n\n\n\n\n\n\n\nIt looks like front-wheel drives (f) are just the most popular type, quickly followed by four-wheel drives. We can reorder our x-axis to follow this ranking:\n\nggplot(mpg, aes(x = fct_infreq(drv))) +\n  geom_bar()\n\n\n\n\n\n\n\nCounts of our data can be very helpful for getting a sense of what is common (or not) among them. For example, I can use a histogram (which plots counts of the number of observations within bins of continuous variables) to see how my variable is distributed across all the range of its values. Here is that distribution for one of our continuous variables above, highway miles per gallon:\n\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram()\n\n\n\n\n\n\n\nFrom this histogram, we learn that the car models in our sample tend to do between roughly 15 to 30 highway miles per gallon of fuel. A small number of cars are more efficient (can do up to over 40 miles with that one gallon). Similarly a small number of cars are very inefficient (only getting around 12 miles with that gallon).\nWe can get a similar, if cleaner, sense of this shape using a density plot:\n\nggplot(mpg, aes(x = hwy)) +\n  geom_density()\n\n\n\n\n\n\n\nThis density plot is showing the same data as the histogram, but it presents a smoother picture. This can often allow us to focus more easily on the shape of the distribution of our data. However, it can gloss over some important details in that distribution. For example, we get less of a sense of the trough (or low point) immediately after 20 miles per gallon in the density plot compared to the histogram.\nWe can also use these data visualizations to easily compare data. For example, here is the distribution of highway miles per gallon for cars according to their drive train type:\n\nggplot(mpg, aes(x = hwy, colour = drv, fill = drv)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe colour aesthetic controls the thin outline of the density plot. Adding the fill aesthetic makes the groups easier to see. geom_density()’s alpha argument controls the transparency of each density plot.\n\n\nExercise\nPlot the number of observations in each category of a categorical variable in the mpg data set. Make sure to use an appropriate graph type.\n\n\n\n\n\n\nCheck your answer\n\n\n\n\n\n\nggplot(mpg, aes(x = drv)) + \n  geom_bar()",
    "crumbs": [
      "Content",
      "Session 1",
      "Introducing R Through Data Visualization"
    ]
  },
  {
    "objectID": "content/slides/01-02-load_data.html#data-visualisation",
    "href": "content/slides/01-02-load_data.html#data-visualisation",
    "title": "Loading and Exploring Your Data",
    "section": "Data visualisation",
    "text": "Data visualisation\nWe will use data visualization to answer the following question:\n\nDo cars with big engines use more fuel than cars with small engines?"
  },
  {
    "objectID": "content/slides/01-02-load_data.html#load-relevant-packages",
    "href": "content/slides/01-02-load_data.html#load-relevant-packages",
    "title": "Loading and Exploring Your Data",
    "section": "Load relevant packages",
    "text": "Load relevant packages\n\n# Load relevant packages\nlibrary(tidyverse)"
  },
  {
    "objectID": "content/slides/01-02-load_data.html#load-in-relevant-data",
    "href": "content/slides/01-02-load_data.html#load-in-relevant-data",
    "title": "Loading and Exploring Your Data",
    "section": "Load in relevant data",
    "text": "Load in relevant data\n\n# Load the data\nmpg\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\n\n\n\n\naudi\na4\n1.8\n1999\n4\n\n\naudi\na4\n1.8\n1999\n4\n\n\naudi\na4\n2.0\n2008\n4\n\n\naudi\na4\n2.0\n2008\n4\n\n\naudi\na4\n2.8\n1999\n6\n\n\naudi\na4\n2.8\n1999\n6"
  },
  {
    "objectID": "content/slides/01-02-load_data.html#the-mpg-data-set",
    "href": "content/slides/01-02-load_data.html#the-mpg-data-set",
    "title": "Loading and Exploring Your Data",
    "section": "The mpg data set",
    "text": "The mpg data set\nA couple of useful variables:\n\ndispl: engine displacement, in liters\nhwy: highway miles per gallon"
  },
  {
    "objectID": "content/slides/01-03-plot.html#data-visualization",
    "href": "content/slides/01-03-plot.html#data-visualization",
    "title": "Plotting Your Data",
    "section": "Data visualization",
    "text": "Data visualization\nWe will use data visualization to answer the following question:\n\nDo cars with big engines use more fuel than cars with small engines?"
  },
  {
    "objectID": "content/slides/01-03-plot.html#set-up-your-plot",
    "href": "content/slides/01-03-plot.html#set-up-your-plot",
    "title": "Plotting Your Data",
    "section": "Set up your plot",
    "text": "Set up your plot\nAn empty canvas!\n\nggplot(data = mpg)"
  },
  {
    "objectID": "content/slides/01-03-plot.html#map-your-aesthetics",
    "href": "content/slides/01-03-plot.html#map-your-aesthetics",
    "title": "Plotting Your Data",
    "section": "Map your aesthetics",
    "text": "Map your aesthetics\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy))"
  },
  {
    "objectID": "content/slides/01-03-plot.html#add-in-your-cars",
    "href": "content/slides/01-03-plot.html#add-in-your-cars",
    "title": "Plotting Your Data",
    "section": "Add in your cars",
    "text": "Add in your cars\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point()"
  },
  {
    "objectID": "content/slides/01-03-plot.html#look-at-the-relationship-across-all-cars",
    "href": "content/slides/01-03-plot.html#look-at-the-relationship-across-all-cars",
    "title": "Plotting Your Data",
    "section": "Look at the relationship across all cars",
    "text": "Look at the relationship across all cars\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "content/slides/01-03-plot.html#lets-look-at-groups-in-the-data",
    "href": "content/slides/01-03-plot.html#lets-look-at-groups-in-the-data",
    "title": "Plotting Your Data",
    "section": "Let’s look at groups in the data",
    "text": "Let’s look at groups in the data\n\nCan look at more than two interesting elements of our data.\nYou can use visual elements or aesthetics (aes) to communicate many dimensions in your data.\nLet’s look at a categorical variable: the class of car (SUV, 2 seater, pick up truck, etc.).\nLook for meaningfully defined groups."
  },
  {
    "objectID": "content/slides/01-03-plot.html#lets-look-at-groups-in-the-data-1",
    "href": "content/slides/01-03-plot.html#lets-look-at-groups-in-the-data-1",
    "title": "Plotting Your Data",
    "section": "Let’s look at groups in the data",
    "text": "Let’s look at groups in the data\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = class)) + \n  geom_point()"
  },
  {
    "objectID": "content/slides/01-03-plot.html#look-at-the-relationship-within-groups",
    "href": "content/slides/01-03-plot.html#look-at-the-relationship-within-groups",
    "title": "Plotting Your Data",
    "section": "Look at the relationship within groups",
    "text": "Look at the relationship within groups\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = class)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "content/slides/01-03-plot.html#aesthetics-can-be-isolated",
    "href": "content/slides/01-03-plot.html#aesthetics-can-be-isolated",
    "title": "Plotting Your Data",
    "section": "Aesthetics can be isolated",
    "text": "Aesthetics can be isolated\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(aes(colour = class)) + \n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#data-visualization",
    "href": "content/slides/01-05-personal_plots.html#data-visualization",
    "title": "Styling Your Plots",
    "section": "Data visualization",
    "text": "Data visualization\nWe will use data visualization to answer the following question:\n\nDo cars with big engines use more fuel than cars with small engines?"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#add-useful-titles-and-labels",
    "href": "content/slides/01-05-personal_plots.html#add-useful-titles-and-labels",
    "title": "Styling Your Plots",
    "section": "Add useful titles and labels",
    "text": "Add useful titles and labels\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#add-useful-titles-and-labels-1",
    "href": "content/slides/01-05-personal_plots.html#add-useful-titles-and-labels-1",
    "title": "Styling Your Plots",
    "section": "Add useful titles and labels",
    "text": "Add useful titles and labels"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#flexible-visualization",
    "href": "content/slides/01-05-personal_plots.html#flexible-visualization",
    "title": "Styling Your Plots",
    "section": "Flexible visualization",
    "text": "Flexible visualization\nYou can use visual elements to communicate your findings in engaging ways.\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class == \"2seater\")) + \n  geom_smooth(method = \"lm\") + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#changing-the-look-of-your-plots",
    "href": "content/slides/01-05-personal_plots.html#changing-the-look-of-your-plots",
    "title": "Styling Your Plots",
    "section": "Changing the look of your plots",
    "text": "Changing the look of your plots\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(colour = \"pink\") + \n  geom_smooth(method = \"lm\") + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  )"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#lets-clean-our-graph-up",
    "href": "content/slides/01-05-personal_plots.html#lets-clean-our-graph-up",
    "title": "Styling Your Plots",
    "section": "Let’s clean our graph up",
    "text": "Let’s clean our graph up\nLess is more when it comes to data visualization.\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  theme_minimal() + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  ) \n\n\n\nAll pre-set ggplot themes can be found in the ggplot documentation."
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#lets-clean-this-up",
    "href": "content/slides/01-05-personal_plots.html#lets-clean-this-up",
    "title": "Styling Your Plots",
    "section": "Let’s clean this up",
    "text": "Let’s clean this up"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#creating-your-own-theme",
    "href": "content/slides/01-05-personal_plots.html#creating-your-own-theme",
    "title": "Styling Your Plots",
    "section": "Creating your own theme",
    "text": "Creating your own theme\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(colour = class)) + \n  geom_smooth(method = \"lm\") + \n  theme(\n    legend.position = \"bottom\",\n    panel.grid = element_blank(),\n    panel.background = element_blank(),\n    plot.title.position = \"plot\",\n    plot.title = element_text(face = \"bold\")\n  ) + \n  labs(\n    title = \"Engine displacement and highway miles per gallon\",\n    subtitle = \"Values for seven different classes of cars\",\n    x = \"Engine displacement (L)\",\n    y = \"Highway miles per gallon\"\n  ) \n\n\n\nAll theme elements that you can control can be found in the ggplot documentation. There are a lot!"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#creating-your-own-theme-1",
    "href": "content/slides/01-05-personal_plots.html#creating-your-own-theme-1",
    "title": "Styling Your Plots",
    "section": "Creating your own theme",
    "text": "Creating your own theme"
  },
  {
    "objectID": "content/slides/01-05-personal_plots.html#the-before-shot",
    "href": "content/slides/01-05-personal_plots.html#the-before-shot",
    "title": "Styling Your Plots",
    "section": "The before shot",
    "text": "The before shot"
  },
  {
    "objectID": "content/slides/01-06-categorical.html#working-with-categorical-data",
    "href": "content/slides/01-06-categorical.html#working-with-categorical-data",
    "title": "Working with Categorical Data",
    "section": "Working with categorical data",
    "text": "Working with categorical data\nWe often want to explore patterns in categorical (or discrete) data. We need new tools to do this."
  },
  {
    "objectID": "content/slides/01-06-categorical.html#working-with-categorical-data-1",
    "href": "content/slides/01-06-categorical.html#working-with-categorical-data-1",
    "title": "Working with Categorical Data",
    "section": "Working with categorical data",
    "text": "Working with categorical data\n\nselect(mpg, manufacturer, model, drv)\n\n# A tibble: 234 × 3\n   manufacturer model      drv  \n   &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;\n 1 audi         a4         f    \n 2 audi         a4         f    \n 3 audi         a4         f    \n 4 audi         a4         f    \n 5 audi         a4         f    \n 6 audi         a4         f    \n 7 audi         a4         f    \n 8 audi         a4 quattro 4    \n 9 audi         a4 quattro 4    \n10 audi         a4 quattro 4    \n# ℹ 224 more rows"
  },
  {
    "objectID": "content/slides/01-06-categorical.html#visualizing-distributions",
    "href": "content/slides/01-06-categorical.html#visualizing-distributions",
    "title": "Working with Categorical Data",
    "section": "Visualizing distributions",
    "text": "Visualizing distributions\n\nggplot(mpg, aes(x = drv)) + \n  geom_bar()"
  },
  {
    "objectID": "content/slides/01-06-categorical.html#visualizing-distributions-1",
    "href": "content/slides/01-06-categorical.html#visualizing-distributions-1",
    "title": "Working with Categorical Data",
    "section": "Visualizing distributions",
    "text": "Visualizing distributions\nReorder in relation to frequency\n\nggplot(mpg, aes(x = fct_infreq(drv))) +\n  geom_bar()"
  },
  {
    "objectID": "content/slides/01-06-categorical.html#visualizing-numeric-variables",
    "href": "content/slides/01-06-categorical.html#visualizing-numeric-variables",
    "title": "Working with Categorical Data",
    "section": "Visualizing numeric variables",
    "text": "Visualizing numeric variables\n\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram()"
  },
  {
    "objectID": "content/slides/01-06-categorical.html#visualizing-numeric-variables-1",
    "href": "content/slides/01-06-categorical.html#visualizing-numeric-variables-1",
    "title": "Working with Categorical Data",
    "section": "Visualizing numeric variables",
    "text": "Visualizing numeric variables\n\nggplot(mpg, aes(x = hwy)) +\n  geom_density()"
  },
  {
    "objectID": "content/slides/01-06-categorical.html#visualizing-numeric-variables-2",
    "href": "content/slides/01-06-categorical.html#visualizing-numeric-variables-2",
    "title": "Working with Categorical Data",
    "section": "Visualizing numeric variables",
    "text": "Visualizing numeric variables\n\nggplot(mpg, aes(x = hwy, colour = drv, fill = drv)) +\n  geom_density(alpha = 0.5)"
  },
  {
    "objectID": "content/01-02-experiments.html",
    "href": "content/01-02-experiments.html",
    "title": "Causes and Effects",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"tidyverse\", \"DT\", \"patchwork\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(patchwork)\n\nWe often want to better understand what factors lead to (or cause) certain outcomes of interest. This session explains how we might go about identifying these causal effects in the real-world.\nOur goal as political scientists is to explain whether (and why) changes to some features lead to changes in our outcomes of interest. For example:\n\nDoes increasing the number of voting booths close to a potential voter make that person more likely to vote?\nDo peace treaties signed with factionalized rebel groups more often lead to a return to conflict than those signed with a single, cohesive group?\nDoes trade between two countries make war between them less likely?\n\nThe questions can be reframed as causal statements that can then be tested:\n\nMore local voting booths lead to an increased likelihood individuals vote.\nMore factionalization among rebel groups lead to a higher likelihood the conflict will restart.\nMore trade between two countries leads to a lower likelihood that war will break out between them.\n\nHowever, proving that changes to one factor (more local voting booths, factionalization, or trade) caused changes to our outcome of interest is very difficult to do. This is because we need to prove that all the other factors that changed when the factor we focus on changed didn’t cause changes to our outcome of interest. How do we do this?\nWe will spend the whole course answering this question. This session, we are going to focus on experiments, which are often called the “gold-standard” of causal research. To guide us through this session, we are going to look at research conducted by Professor Susan Hyde.",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/01-02-experiments.html#set-up",
    "href": "content/01-02-experiments.html#set-up",
    "title": "Causes and Effects",
    "section": "",
    "text": "To complete this session, you need to load in the following R packages:\n\n\n\n\n\n\nInstall packages\n\n\n\n\n\nTo install new R packages, run the following (excluding the packages you have already installed):\n\ninstall.packages(c(\"tidyverse\", \"DT\", \"patchwork\"))\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(patchwork)\n\nWe often want to better understand what factors lead to (or cause) certain outcomes of interest. This session explains how we might go about identifying these causal effects in the real-world.\nOur goal as political scientists is to explain whether (and why) changes to some features lead to changes in our outcomes of interest. For example:\n\nDoes increasing the number of voting booths close to a potential voter make that person more likely to vote?\nDo peace treaties signed with factionalized rebel groups more often lead to a return to conflict than those signed with a single, cohesive group?\nDoes trade between two countries make war between them less likely?\n\nThe questions can be reframed as causal statements that can then be tested:\n\nMore local voting booths lead to an increased likelihood individuals vote.\nMore factionalization among rebel groups lead to a higher likelihood the conflict will restart.\nMore trade between two countries leads to a lower likelihood that war will break out between them.\n\nHowever, proving that changes to one factor (more local voting booths, factionalization, or trade) caused changes to our outcome of interest is very difficult to do. This is because we need to prove that all the other factors that changed when the factor we focus on changed didn’t cause changes to our outcome of interest. How do we do this?\nWe will spend the whole course answering this question. This session, we are going to focus on experiments, which are often called the “gold-standard” of causal research. To guide us through this session, we are going to look at research conducted by Professor Susan Hyde.",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/01-02-experiments.html#are-election-monitors-effective-at-reducing-election-day-fraud-in-new-democracies",
    "href": "content/01-02-experiments.html#are-election-monitors-effective-at-reducing-election-day-fraud-in-new-democracies",
    "title": "Causes and Effects",
    "section": "Are election monitors effective at reducing election-day fraud in new democracies?",
    "text": "Are election monitors effective at reducing election-day fraud in new democracies?\nHyde was very interested in election fraud. She wanted to uncover what things the international community could do to prevent elections from being stolen. Interestingly for her, she completed her PhD during a time in which the prevalence of international election monitors exploded. There was a sharp increase in the number of elections held in new democracies globally that included international organizations or representatives from other countries monitoring how those elections were run. So, she wanted to know: did these international monitors cause less election-day fraud in democratic elections?\nShe worked out that, although fraud itself is very difficult to see, its outcome is not. (Effective) cheating parties receive a greater vote share than they would had they not cheated. So, she set out to see whether international election monitors camped out at election booths decreased the vote share won by cheating parties at those booths. In her own words (Hyde 2007, 39):\n\nIf the presence of international observers causes a reduction in election-day fraud, the effect of observers should be visible at the subnational level by comparing polling stations that were visited by observers with those that were not visited. More specifically, if international monitoring reduces electionday fraud directly, all else held equal, the cheating parties should gain less of their ill-gotten vote share in polling stations that were visited by international monitors.\n\nSo, Hyde offers the following sequence of causes:\n\nInternational election monitors cause\nLess election-day fraud at the booth at which they are stationed (which we cannot observe directly), which causes\nA lower vote-share won by the cheating party than they would otherwise have won (which we can observe directly, kind of … stay tuned).",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/01-02-experiments.html#causal-relationships",
    "href": "content/01-02-experiments.html#causal-relationships",
    "title": "Causes and Effects",
    "section": "Causal relationships",
    "text": "Causal relationships\n\n\n\n\n\n\nWarning\n\n\n\nJargon incoming!\n\n\nHyde is interested in the causal relationship between international election monitors and election-day fraud. Formally, a causal relationship refers to the directional connection between a change in one variable and a corresponding change in another.\nFor causal relationships, direction really matters. You need to prove the following sequence of events:\n\nA change happened to some factor, then:\nA change happened to your outcome of interest\n\nLet’s label these factors to avoid confusion. The treatment variable is the variable causing changes to another variable. It’s the one that moves first. The outcome variable is the variable changing as a result of changes to another variable (the treatment). It’s the one that moves second.\nHyde wanted to test whether the presence of international monitors (the treatment) leads to less election day fraud (the outcome).\nFocus for a moment on the treatment variable. At any given polling station in any given election, monitors may be: 1) present, or 2) not present. We, therefore, have two conditions:\n\nTreatment: monitors are present\nControl: monitors are not present",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/01-02-experiments.html#individual-causal-effects",
    "href": "content/01-02-experiments.html#individual-causal-effects",
    "title": "Causes and Effects",
    "section": "Individual causal effects",
    "text": "Individual causal effects\nWe want to know whether the treatment causes a change in our outcome of interest. To do this, we want to compare the vote share the cheating party received at the voting booth with election monitors present (under treatment) to that it received at the voting booth without election monitors present (under control). Huh…\nLet’s step through this with a concrete example. Imagine that we are looking at a specific election held within a new democracy. There are 10 election booths set up for the election.\nIn an ideal world, we would run the election with no monitors and record the vote share each party received at each booth. We would then jump in our very handy time machine and go back to the start of the election. We would station monitors at every booth, run the election, and record the vote share each party received.\nWe could then directly compare the vote share each party received at each booth with and without monitors (in treatment and control). If Hyde’s hypothesis is correct, we should see that the cheating party receives a lower vote share in the timeline with election monitors than it does in the timeline without them.\nFor example, imagine that the following results were recorded for the cheating party at each of the 1,000 booths in both timelines:\n\n\n\n\n\n\nBecause the only difference between these two versions of the election was the presence of election monitors, we can definitively state that the difference in vote shares won by each party was caused by the monitors. Let’s calculate those differences:\n\nindiv_effect_df |&gt; \n  mutate(across(vote_share_monitored:difference, \n                ~ scales::percent(.x, accuracy = 0.1))) |&gt; \n  rename(ID = polling_station_id,\n         `Monitored vote %` = vote_share_monitored,\n         `Non-monitored vote %` = vote_share_not_monitored,\n         Difference = difference) |&gt; \n  datatable(rownames = F, options = list(pageLength = 10, dom = 'tip'))\n\n\n\n\n\nIn this hypothetical election, these differences are substantial! They are often the difference between a decisive victory and an embarrassing defeat.",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/01-02-experiments.html#average-causal-effects",
    "href": "content/01-02-experiments.html#average-causal-effects",
    "title": "Causes and Effects",
    "section": "Average causal effects",
    "text": "Average causal effects\nSadly for us, however, we are yet to invent time machines. We cannot observe both the treatment and control for each individual booth. Rather what we see is the following:\n\n\n\n\n\n\nWe are, essentially, missing data for the counter-factual for each booth. We cannot, therefore, calculate the difference and identify the causal effect of election monitors for each individual booth. So, now what?\nWe need to move away from looking at individuals and start to look for patterns in our group. Let’s return to our two timelines. What was the difference between the vote share won by the cheating party with and without election monitors on average across all booths?\n\n\n\n\nAvg. monitored vote %\nAvg. non-monitored vote %\nDifference\n\n\n39.5%\n84.3%\n-44.8%\n\n\n\n\nOkay, what is the difference, on average, in our real world?\n\n\n\n\nAvg. monitored vote %\nAvg. non-monitored vote %\nDifference\n\n\n40.2%\n84.5%\n-44.3%\n\n\n\n\nThe average difference with missing counter-factuals is very close to that with full information (that relies on that handy time machine). How does this work so well?",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/01-02-experiments.html#randomization",
    "href": "content/01-02-experiments.html#randomization",
    "title": "Causes and Effects",
    "section": "Randomization",
    "text": "Randomization\nThrough randomization! I assigned monitors to the 1,000 voting booths randomly. For each booth, I flipped a (R generated) coin to decide whether that booth would be monitored. At the end of that process, roughly half of the booths had monitors and half did not:\n\n\n\n\nMonitored\nNo. of booths\n\n\n\nNo\n502\n\n\nYes\n498\n\n\n\n\n\nThe magic trick with random assignment is that you tend to end up with two groups that are roughly identical to one another prior to treatment, on average. Remember, our goal is to create two groups (treatment and control) that are identical to one another prior to treatment. If the only difference between the groups is the treatment, we can say that any differences in our outcome of interest is caused by the treatment.\nAbsent a time machine, we then need to set about creating two groups that are as identical to each other as possible. It turns out that random assignment does a very good job of achieving this.\n\n\n\n\n\n\nNote\n\n\n\nPractitioners have come up with other clever ways of doing this, including pairwise matching. We will not cover those in this course.\n\n\nYou don’t need to take my word for this. Let’s prove it with simulation! Imagine we have a group of 1,000 individuals. We know the following about them:\n\nHeight\nWeight\nEye colour\n\nHere are those data:\n\n\n\n\n\n\nI’m now going to flip (an imaginary, R-generated) coin for each of these 1,000 individuals to assigned them to either group A or B:\n\n\n\n\n\n\nNow we can check how similar these two groups are to one another. Let’s start with their heights:\n\n\n\n\n\n\n\n\nThe distribution of heights among individuals in groups A and B are roughly identical. The average height of individuals in group A is 170.1 cm and in group B is 170 cm. Pretty neat!\nLet’s check their weight:\n\n\n\n\n\n\n\n\nSimilarly, the distribution of weights among individuals in groups A and B are roughly identical. On average, individuals in group A weigh 79.9 kg. Individuals in group B weigh 79.6 kg, on average.\nFinally, let’s look at eye colour:\n\n\n\n\n\n\n\n\nAgain, the proportion of individuals within each group with each eye colour are roughly identical. This is all due to random assignment.\nLet’s repeat this process, assigning our 1,000 individuals randomly to each group, and make sure this wasn’t a fluke:\n\n\n\n\n\n\nAnd let’s see how similar these new, randomly-assigned groups are to each other:\n\n\n\n\n\n\n\n\nAgain, these two groups are nearly identical to one another, on average. In fact, if we did this many, many, many times, these groups would be, on average, increasingly identical.\n\n\n\n\n\n\nWhy?\n\n\n\nBecause of the Central Limit Theorem and Law of Large Numbers. We will talk about these two concepts later in the course.",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/01-02-experiments.html#returning-to-our-question",
    "href": "content/01-02-experiments.html#returning-to-our-question",
    "title": "Causes and Effects",
    "section": "Returning to our question",
    "text": "Returning to our question\nSo, do international election monitors deter election-fraud? Yes! The international community monitored the 2003 Armenian Presidential elections. Monitors were assigned randomly to the polling stations. Hyde found a large difference between the vote share received by the cheating party at monitored stations compared to non-monitored stations, on average.",
    "crumbs": [
      "Content",
      "Session 1",
      "Causes and Effects"
    ]
  },
  {
    "objectID": "content/slides/01-07-experiments.html#causes-and-effects",
    "href": "content/slides/01-07-experiments.html#causes-and-effects",
    "title": "Causal Effects and Experiments",
    "section": "Causes and effects",
    "text": "Causes and effects\nOur goal is to better understand what factors lead to certain outcomes of interest.\n\nDoes increasing the number of voting booths close to a potential voter make that person more likely to vote?\nDo peace treaties signed with factionalized rebel groups more often lead to a return to conflict than those signed with a single, cohesive group?\nDoes trade between two countries make war between them less likely?"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#causes-and-effects-1",
    "href": "content/slides/01-07-experiments.html#causes-and-effects-1",
    "title": "Causal Effects and Experiments",
    "section": "Causes and effects",
    "text": "Causes and effects\nThese are causal statements:\n\nMore local voting booths \\(\\rightarrow\\) More likely to vote\nMore factionalization \\(\\rightarrow\\) More likely to restart conflict\nTrade \\(\\rightarrow\\) Less likely to go to war"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#how-to-identify-causes-and-their-effects",
    "href": "content/slides/01-07-experiments.html#how-to-identify-causes-and-their-effects",
    "title": "Causal Effects and Experiments",
    "section": "How to identify causes and their effects",
    "text": "How to identify causes and their effects\nProving that changes to one factor cause changes to another is very tricky!\n\nNeed to account for all the other factors"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#the-efficacy-of-international-election-monitors",
    "href": "content/slides/01-07-experiments.html#the-efficacy-of-international-election-monitors",
    "title": "Causal Effects and Experiments",
    "section": "The efficacy of international election monitors",
    "text": "The efficacy of international election monitors\nDo international monitors cause less election-day fraud in democratic elections?\n\nNumber of elections monitored by international observers exploded throughout the 2000s\nBut do monitors increase the chances the election will be free and fair?\nIn other words, are they effective?\n\n\n\nHyde, Susan D. 2007. “The Observer Effect in International Politics: Evidence from a Natural Experiment.” World Politics 60 (1): 37–63. http://www.jstor.org/stable/40060180."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#the-efficacy-of-international-election-monitors-1",
    "href": "content/slides/01-07-experiments.html#the-efficacy-of-international-election-monitors-1",
    "title": "Causal Effects and Experiments",
    "section": "The efficacy of international election monitors",
    "text": "The efficacy of international election monitors\nDr Susan Hyde set out to answer this very question. From her article (page 39):\n\nIf the presence of international observers causes a reduction in election-day fraud, the effect of observers should be visible at the subnational level by comparing polling stations that were visited by observers with those that were not visited. More specifically, if international monitoring reduces electionday fraud directly, all else held equal, the cheating parties should gain less of their ill-gotten vote share in polling stations that were visited by international monitors."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#causal-relationships",
    "href": "content/slides/01-07-experiments.html#causal-relationships",
    "title": "Causal Effects and Experiments",
    "section": "Causal relationships",
    "text": "Causal relationships\nRefers to the directional connection between a change in one variable and a corresponding change in another.\n\nThe direction matters!\nTreatment variable: the variable causing changes to another variable.\nOutcome variable: the variable changing as a result of changes to another variable (the treatment)."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#treatment-and-outcome-variables",
    "href": "content/slides/01-07-experiments.html#treatment-and-outcome-variables",
    "title": "Causal Effects and Experiments",
    "section": "Treatment and outcome variables",
    "text": "Treatment and outcome variables\nWe want to test whether the presence of international monitors (treatment) leads to less election day fraud (outcome).\nInternational election monitors present at polling stations \\(\\rightarrow\\) Less election-day fraud at that station"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#treatment-variable",
    "href": "content/slides/01-07-experiments.html#treatment-variable",
    "title": "Causal Effects and Experiments",
    "section": "Treatment variable",
    "text": "Treatment variable\nAt any given polling station in any given election, monitors may be: 1) present, or 2) not present.\nTwo different conditions:\n\nTreatment: condition with treatment (monitors are present)\nControl: condition without treatment (monitors are not present)\n\n\n\nTreatment variables do not need to be binary."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#outcome-variable",
    "href": "content/slides/01-07-experiments.html#outcome-variable",
    "title": "Causal Effects and Experiments",
    "section": "Outcome variable",
    "text": "Outcome variable\nAt any given polling station in any given election, fraud may: 1) occur, or 2) not occur.\n\n\nOutcome variables also do not need to binary."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#observing-our-outcome",
    "href": "content/slides/01-07-experiments.html#observing-our-outcome",
    "title": "Causal Effects and Experiments",
    "section": "Observing our outcome",
    "text": "Observing our outcome\nSometimes it can be hard to observe our outcome of interest.\n\nHow might we see all election-day fraud?\nHow might we measure it?"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#observing-our-outcome-1",
    "href": "content/slides/01-07-experiments.html#observing-our-outcome-1",
    "title": "Causal Effects and Experiments",
    "section": "Observing our outcome",
    "text": "Observing our outcome\nHyde’s answer: vote-share!\nInternational election monitors present at polling stations \\(\\rightarrow\\) Less election-day fraud at that station \\(\\rightarrow\\) Lower vote-share for the cheating party"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#individual-causal-effects",
    "href": "content/slides/01-07-experiments.html#individual-causal-effects",
    "title": "Causal Effects and Experiments",
    "section": "Individual causal effects",
    "text": "Individual causal effects\nWe want to know whether the treatment causes a change in our outcome of interest.\nWhat might this look like in the real world?\n\nImagine we are looking at a specific election\nFive polling stations"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#parallel-worlds",
    "href": "content/slides/01-07-experiments.html#parallel-worlds",
    "title": "Causal Effects and Experiments",
    "section": "Parallel worlds",
    "text": "Parallel worlds"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#hypothetical-election",
    "href": "content/slides/01-07-experiments.html#hypothetical-election",
    "title": "Causal Effects and Experiments",
    "section": "Hypothetical election",
    "text": "Hypothetical election\n\n\n\n\n\nID\nMonitored vote %\nNon-monitored vote %\n\n\n\n\n1\n51.78\n91.94\n\n\n2\n45.49\n97.35\n\n\n3\n42.17\n83.88\n\n\n4\n46.28\n83.52\n\n\n5\n27.17\n98.89"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#individual-effects",
    "href": "content/slides/01-07-experiments.html#individual-effects",
    "title": "Causal Effects and Experiments",
    "section": "Individual effects",
    "text": "Individual effects\nThe only difference between these two conditions is the presence of international monitors!\n\nThe difference between vote shares under these conditions is caused by the monitors."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#individual-effects-1",
    "href": "content/slides/01-07-experiments.html#individual-effects-1",
    "title": "Causal Effects and Experiments",
    "section": "Individual effects",
    "text": "Individual effects\n\n\n\n\n\nID\nMonitored vote %\nNon-monitored vote %\nDifference (%)\n\n\n\n\n1\n51.78\n91.94\n-40.16\n\n\n2\n45.49\n97.35\n-51.86\n\n\n3\n42.17\n83.88\n-41.71\n\n\n4\n46.28\n83.52\n-37.24\n\n\n5\n27.17\n98.89\n-71.72"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#no-parallel-worlds",
    "href": "content/slides/01-07-experiments.html#no-parallel-worlds",
    "title": "Causal Effects and Experiments",
    "section": "No parallel worlds",
    "text": "No parallel worlds\nSadly for us, we cannot create parallel worlds…"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#what-now",
    "href": "content/slides/01-07-experiments.html#what-now",
    "title": "Causal Effects and Experiments",
    "section": "What now?",
    "text": "What now?\n\n\n\n\n\nID\nMonitored\nMonitored vote %\nNon-monitored vote %\nDifference\n\n\n\n\n1\n0\nNA\n91.94\nNA\n\n\n2\n0\nNA\n97.35\nNA\n\n\n3\n1\n42.17\nNA\nNA\n\n\n4\n0\nNA\n83.52\nNA\n\n\n5\n0\nNA\n98.89\nNA"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#average-causal-effects",
    "href": "content/slides/01-07-experiments.html#average-causal-effects",
    "title": "Causal Effects and Experiments",
    "section": "Average causal effects",
    "text": "Average causal effects\nWe need to move away from looking at individuals and start to look for patterns in our group."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#back-to-our-parallel-worlds",
    "href": "content/slides/01-07-experiments.html#back-to-our-parallel-worlds",
    "title": "Causal Effects and Experiments",
    "section": "Back to our parallel worlds",
    "text": "Back to our parallel worlds\n\n\n\n\n\nID\nMonitored vote %\nNon-monitored vote %\nDifference\n\n\n\n\n1\n51.78\n91.94\n-40.16\n\n\n2\n45.49\n97.35\n-51.86\n\n\n3\n42.17\n83.88\n-41.71\n\n\n4\n46.28\n83.52\n-37.24\n\n\n5\n27.17\n98.89\n-71.72"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#difference-of-averages-across-all-individuals",
    "href": "content/slides/01-07-experiments.html#difference-of-averages-across-all-individuals",
    "title": "Causal Effects and Experiments",
    "section": "Difference of averages across all individuals",
    "text": "Difference of averages across all individuals\nWhat was the average vote share received in each world?\n\n\n\n\n\nAvg. monitored vote %\nAvg. non-monitored vote %\nDifference\n\n\n\n\n42.58\n91.12\n-48.54"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#back-to-reality",
    "href": "content/slides/01-07-experiments.html#back-to-reality",
    "title": "Causal Effects and Experiments",
    "section": "Back to reality",
    "text": "Back to reality\n\n\n\n\n\nID\nMonitored\nMonitored vote %\nNon-monitored vote %\nDifference\n\n\n\n\n1\n0\nNA\n91.94\nNA\n\n\n2\n0\nNA\n97.35\nNA\n\n\n3\n1\n42.17\nNA\nNA\n\n\n4\n0\nNA\n83.52\nNA\n\n\n5\n0\nNA\n98.89\nNA"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#difference-of-means",
    "href": "content/slides/01-07-experiments.html#difference-of-means",
    "title": "Causal Effects and Experiments",
    "section": "Difference-of-means",
    "text": "Difference-of-means\nWhat was the average vote share received in each group?\n\n\n\n\n\nAvg. monitored vote %\nAvg. non-monitored vote %\nDifference\n\n\n\n\n42.17\n92.92\n-50.75"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#how-on-earth-does-this-work-so-well",
    "href": "content/slides/01-07-experiments.html#how-on-earth-does-this-work-so-well",
    "title": "Causal Effects and Experiments",
    "section": "How on Earth does this work so well?",
    "text": "How on Earth does this work so well?\nRandomization!\n\nMonitors were assigned to polling stations randomly (for example, with the flip of a coin)\nThis created two groups of stations that were roughly identical on average to one another prior to treatment\nThis mimics what happens when we split our world into two (creating two literally identical groups)"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#our-goal",
    "href": "content/slides/01-07-experiments.html#our-goal",
    "title": "Causal Effects and Experiments",
    "section": "Our goal",
    "text": "Our goal\nWe want two groups that are completely identical to one another prior to treatment.\n\nThis allows us to compare their outcomes after treatment and claim that the treatment caused differences in those outcomes (if any differences exist)"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#our-goal-1",
    "href": "content/slides/01-07-experiments.html#our-goal-1",
    "title": "Causal Effects and Experiments",
    "section": "Our goal",
    "text": "Our goal"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#next-best-thing",
    "href": "content/slides/01-07-experiments.html#next-best-thing",
    "title": "Causal Effects and Experiments",
    "section": "Next best thing",
    "text": "Next best thing\nInstead, we should try to make two groups that are as similar as possible to each other prior to treatment."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#the-magic-of-randomization",
    "href": "content/slides/01-07-experiments.html#the-magic-of-randomization",
    "title": "Causal Effects and Experiments",
    "section": "The magic of randomization",
    "text": "The magic of randomization\nPerfectly random assignment does this very well!"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#dont-take-my-word-for-it",
    "href": "content/slides/01-07-experiments.html#dont-take-my-word-for-it",
    "title": "Causal Effects and Experiments",
    "section": "Don’t take my word for it",
    "text": "Don’t take my word for it\nImagine we have a group of 1,000 individuals. We know the following about them:\n\nHeight\nWeight\nEye colour"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#our-group",
    "href": "content/slides/01-07-experiments.html#our-group",
    "title": "Causal Effects and Experiments",
    "section": "Our group",
    "text": "Our group\n\n\n\n\n\nID\nHeight\nWeight\nEye colour\n\n\n\n\n1\n170.62\n77.78\nBrown\n\n\n2\n174.04\n49.24\nBrown\n\n\n3\n171.12\n85.96\nGrey\n\n\n4\n166.27\n89.28\nGrey\n\n\n5\n169.99\n103.33\nBrown\n\n\n6\n165.38\n84.37\nBrown\n\n\n7\n171.92\n80.29\nGreen\n\n\n8\n173.02\n97.12\nBlue\n\n\n9\n165.83\n91.32\nGreen\n\n\n10\n163.81\n89.87\nBrown\n\n\n11\n165.78\n74.25\nGreen\n\n\n12\n175.28\n99.72\nGrey\n\n\n13\n171.90\n95.85\nBlue\n\n\n14\n171.11\n63.92\nBrown\n\n\n15\n167.29\n66.29\nGrey\n\n\n16\n167.43\n97.85\nBlue\n\n\n17\n166.59\n77.91\nGrey\n\n\n18\n169.54\n89.53\nGrey\n\n\n19\n162.91\n81.23\nBrown\n\n\n20\n156.62\n71.98\nGrey\n\n\n21\n168.07\n83.66\nBrown\n\n\n22\n167.72\n81.11\nBlue\n\n\n23\n173.65\n78.10\nGreen\n\n\n24\n171.84\n74.55\nGrey\n\n\n25\n161.53\n70.32\nBrown\n\n\n26\n167.05\n90.10\nBrown\n\n\n27\n172.42\n88.43\nBlue\n\n\n28\n176.32\n63.16\nGrey\n\n\n29\n181.28\n87.74\nGreen\n\n\n30\n171.20\n63.42\nBrown\n\n\n31\n166.78\n74.78\nBlue\n\n\n32\n168.40\n80.77\nGreen\n\n\n33\n167.06\n78.07\nGrey\n\n\n34\n162.80\n69.65\nBlue\n\n\n35\n154.76\n84.17\nBrown\n\n\n36\n163.79\n86.04\nBrown\n\n\n37\n158.00\n82.08\nGreen\n\n\n38\n170.47\n68.50\nBlue\n\n\n39\n170.56\n77.96\nBlue\n\n\n40\n180.94\n94.93\nGreen\n\n\n41\n167.84\n95.25\nBrown\n\n\n42\n167.48\n99.63\nBrown\n\n\n43\n167.45\n93.59\nGrey\n\n\n44\n152.83\n88.78\nGrey\n\n\n45\n169.91\n78.77\nGrey\n\n\n46\n167.39\n75.19\nGreen\n\n\n47\n163.90\n77.07\nGrey\n\n\n48\n171.55\n75.64\nGreen\n\n\n49\n169.16\n90.56\nGrey\n\n\n50\n172.17\n72.51\nBlue\n\n\n51\n176.74\n81.63\nBlue\n\n\n52\n171.20\n76.86\nBlue\n\n\n53\n175.02\n97.72\nBlue\n\n\n54\n165.89\n87.05\nGreen\n\n\n55\n159.78\n76.90\nGreen\n\n\n56\n169.08\n81.10\nBrown\n\n\n57\n172.15\n65.48\nBrown\n\n\n58\n165.38\n81.77\nGreen\n\n\n59\n164.43\n81.79\nGrey\n\n\n60\n174.78\n74.47\nBrown\n\n\n61\n182.01\n74.23\nGrey\n\n\n62\n166.11\n79.51\nBrown\n\n\n63\n174.10\n90.42\nGrey\n\n\n64\n174.12\n82.12\nBlue\n\n\n65\n169.17\n91.05\nGrey\n\n\n66\n181.42\n77.08\nGreen\n\n\n67\n176.10\n82.71\nBrown\n\n\n68\n169.15\n78.50\nGrey\n\n\n69\n172.27\n89.14\nBlue\n\n\n70\n166.27\n74.35\nGreen\n\n\n71\n168.44\n70.31\nGreen\n\n\n72\n166.40\n95.56\nGrey\n\n\n73\n167.81\n72.94\nBrown\n\n\n74\n169.04\n86.17\nGreen\n\n\n75\n170.34\n74.29\nGrey\n\n\n76\n173.59\n85.34\nBrown\n\n\n77\n160.20\n83.85\nGreen\n\n\n78\n163.58\n99.63\nBlue\n\n\n79\n170.72\n85.68\nGrey\n\n\n80\n165.34\n94.12\nBrown\n\n\n81\n177.27\n76.52\nGreen\n\n\n82\n157.97\n69.20\nGrey\n\n\n83\n180.20\n93.03\nBlue\n\n\n84\n164.41\n80.35\nBlue\n\n\n85\n171.17\n87.68\nGreen\n\n\n86\n173.12\n91.04\nBrown\n\n\n87\n170.82\n79.29\nBrown\n\n\n88\n179.01\n70.03\nGreen\n\n\n89\n173.40\n85.50\nGrey\n\n\n90\n153.63\n85.02\nBlue\n\n\n91\n157.98\n81.01\nGrey\n\n\n92\n177.32\n90.66\nGrey\n\n\n93\n169.64\n64.72\nGreen\n\n\n94\n176.31\n79.63\nBlue\n\n\n95\n173.12\n87.03\nGreen\n\n\n96\n181.55\n94.48\nBrown\n\n\n97\n164.51\n77.91\nGrey\n\n\n98\n173.67\n70.98\nGreen\n\n\n99\n185.87\n73.14\nBlue\n\n\n100\n175.63\n106.73\nGreen\n\n\n101\n170.16\n63.49\nBlue\n\n\n102\n161.98\n92.24\nBlue\n\n\n103\n164.81\n64.20\nBlue\n\n\n104\n171.76\n91.59\nGrey\n\n\n105\n173.45\n79.38\nBlue\n\n\n106\n178.81\n85.98\nBlue\n\n\n107\n169.10\n92.82\nGrey\n\n\n108\n166.88\n91.30\nBlue\n\n\n109\n173.63\n78.75\nBrown\n\n\n110\n173.67\n54.60\nGreen\n\n\n111\n164.05\n71.77\nGrey\n\n\n112\n170.56\n85.79\nGreen\n\n\n113\n161.59\n65.32\nGreen\n\n\n114\n159.97\n79.96\nGreen\n\n\n115\n167.57\n86.89\nGrey\n\n\n116\n165.20\n86.76\nBlue\n\n\n117\n162.48\n55.40\nGreen\n\n\n118\n179.48\n91.55\nBlue\n\n\n119\n167.69\n85.30\nBlue\n\n\n120\n164.32\n86.76\nBlue\n\n\n121\n176.56\n78.42\nGreen\n\n\n122\n166.03\n68.93\nBlue\n\n\n123\n175.66\n91.10\nGrey\n\n\n124\n173.17\n95.23\nBlue\n\n\n125\n175.84\n100.18\nBrown\n\n\n126\n163.15\n75.93\nBlue\n\n\n127\n170.37\n86.70\nGrey\n\n\n128\n174.11\n85.43\nGrey\n\n\n129\n164.79\n85.64\nGrey\n\n\n130\n170.73\n76.34\nGrey\n\n\n131\n186.59\n70.37\nBrown\n\n\n132\n165.57\n75.13\nBlue\n\n\n133\n169.04\n67.44\nBlue\n\n\n134\n175.40\n101.61\nGreen\n\n\n135\n172.84\n70.44\nBlue\n\n\n136\n173.65\n73.54\nBrown\n\n\n137\n165.04\n87.82\nGreen\n\n\n138\n178.02\n82.15\nBrown\n\n\n139\n170.15\n82.39\nGrey\n\n\n140\n167.53\n68.22\nGreen\n\n\n141\n161.17\n86.42\nBlue\n\n\n142\n159.85\n76.22\nGreen\n\n\n143\n177.30\n64.93\nGrey\n\n\n144\n170.08\n91.70\nGreen\n\n\n145\n171.94\n66.35\nGrey\n\n\n146\n168.39\n84.10\nGreen\n\n\n147\n181.65\n83.92\nBrown\n\n\n148\n162.03\n63.61\nGreen\n\n\n149\n173.01\n83.91\nGreen\n\n\n150\n167.48\n94.82\nGrey\n\n\n151\n162.33\n75.85\nGrey\n\n\n152\n173.18\n75.34\nBlue\n\n\n153\n174.91\n96.38\nBrown\n\n\n154\n167.47\n90.25\nBlue\n\n\n155\n174.41\n94.96\nGrey\n\n\n156\n174.90\n78.69\nGrey\n\n\n157\n171.82\n72.72\nGreen\n\n\n158\n168.90\n81.85\nGrey\n\n\n159\n162.98\n76.76\nBrown\n\n\n160\n155.14\n89.70\nBlue\n\n\n161\n165.63\n66.75\nBlue\n\n\n162\n165.11\n94.75\nGrey\n\n\n163\n178.82\n100.58\nBrown\n\n\n164\n172.67\n75.55\nBrown\n\n\n165\n170.26\n66.56\nGreen\n\n\n166\n167.62\n84.77\nGrey\n\n\n167\n163.63\n55.40\nBlue\n\n\n168\n165.41\n79.29\nGrey\n\n\n169\n174.51\n70.43\nGrey\n\n\n170\n180.01\n70.95\nGreen\n\n\n171\n177.35\n78.97\nBlue\n\n\n172\n174.29\n52.47\nGreen\n\n\n173\n166.63\n78.44\nGrey\n\n\n174\n180.02\n75.06\nBlue\n\n\n175\n168.21\n93.89\nGreen\n\n\n176\n161.29\n67.78\nBrown\n\n\n177\n172.94\n61.05\nGreen\n\n\n178\n166.38\n89.27\nBrown\n\n\n179\n175.07\n82.56\nGrey\n\n\n180\n170.23\n87.77\nBlue\n\n\n181\n175.95\n92.22\nBrown\n\n\n182\n169.59\n78.52\nGrey\n\n\n183\n174.96\n78.73\nBrown\n\n\n184\n172.37\n83.49\nBlue\n\n\n185\n175.60\n77.63\nGrey\n\n\n186\n177.30\n56.96\nGreen\n\n\n187\n176.32\n72.43\nBrown\n\n\n188\n164.18\n63.03\nGreen\n\n\n189\n164.53\n76.59\nGreen\n\n\n190\n171.87\n60.85\nGreen\n\n\n191\n172.65\n98.63\nGreen\n\n\n192\n177.06\n79.33\nBlue\n\n\n193\n171.54\n75.83\nBrown\n\n\n194\n168.89\n74.78\nBlue\n\n\n195\n163.36\n96.49\nGrey\n\n\n196\n160.62\n84.62\nGrey\n\n\n197\n165.65\n69.40\nBlue\n\n\n198\n169.85\n84.64\nGreen\n\n\n199\n156.28\n74.89\nGrey\n\n\n200\n174.21\n86.76\nGrey\n\n\n201\n170.00\n86.61\nBlue\n\n\n202\n159.73\n76.70\nGreen\n\n\n203\n164.18\n82.22\nBlue\n\n\n204\n165.78\n92.82\nBrown\n\n\n205\n165.10\n85.67\nGreen\n\n\n206\n172.86\n83.77\nBrown\n\n\n207\n169.74\n73.18\nGrey\n\n\n208\n175.94\n81.90\nBlue\n\n\n209\n162.98\n84.52\nBrown\n\n\n210\n159.15\n73.38\nBlue\n\n\n211\n169.32\n73.60\nBlue\n\n\n212\n154.14\n71.95\nBlue\n\n\n213\n172.24\n75.03\nBrown\n\n\n214\n154.08\n90.05\nBrown\n\n\n215\n167.74\n91.83\nGrey\n\n\n216\n170.58\n76.46\nBlue\n\n\n217\n166.15\n77.12\nGrey\n\n\n218\n178.03\n89.99\nBrown\n\n\n219\n164.31\n95.61\nBrown\n\n\n220\n178.09\n87.15\nBlue\n\n\n221\n168.28\n76.83\nBrown\n\n\n222\n178.79\n69.79\nGrey\n\n\n223\n163.44\n82.43\nGrey\n\n\n224\n175.38\n72.01\nGreen\n\n\n225\n180.53\n72.40\nGrey\n\n\n226\n176.48\n79.89\nGrey\n\n\n227\n173.83\n71.29\nBrown\n\n\n228\n163.92\n97.71\nBlue\n\n\n229\n169.49\n81.67\nGreen\n\n\n230\n167.89\n76.51\nGrey\n\n\n231\n164.06\n77.95\nBlue\n\n\n232\n177.57\n60.08\nBrown\n\n\n233\n170.36\n93.87\nGreen\n\n\n234\n163.29\n78.48\nBrown\n\n\n235\n162.85\n84.71\nBrown\n\n\n236\n159.09\n75.07\nBlue\n\n\n237\n171.42\n65.11\nBlue\n\n\n238\n168.34\n83.67\nGrey\n\n\n239\n172.22\n80.99\nBlue\n\n\n240\n166.33\n83.19\nBlue\n\n\n241\n174.84\n85.51\nGrey\n\n\n242\n165.34\n69.62\nGreen\n\n\n243\n169.36\n79.82\nGreen\n\n\n244\n179.62\n93.70\nBrown\n\n\n245\n169.82\n84.24\nBlue\n\n\n246\n166.66\n83.28\nGreen\n\n\n247\n161.48\n85.71\nGreen\n\n\n248\n157.12\n77.46\nBlue\n\n\n249\n180.87\n76.46\nGreen\n\n\n250\n165.45\n74.02\nGrey\n\n\n251\n174.05\n90.16\nGrey\n\n\n252\n169.76\n82.22\nBrown\n\n\n253\n163.57\n88.21\nBrown\n\n\n254\n169.04\n79.57\nGreen\n\n\n255\n166.77\n86.78\nGreen\n\n\n256\n177.32\n81.80\nBlue\n\n\n257\n174.64\n79.11\nGreen\n\n\n258\n157.93\n71.06\nBlue\n\n\n259\n166.43\n84.81\nGreen\n\n\n260\n181.11\n95.02\nGrey\n\n\n261\n175.02\n64.48\nGreen\n\n\n262\n166.49\n75.80\nBlue\n\n\n263\n172.96\n101.45\nBrown\n\n\n264\n167.46\n77.60\nBrown\n\n\n265\n171.88\n99.65\nBlue\n\n\n266\n169.96\n76.15\nBlue\n\n\n267\n171.61\n69.22\nBrown\n\n\n268\n173.93\n77.01\nGrey\n\n\n269\n175.86\n87.87\nBrown\n\n\n270\n163.80\n79.77\nBrown\n\n\n271\n162.62\n89.06\nBrown\n\n\n272\n164.56\n81.04\nBlue\n\n\n273\n169.15\n78.08\nBlue\n\n\n274\n178.99\n82.12\nBlue\n\n\n275\n172.16\n79.83\nBlue\n\n\n276\n177.58\n64.16\nBlue\n\n\n277\n172.11\n87.64\nBlue\n\n\n278\n172.05\n80.89\nGreen\n\n\n279\n158.79\n88.85\nGrey\n\n\n280\n164.65\n76.36\nGrey\n\n\n281\n158.25\n85.47\nBlue\n\n\n282\n161.47\n86.85\nGrey\n\n\n283\n168.93\n74.24\nBlue\n\n\n284\n173.54\n81.79\nGrey\n\n\n285\n168.52\n71.50\nGrey\n\n\n286\n175.56\n79.94\nBlue\n\n\n287\n171.62\n108.83\nBlue\n\n\n288\n181.84\n68.46\nBrown\n\n\n289\n158.44\n86.19\nBlue\n\n\n290\n176.02\n82.23\nGreen\n\n\n291\n168.42\n84.62\nGreen\n\n\n292\n173.19\n83.46\nGrey\n\n\n293\n166.54\n85.19\nBrown\n\n\n294\n151.38\n81.86\nGrey\n\n\n295\n168.90\n88.59\nGreen\n\n\n296\n172.88\n90.38\nBlue\n\n\n297\n163.58\n86.98\nGreen\n\n\n298\n171.87\n72.61\nBrown\n\n\n299\n155.50\n86.58\nGrey\n\n\n300\n161.69\n77.95\nGreen\n\n\n301\n163.56\n83.34\nBlue\n\n\n302\n156.77\n83.00\nGrey\n\n\n303\n179.06\n81.64\nBlue\n\n\n304\n160.63\n79.35\nBlue\n\n\n305\n179.69\n80.81\nBrown\n\n\n306\n177.41\n80.01\nBrown\n\n\n307\n171.50\n77.46\nGreen\n\n\n308\n165.03\n95.09\nGrey\n\n\n309\n165.97\n73.05\nBlue\n\n\n310\n174.97\n88.43\nBrown\n\n\n311\n166.61\n69.08\nGreen\n\n\n312\n167.91\n87.84\nBlue\n\n\n313\n169.47\n56.45\nBlue\n\n\n314\n167.06\n72.44\nBrown\n\n\n315\n169.09\n85.62\nBrown\n\n\n316\n176.48\n84.64\nGreen\n\n\n317\n169.26\n77.97\nBrown\n\n\n318\n166.44\n81.41\nBlue\n\n\n319\n167.66\n97.88\nBrown\n\n\n320\n177.46\n86.76\nGrey\n\n\n321\n167.35\n87.24\nGreen\n\n\n322\n172.86\n73.35\nGrey\n\n\n323\n177.16\n89.08\nGrey\n\n\n324\n165.88\n90.44\nGreen\n\n\n325\n167.17\n85.64\nBlue\n\n\n326\n183.38\n55.84\nGrey\n\n\n327\n169.61\n84.00\nGrey\n\n\n328\n169.70\n85.50\nGreen\n\n\n329\n166.65\n82.95\nGrey\n\n\n330\n164.89\n82.81\nBlue\n\n\n331\n158.82\n74.39\nGrey\n\n\n332\n168.01\n88.06\nBrown\n\n\n333\n165.09\n76.29\nBrown\n\n\n334\n180.56\n75.08\nBlue\n\n\n335\n167.27\n77.80\nBlue\n\n\n336\n173.88\n69.05\nBlue\n\n\n337\n168.97\n77.02\nBrown\n\n\n338\n173.34\n73.76\nBrown\n\n\n339\n176.46\n87.81\nGrey\n\n\n340\n169.78\n94.35\nGreen\n\n\n341\n169.27\n59.98\nGrey\n\n\n342\n173.28\n75.23\nGreen\n\n\n343\n175.18\n97.06\nBlue\n\n\n344\n169.39\n73.95\nBrown\n\n\n345\n172.04\n70.90\nBrown\n\n\n346\n161.62\n96.00\nGrey\n\n\n347\n167.23\n89.55\nGrey\n\n\n348\n168.43\n76.65\nGrey\n\n\n349\n165.32\n81.25\nBrown\n\n\n350\n170.01\n70.74\nGreen\n\n\n351\n173.34\n68.53\nGreen\n\n\n352\n176.02\n77.40\nBlue\n\n\n353\n180.56\n78.09\nBlue\n\n\n354\n170.24\n80.80\nBlue\n\n\n355\n158.60\n103.87\nGreen\n\n\n356\n174.98\n78.75\nGrey\n\n\n357\n168.61\n72.29\nGreen\n\n\n358\n170.10\n68.90\nBlue\n\n\n359\n174.01\n77.02\nBlue\n\n\n360\n164.99\n72.64\nGrey\n\n\n361\n159.98\n83.14\nGrey\n\n\n362\n175.54\n96.49\nGreen\n\n\n363\n179.56\n96.62\nGrey\n\n\n364\n165.69\n91.31\nBlue\n\n\n365\n173.79\n85.11\nGreen\n\n\n366\n187.49\n100.73\nBrown\n\n\n367\n160.26\n76.32\nGreen\n\n\n368\n173.90\n73.22\nGreen\n\n\n369\n172.34\n87.56\nBrown\n\n\n370\n167.85\n71.15\nBrown\n\n\n371\n164.94\n78.22\nBlue\n\n\n372\n168.43\n100.49\nGreen\n\n\n373\n170.77\n61.10\nGreen\n\n\n374\n165.16\n94.65\nGrey\n\n\n375\n181.06\n82.71\nBlue\n\n\n376\n180.98\n69.60\nGreen\n\n\n377\n165.63\n102.78\nBrown\n\n\n378\n173.88\n84.07\nBlue\n\n\n379\n161.95\n77.01\nGreen\n\n\n380\n154.79\n90.84\nBrown\n\n\n381\n172.77\n86.06\nBrown\n\n\n382\n167.95\n80.49\nBlue\n\n\n383\n172.97\n101.62\nGrey\n\n\n384\n171.57\n87.71\nGrey\n\n\n385\n176.72\n75.32\nBlue\n\n\n386\n164.06\n87.94\nGreen\n\n\n387\n172.79\n83.01\nBlue\n\n\n388\n175.86\n75.64\nBrown\n\n\n389\n167.42\n92.96\nBlue\n\n\n390\n162.53\n65.76\nGreen\n\n\n391\n168.44\n74.42\nGreen\n\n\n392\n167.32\n84.70\nBrown\n\n\n393\n182.32\n69.11\nBlue\n\n\n394\n165.47\n77.11\nGrey\n\n\n395\n173.39\n78.83\nBrown\n\n\n396\n176.25\n63.43\nGrey\n\n\n397\n172.76\n78.82\nBrown\n\n\n398\n165.97\n87.00\nBrown\n\n\n399\n161.92\n72.14\nBlue\n\n\n400\n170.86\n74.11\nGreen\n\n\n401\n167.52\n92.29\nGrey\n\n\n402\n164.94\n84.64\nGreen\n\n\n403\n168.27\n79.70\nBlue\n\n\n404\n171.15\n79.21\nGrey\n\n\n405\n175.77\n74.46\nBlue\n\n\n406\n168.97\n89.02\nBrown\n\n\n407\n158.81\n80.27\nBlue\n\n\n408\n174.03\n89.98\nBrown\n\n\n409\n169.40\n86.23\nGrey\n\n\n410\n165.39\n71.14\nGrey\n\n\n411\n169.39\n69.60\nBlue\n\n\n412\n169.70\n64.77\nGrey\n\n\n413\n169.33\n55.84\nGreen\n\n\n414\n166.31\n66.28\nBlue\n\n\n415\n171.87\n82.67\nBlue\n\n\n416\n169.81\n85.32\nBlue\n\n\n417\n165.96\n98.49\nBrown\n\n\n418\n170.11\n82.69\nGreen\n\n\n419\n172.79\n71.13\nGreen\n\n\n420\n151.57\n74.58\nGreen\n\n\n421\n170.07\n77.48\nBlue\n\n\n422\n175.22\n86.84\nGrey\n\n\n423\n167.23\n83.74\nBlue\n\n\n424\n167.22\n71.24\nGreen\n\n\n425\n170.32\n75.31\nBlue\n\n\n426\n171.78\n73.14\nBrown\n\n\n427\n167.27\n59.76\nGrey\n\n\n428\n171.14\n86.26\nBrown\n\n\n429\n163.64\n86.49\nBlue\n\n\n430\n168.21\n80.75\nBlue\n\n\n431\n173.15\n90.29\nBrown\n\n\n432\n179.22\n77.37\nBrown\n\n\n433\n167.71\n87.98\nBrown\n\n\n434\n164.39\n72.47\nGrey\n\n\n435\n162.67\n92.86\nGreen\n\n\n436\n167.86\n82.60\nBrown\n\n\n437\n175.16\n89.60\nBlue\n\n\n438\n171.33\n76.94\nGrey\n\n\n439\n170.80\n92.12\nBlue\n\n\n440\n153.98\n63.60\nBlue\n\n\n441\n176.48\n91.12\nBrown\n\n\n442\n165.54\n86.03\nGrey\n\n\n443\n170.35\n71.17\nGrey\n\n\n444\n164.12\n69.42\nGreen\n\n\n445\n166.53\n92.79\nBlue\n\n\n446\n161.65\n80.08\nGrey\n\n\n447\n162.83\n71.39\nGrey\n\n\n448\n154.30\n73.71\nBlue\n\n\n449\n171.31\n96.96\nGrey\n\n\n450\n170.92\n92.17\nGrey\n\n\n451\n176.17\n80.38\nBlue\n\n\n452\n164.79\n85.05\nGrey\n\n\n453\n172.76\n89.85\nBlue\n\n\n454\n172.17\n90.20\nGrey\n\n\n455\n169.22\n80.94\nBlue\n\n\n456\n174.34\n89.89\nGrey\n\n\n457\n159.21\n85.14\nGreen\n\n\n458\n159.25\n84.37\nBrown\n\n\n459\n178.79\n85.92\nBrown\n\n\n460\n170.75\n100.58\nGreen\n\n\n461\n174.01\n87.50\nGreen\n\n\n462\n170.14\n60.14\nBlue\n\n\n463\n166.26\n92.74\nGrey\n\n\n464\n158.56\n86.13\nBlue\n\n\n465\n172.19\n66.96\nBrown\n\n\n466\n180.26\n58.91\nGreen\n\n\n467\n173.94\n76.43\nGreen\n\n\n468\n174.47\n82.83\nBrown\n\n\n469\n174.15\n75.78\nGreen\n\n\n470\n178.28\n77.57\nBlue\n\n\n471\n167.32\n76.81\nBrown\n\n\n472\n167.55\n74.71\nBrown\n\n\n473\n174.61\n80.27\nGreen\n\n\n474\n173.82\n76.83\nBlue\n\n\n475\n167.19\n79.44\nGreen\n\n\n476\n177.24\n93.01\nBlue\n\n\n477\n176.86\n82.12\nGreen\n\n\n478\n179.92\n65.61\nBlue\n\n\n479\n172.28\n93.04\nGreen\n\n\n480\n171.46\n89.48\nGreen\n\n\n481\n172.67\n79.50\nGreen\n\n\n482\n166.06\n77.27\nGreen\n\n\n483\n176.50\n77.26\nBrown\n\n\n484\n156.14\n92.50\nBlue\n\n\n485\n174.33\n63.12\nGreen\n\n\n486\n165.67\n86.60\nBrown\n\n\n487\n182.18\n67.37\nGreen\n\n\n488\n168.91\n86.88\nBrown\n\n\n489\n168.06\n81.96\nBlue\n\n\n490\n168.13\n89.14\nGreen\n\n\n491\n165.28\n79.44\nGrey\n\n\n492\n162.20\n80.96\nGreen\n\n\n493\n168.13\n102.88\nGrey\n\n\n494\n167.04\n82.09\nBrown\n\n\n495\n171.84\n77.24\nGrey\n\n\n496\n184.84\n88.92\nGreen\n\n\n497\n163.31\n75.80\nGrey\n\n\n498\n168.68\n62.92\nBlue\n\n\n499\n164.68\n87.64\nBrown\n\n\n500\n168.44\n80.81\nBrown\n\n\n501\n170.56\n79.15\nGrey\n\n\n502\n170.47\n80.63\nBrown\n\n\n503\n175.32\n78.17\nGrey\n\n\n504\n158.59\n74.18\nBrown\n\n\n505\n165.56\n80.54\nGrey\n\n\n506\n169.45\n94.18\nGreen\n\n\n507\n178.75\n85.72\nGreen\n\n\n508\n162.96\n74.55\nGrey\n\n\n509\n178.21\n73.44\nBlue\n\n\n510\n174.59\n72.40\nBlue\n\n\n511\n165.34\n56.60\nBlue\n\n\n512\n163.03\n86.26\nBrown\n\n\n513\n169.64\n95.38\nGrey\n\n\n514\n164.10\n70.94\nBlue\n\n\n515\n176.51\n62.65\nGreen\n\n\n516\n171.61\n78.36\nBlue\n\n\n517\n172.94\n84.12\nBrown\n\n\n518\n171.89\n87.12\nGreen\n\n\n519\n170.93\n94.28\nGreen\n\n\n520\n177.57\n67.06\nGreen\n\n\n521\n160.03\n78.09\nGreen\n\n\n522\n169.60\n88.06\nGreen\n\n\n523\n173.22\n78.78\nGrey\n\n\n524\n170.88\n93.96\nBlue\n\n\n525\n176.22\n85.53\nGrey\n\n\n526\n161.18\n80.51\nBrown\n\n\n527\n177.53\n71.20\nGreen\n\n\n528\n169.75\n59.59\nBrown\n\n\n529\n176.47\n72.47\nGreen\n\n\n530\n169.93\n73.92\nBrown\n\n\n531\n171.35\n88.80\nBrown\n\n\n532\n154.61\n87.71\nGreen\n\n\n533\n169.48\n100.93\nBlue\n\n\n534\n159.87\n83.71\nBrown\n\n\n535\n181.63\n71.47\nBlue\n\n\n536\n172.27\n76.68\nGreen\n\n\n537\n169.75\n91.72\nBrown\n\n\n538\n172.92\n84.89\nBlue\n\n\n539\n168.23\n96.27\nBlue\n\n\n540\n170.28\n99.65\nGrey\n\n\n541\n178.00\n93.20\nGreen\n\n\n542\n167.68\n78.06\nGreen\n\n\n543\n178.57\n75.86\nGrey\n\n\n544\n161.43\n90.47\nBlue\n\n\n545\n168.57\n87.13\nGreen\n\n\n546\n169.03\n78.56\nBrown\n\n\n547\n176.40\n69.67\nGrey\n\n\n548\n164.51\n73.67\nGrey\n\n\n549\n175.72\n98.95\nBrown\n\n\n550\n164.30\n86.90\nGrey\n\n\n551\n179.74\n75.47\nGrey\n\n\n552\n169.85\n89.23\nBlue\n\n\n553\n164.25\n87.27\nGreen\n\n\n554\n163.10\n76.19\nGrey\n\n\n555\n175.64\n88.12\nBrown\n\n\n556\n169.75\n73.06\nGreen\n\n\n557\n163.19\n95.33\nBrown\n\n\n558\n163.43\n87.91\nGrey\n\n\n559\n170.85\n107.88\nBrown\n\n\n560\n175.98\n66.96\nGrey\n\n\n561\n174.14\n79.59\nGrey\n\n\n562\n164.63\n93.77\nBrown\n\n\n563\n171.05\n83.14\nGrey\n\n\n564\n175.30\n80.91\nBlue\n\n\n565\n171.79\n77.92\nGreen\n\n\n566\n190.44\n81.94\nBlue\n\n\n567\n162.78\n81.46\nBlue\n\n\n568\n164.60\n77.69\nBlue\n\n\n569\n178.35\n67.43\nGrey\n\n\n570\n171.65\n78.93\nBrown\n\n\n571\n177.71\n89.10\nBrown\n\n\n572\n176.95\n78.05\nGrey\n\n\n573\n172.74\n70.49\nBlue\n\n\n574\n176.61\n77.40\nBlue\n\n\n575\n168.20\n77.70\nGreen\n\n\n576\n177.16\n76.00\nGreen\n\n\n577\n163.80\n80.86\nBlue\n\n\n578\n175.10\n82.01\nGrey\n\n\n579\n163.18\n75.15\nBlue\n\n\n580\n163.82\n75.95\nBlue\n\n\n581\n177.32\n78.83\nGrey\n\n\n582\n174.91\n71.80\nGrey\n\n\n583\n166.34\n70.16\nGreen\n\n\n584\n175.25\n65.76\nBrown\n\n\n585\n156.16\n86.63\nGreen\n\n\n586\n166.14\n69.57\nGreen\n\n\n587\n161.35\n82.06\nBlue\n\n\n588\n164.37\n68.86\nGreen\n\n\n589\n164.92\n76.66\nBlue\n\n\n590\n174.23\n82.38\nBrown\n\n\n591\n174.52\n70.99\nGrey\n\n\n592\n186.73\n77.90\nBrown\n\n\n593\n176.61\n66.73\nBrown\n\n\n594\n178.36\n79.33\nBlue\n\n\n595\n179.95\n88.37\nGreen\n\n\n596\n162.99\n67.45\nGreen\n\n\n597\n161.19\n69.84\nBlue\n\n\n598\n166.66\n73.27\nBlue\n\n\n599\n166.08\n76.23\nGrey\n\n\n600\n162.38\n93.61\nGreen\n\n\n601\n156.36\n93.38\nBlue\n\n\n602\n173.69\n82.56\nBrown\n\n\n603\n177.88\n71.49\nGreen\n\n\n604\n162.75\n71.58\nBlue\n\n\n605\n155.25\n79.86\nBrown\n\n\n606\n173.30\n74.63\nBlue\n\n\n607\n171.15\n85.35\nBlue\n\n\n608\n174.29\n81.74\nBlue\n\n\n609\n166.11\n77.77\nGrey\n\n\n610\n177.69\n71.63\nGrey\n\n\n611\n176.83\n97.28\nGreen\n\n\n612\n173.63\n66.37\nGrey\n\n\n613\n168.13\n84.93\nGreen\n\n\n614\n186.67\n89.01\nBlue\n\n\n615\n169.45\n91.76\nBlue\n\n\n616\n178.85\n64.77\nBlue\n\n\n617\n161.17\n68.79\nGrey\n\n\n618\n167.75\n63.01\nGreen\n\n\n619\n171.41\n88.07\nGrey\n\n\n620\n160.24\n79.17\nGrey\n\n\n621\n170.00\n84.39\nGrey\n\n\n622\n172.43\n90.57\nBlue\n\n\n623\n178.24\n82.11\nGreen\n\n\n624\n174.22\n85.25\nBrown\n\n\n625\n180.30\n77.02\nGreen\n\n\n626\n174.27\n89.12\nBrown\n\n\n627\n170.56\n82.55\nGreen\n\n\n628\n176.39\n76.38\nGrey\n\n\n629\n163.32\n65.88\nGreen\n\n\n630\n170.75\n74.43\nGrey\n\n\n631\n160.66\n61.51\nBlue\n\n\n632\n172.63\n83.80\nBrown\n\n\n633\n166.59\n92.43\nBlue\n\n\n634\n169.93\n67.27\nGreen\n\n\n635\n175.05\n77.63\nGrey\n\n\n636\n178.56\n60.04\nBlue\n\n\n637\n168.06\n66.69\nGrey\n\n\n638\n170.22\n73.47\nBlue\n\n\n639\n176.07\n75.65\nBlue\n\n\n640\n166.89\n70.63\nBlue\n\n\n641\n167.15\n62.59\nBlue\n\n\n642\n168.53\n79.38\nBlue\n\n\n643\n172.10\n74.06\nGrey\n\n\n644\n174.17\n63.32\nGrey\n\n\n645\n174.77\n87.55\nGrey\n\n\n646\n176.97\n80.21\nBlue\n\n\n647\n164.17\n79.90\nGrey\n\n\n648\n171.23\n71.95\nGrey\n\n\n649\n178.24\n71.82\nGreen\n\n\n650\n153.72\n72.64\nBrown\n\n\n651\n162.70\n82.01\nBrown\n\n\n652\n170.51\n89.57\nGreen\n\n\n653\n163.95\n68.58\nBrown\n\n\n654\n162.51\n83.46\nGrey\n\n\n655\n164.24\n82.45\nBrown\n\n\n656\n167.54\n83.40\nBrown\n\n\n657\n180.75\n81.15\nBlue\n\n\n658\n169.94\n91.08\nBrown\n\n\n659\n174.52\n73.70\nBrown\n\n\n660\n163.22\n95.60\nBrown\n\n\n661\n175.33\n74.50\nGreen\n\n\n662\n171.08\n62.38\nBrown\n\n\n663\n171.09\n77.07\nBlue\n\n\n664\n170.31\n66.84\nBrown\n\n\n665\n172.64\n95.30\nBrown\n\n\n666\n174.63\n76.54\nBlue\n\n\n667\n169.94\n84.62\nBrown\n\n\n668\n176.14\n63.09\nBrown\n\n\n669\n174.21\n66.37\nGrey\n\n\n670\n172.13\n84.67\nBrown\n\n\n671\n169.09\n84.65\nBrown\n\n\n672\n169.38\n74.12\nBlue\n\n\n673\n168.05\n82.06\nBrown\n\n\n674\n162.81\n88.53\nBrown\n\n\n675\n171.95\n88.09\nBlue\n\n\n676\n170.11\n73.98\nBrown\n\n\n677\n175.39\n91.79\nGreen\n\n\n678\n174.19\n82.75\nGreen\n\n\n679\n167.34\n86.30\nBrown\n\n\n680\n168.52\n98.53\nBlue\n\n\n681\n176.53\n92.44\nBrown\n\n\n682\n166.62\n78.45\nBlue\n\n\n683\n161.31\n62.22\nGrey\n\n\n684\n166.47\n70.96\nBlue\n\n\n685\n180.05\n73.98\nBlue\n\n\n686\n168.94\n89.70\nGreen\n\n\n687\n169.79\n80.33\nBlue\n\n\n688\n168.25\n74.68\nBlue\n\n\n689\n164.29\n82.73\nBlue\n\n\n690\n171.67\n91.56\nBrown\n\n\n691\n174.31\n77.22\nBrown\n\n\n692\n172.06\n71.97\nBlue\n\n\n693\n161.57\n72.75\nBlue\n\n\n694\n164.84\n76.83\nBlue\n\n\n695\n172.66\n67.10\nGreen\n\n\n696\n162.87\n49.90\nBlue\n\n\n697\n163.19\n78.14\nBrown\n\n\n698\n164.02\n96.30\nGreen\n\n\n699\n183.65\n99.65\nBrown\n\n\n700\n175.41\n82.76\nBrown\n\n\n701\n174.07\n80.72\nBlue\n\n\n702\n174.03\n94.90\nBrown\n\n\n703\n167.99\n56.45\nBrown\n\n\n704\n173.09\n78.02\nGreen\n\n\n705\n171.77\n99.21\nBrown\n\n\n706\n179.12\n73.48\nGreen\n\n\n707\n174.09\n70.61\nBlue\n\n\n708\n161.14\n77.89\nGrey\n\n\n709\n174.88\n73.97\nBlue\n\n\n710\n170.58\n73.96\nBlue\n\n\n711\n170.48\n80.32\nGrey\n\n\n712\n179.76\n93.34\nGreen\n\n\n713\n170.23\n85.36\nBlue\n\n\n714\n168.76\n87.17\nBlue\n\n\n715\n172.88\n81.29\nGreen\n\n\n716\n172.18\n89.87\nGreen\n\n\n717\n171.80\n76.74\nBrown\n\n\n718\n166.94\n73.91\nBrown\n\n\n719\n165.70\n90.13\nGreen\n\n\n720\n171.07\n70.05\nBlue\n\n\n721\n164.01\n66.34\nBlue\n\n\n722\n168.21\n70.46\nBrown\n\n\n723\n171.18\n79.93\nBrown\n\n\n724\n164.36\n78.43\nBrown\n\n\n725\n166.96\n95.54\nBlue\n\n\n726\n163.79\n87.12\nBlue\n\n\n727\n165.65\n70.37\nBrown\n\n\n728\n175.15\n81.44\nGrey\n\n\n729\n174.15\n84.45\nBrown\n\n\n730\n180.04\n92.50\nGreen\n\n\n731\n170.75\n92.74\nBlue\n\n\n732\n168.77\n88.26\nBrown\n\n\n733\n164.22\n71.09\nGreen\n\n\n734\n162.97\n76.52\nBrown\n\n\n735\n176.71\n77.90\nGrey\n\n\n736\n176.80\n71.54\nBlue\n\n\n737\n165.90\n90.97\nGreen\n\n\n738\n172.60\n79.67\nBlue\n\n\n739\n167.44\n80.15\nGrey\n\n\n740\n165.58\n90.47\nBlue\n\n\n741\n173.97\n68.93\nGreen\n\n\n742\n171.99\n75.40\nGrey\n\n\n743\n172.34\n78.00\nGreen\n\n\n744\n179.89\n103.31\nBlue\n\n\n745\n167.02\n74.14\nBlue\n\n\n746\n172.16\n54.04\nBlue\n\n\n747\n176.38\n70.12\nGrey\n\n\n748\n170.93\n82.14\nGrey\n\n\n749\n167.08\n91.17\nBrown\n\n\n750\n164.93\n82.62\nBlue\n\n\n751\n175.88\n76.24\nGrey\n\n\n752\n166.28\n83.51\nBrown\n\n\n753\n170.95\n75.33\nGreen\n\n\n754\n179.68\n66.80\nGreen\n\n\n755\n169.16\n93.42\nBrown\n\n\n756\n168.96\n90.89\nBlue\n\n\n757\n163.47\n93.37\nBrown\n\n\n758\n171.15\n71.93\nBrown\n\n\n759\n167.40\n75.02\nBlue\n\n\n760\n161.63\n102.45\nGrey\n\n\n761\n180.13\n77.66\nBrown\n\n\n762\n178.47\n80.87\nBlue\n\n\n763\n169.63\n75.21\nGrey\n\n\n764\n176.56\n86.78\nGreen\n\n\n765\n177.74\n82.43\nGrey\n\n\n766\n169.19\n69.64\nGreen\n\n\n767\n164.83\n97.09\nBrown\n\n\n768\n163.19\n89.89\nBlue\n\n\n769\n165.76\n85.69\nBlue\n\n\n770\n173.29\n72.52\nGreen\n\n\n771\n167.18\n77.84\nGrey\n\n\n772\n172.95\n78.55\nGreen\n\n\n773\n176.74\n74.88\nBlue\n\n\n774\n177.22\n87.75\nGrey\n\n\n775\n166.53\n74.29\nGreen\n\n\n776\n160.60\n67.70\nGreen\n\n\n777\n176.38\n88.54\nGreen\n\n\n778\n174.40\n85.31\nBrown\n\n\n779\n165.25\n91.00\nGreen\n\n\n780\n177.43\n89.33\nBlue\n\n\n781\n167.65\n63.56\nGreen\n\n\n782\n177.33\n94.90\nGrey\n\n\n783\n170.09\n86.71\nGreen\n\n\n784\n165.35\n77.97\nGreen\n\n\n785\n170.60\n76.48\nGrey\n\n\n786\n162.26\n67.41\nGreen\n\n\n787\n167.22\n84.14\nGreen\n\n\n788\n175.02\n74.77\nGreen\n\n\n789\n168.25\n82.26\nBrown\n\n\n790\n179.58\n82.23\nBrown\n\n\n791\n166.60\n63.60\nGrey\n\n\n792\n183.53\n93.09\nGreen\n\n\n793\n162.68\n87.86\nBlue\n\n\n794\n162.25\n78.41\nGrey\n\n\n795\n166.39\n86.34\nBlue\n\n\n796\n168.94\n76.32\nGrey\n\n\n797\n169.38\n66.64\nGreen\n\n\n798\n160.81\n80.23\nBrown\n\n\n799\n175.86\n103.65\nBlue\n\n\n800\n173.55\n75.50\nGreen\n\n\n801\n175.93\n78.76\nBrown\n\n\n802\n174.23\n72.99\nGreen\n\n\n803\n155.07\n78.15\nBrown\n\n\n804\n154.94\n91.89\nGreen\n\n\n805\n181.97\n85.87\nBlue\n\n\n806\n168.37\n78.18\nBlue\n\n\n807\n168.38\n84.86\nGrey\n\n\n808\n164.10\n86.29\nBrown\n\n\n809\n176.51\n83.06\nBrown\n\n\n810\n169.17\n70.59\nBlue\n\n\n811\n165.30\n88.88\nGreen\n\n\n812\n152.73\n106.71\nGrey\n\n\n813\n162.30\n78.38\nGrey\n\n\n814\n169.78\n88.09\nGreen\n\n\n815\n156.24\n69.05\nBrown\n\n\n816\n173.76\n84.85\nBrown\n\n\n817\n167.88\n68.38\nGrey\n\n\n818\n173.61\n80.97\nBrown\n\n\n819\n173.97\n65.25\nBrown\n\n\n820\n170.20\n72.93\nGreen\n\n\n821\n163.11\n76.60\nGreen\n\n\n822\n168.18\n79.78\nGreen\n\n\n823\n180.30\n74.17\nBrown\n\n\n824\n178.59\n108.06\nGrey\n\n\n825\n175.04\n93.19\nBlue\n\n\n826\n166.47\n83.47\nGreen\n\n\n827\n167.79\n103.34\nGreen\n\n\n828\n168.53\n87.19\nGreen\n\n\n829\n173.41\n85.98\nGreen\n\n\n830\n177.26\n71.78\nGreen\n\n\n831\n165.19\n73.09\nGrey\n\n\n832\n160.25\n79.25\nBrown\n\n\n833\n166.17\n75.82\nBlue\n\n\n834\n165.99\n90.73\nBrown\n\n\n835\n174.01\n93.04\nGrey\n\n\n836\n170.75\n73.70\nGreen\n\n\n837\n165.53\n76.12\nGrey\n\n\n838\n163.12\n79.36\nBrown\n\n\n839\n175.52\n104.40\nGrey\n\n\n840\n162.10\n82.79\nGrey\n\n\n841\n170.70\n81.55\nGrey\n\n\n842\n179.68\n80.26\nGrey\n\n\n843\n173.63\n74.21\nBlue\n\n\n844\n164.29\n95.37\nBlue\n\n\n845\n176.13\n65.54\nGrey\n\n\n846\n166.36\n95.99\nBlue\n\n\n847\n159.11\n95.86\nGrey\n\n\n848\n161.11\n82.53\nGreen\n\n\n849\n168.29\n75.64\nBlue\n\n\n850\n169.12\n92.68\nGrey\n\n\n851\n178.47\n79.49\nBlue\n\n\n852\n164.98\n84.26\nBrown\n\n\n853\n167.15\n91.39\nBrown\n\n\n854\n174.75\n89.21\nBlue\n\n\n855\n173.06\n96.82\nGrey\n\n\n856\n170.89\n85.34\nGreen\n\n\n857\n176.36\n81.04\nGreen\n\n\n858\n159.71\n89.90\nGreen\n\n\n859\n179.42\n74.60\nBrown\n\n\n860\n171.31\n77.28\nBrown\n\n\n861\n175.87\n79.65\nGrey\n\n\n862\n172.01\n73.07\nGreen\n\n\n863\n172.25\n88.08\nGreen\n\n\n864\n174.65\n103.53\nGrey\n\n\n865\n169.25\n87.58\nBlue\n\n\n866\n174.45\n76.70\nGrey\n\n\n867\n168.06\n73.86\nGreen\n\n\n868\n168.20\n94.57\nBrown\n\n\n869\n174.37\n83.11\nBrown\n\n\n870\n177.28\n84.83\nGreen\n\n\n871\n161.53\n68.31\nBlue\n\n\n872\n176.04\n82.64\nBlue\n\n\n873\n168.29\n89.21\nBrown\n\n\n874\n171.79\n84.39\nGrey\n\n\n875\n161.65\n64.42\nGrey\n\n\n876\n167.76\n72.40\nBlue\n\n\n877\n165.00\n85.91\nBlue\n\n\n878\n169.62\n86.85\nGreen\n\n\n879\n164.89\n86.33\nBrown\n\n\n880\n172.45\n92.88\nBlue\n\n\n881\n177.68\n82.90\nGrey\n\n\n882\n171.01\n73.70\nBrown\n\n\n883\n172.80\n70.30\nGreen\n\n\n884\n162.82\n78.72\nGrey\n\n\n885\n172.07\n78.42\nBrown\n\n\n886\n167.53\n76.82\nGreen\n\n\n887\n166.53\n61.72\nBrown\n\n\n888\n175.83\n82.41\nBrown\n\n\n889\n175.85\n78.54\nBlue\n\n\n890\n172.35\n77.06\nGreen\n\n\n891\n159.89\n72.25\nBlue\n\n\n892\n168.86\n74.20\nGreen\n\n\n893\n168.82\n84.83\nGrey\n\n\n894\n162.43\n76.83\nGrey\n\n\n895\n171.67\n78.62\nGreen\n\n\n896\n170.28\n84.15\nGrey\n\n\n897\n164.97\n92.02\nGrey\n\n\n898\n173.88\n79.34\nGrey\n\n\n899\n169.67\n89.66\nBlue\n\n\n900\n161.69\n75.16\nBlue\n\n\n901\n172.27\n85.13\nBrown\n\n\n902\n169.54\n91.62\nGreen\n\n\n903\n168.60\n77.12\nGrey\n\n\n904\n182.19\n95.20\nBrown\n\n\n905\n168.41\n96.50\nGrey\n\n\n906\n172.94\n88.94\nGreen\n\n\n907\n161.49\n74.56\nGreen\n\n\n908\n173.85\n76.79\nGreen\n\n\n909\n174.67\n68.89\nBlue\n\n\n910\n170.00\n79.42\nGreen\n\n\n911\n173.66\n69.17\nGrey\n\n\n912\n171.71\n75.47\nGreen\n\n\n913\n176.86\n86.89\nBrown\n\n\n914\n177.43\n83.44\nGrey\n\n\n915\n176.72\n87.39\nGrey\n\n\n916\n163.52\n85.04\nGreen\n\n\n917\n167.98\n64.71\nBlue\n\n\n918\n169.84\n68.25\nBrown\n\n\n919\n181.70\n86.95\nGrey\n\n\n920\n168.66\n87.02\nGreen\n\n\n921\n178.01\n76.09\nGrey\n\n\n922\n172.97\n86.43\nBlue\n\n\n923\n163.88\n94.98\nBlue\n\n\n924\n175.91\n70.74\nGreen\n\n\n925\n175.02\n83.33\nGrey\n\n\n926\n166.03\n74.03\nGrey\n\n\n927\n168.75\n68.48\nGrey\n\n\n928\n169.23\n91.66\nGrey\n\n\n929\n180.73\n84.52\nBlue\n\n\n930\n171.83\n84.99\nBrown\n\n\n931\n175.38\n84.91\nBrown\n\n\n932\n174.40\n68.84\nGrey\n\n\n933\n169.82\n84.77\nGrey\n\n\n934\n167.19\n86.10\nBrown\n\n\n935\n179.94\n82.12\nBlue\n\n\n936\n164.61\n83.94\nBrown\n\n\n937\n165.90\n80.76\nGreen\n\n\n938\n168.49\n62.05\nGreen\n\n\n939\n171.94\n62.71\nBlue\n\n\n940\n166.10\n70.15\nGreen\n\n\n941\n179.36\n67.38\nGrey\n\n\n942\n170.49\n72.80\nGreen\n\n\n943\n169.66\n72.84\nBrown\n\n\n944\n165.70\n67.24\nGreen\n\n\n945\n167.07\n69.70\nGreen\n\n\n946\n167.18\n85.68\nGreen\n\n\n947\n176.69\n71.44\nBlue\n\n\n948\n167.44\n82.49\nGreen\n\n\n949\n174.51\n86.17\nGrey\n\n\n950\n165.77\n80.27\nBrown\n\n\n951\n159.22\n69.53\nBrown\n\n\n952\n158.99\n81.21\nGrey\n\n\n953\n167.96\n94.78\nBlue\n\n\n954\n166.47\n57.39\nBlue\n\n\n955\n165.49\n77.38\nGrey\n\n\n956\n161.26\n77.51\nBrown\n\n\n957\n171.96\n71.25\nBrown\n\n\n958\n171.74\n74.65\nBlue\n\n\n959\n165.00\n64.00\nGrey\n\n\n960\n175.32\n94.93\nGrey\n\n\n961\n168.47\n70.10\nBrown\n\n\n962\n169.96\n76.55\nGreen\n\n\n963\n159.99\n85.83\nBrown\n\n\n964\n182.92\n68.42\nBlue\n\n\n965\n166.44\n77.82\nGrey\n\n\n966\n168.62\n79.84\nGrey\n\n\n967\n172.09\n61.65\nBlue\n\n\n968\n175.73\n76.45\nBrown\n\n\n969\n168.53\n93.80\nBlue\n\n\n970\n156.00\n90.44\nGrey\n\n\n971\n166.66\n60.89\nBrown\n\n\n972\n161.20\n56.18\nGreen\n\n\n973\n179.80\n77.04\nBrown\n\n\n974\n164.49\n82.16\nGreen\n\n\n975\n164.97\n77.10\nGreen\n\n\n976\n166.25\n72.15\nBlue\n\n\n977\n165.78\n84.93\nBlue\n\n\n978\n159.43\n77.98\nGreen\n\n\n979\n165.40\n108.75\nGrey\n\n\n980\n168.26\n83.79\nGrey\n\n\n981\n171.39\n91.25\nGrey\n\n\n982\n176.38\n70.61\nGreen\n\n\n983\n174.40\n85.17\nGrey\n\n\n984\n169.76\n73.37\nGreen\n\n\n985\n158.29\n96.39\nGrey\n\n\n986\n177.91\n83.13\nGrey\n\n\n987\n167.58\n72.57\nGreen\n\n\n988\n158.10\n67.28\nGrey\n\n\n989\n170.73\n95.74\nBrown\n\n\n990\n165.32\n89.17\nBrown\n\n\n991\n175.11\n72.74\nGrey\n\n\n992\n167.17\n88.95\nGreen\n\n\n993\n172.26\n104.35\nGrey\n\n\n994\n162.35\n60.29\nBrown\n\n\n995\n162.48\n90.76\nGreen\n\n\n996\n174.42\n85.16\nBlue\n\n\n997\n169.26\n72.03\nBrown\n\n\n998\n178.41\n75.57\nGrey\n\n\n999\n167.06\n77.55\nBlue\n\n\n1000\n169.07\n92.08\nBlue"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#random-assignment",
    "href": "content/slides/01-07-experiments.html#random-assignment",
    "title": "Causal Effects and Experiments",
    "section": "Random assignment",
    "text": "Random assignment\nI’m now going to flip (an imaginary, computer-generated) coin for each of these 1,000 individuals to assigned them to group A or B:\n\n\n\n\n\nID\nHeight\nWeight\nEye colour\nGroup\n\n\n\n\n1\n170.62\n77.78\nBrown\nA\n\n\n2\n174.04\n49.24\nBrown\nA\n\n\n3\n171.12\n85.96\nGrey\nA\n\n\n4\n166.27\n89.28\nGrey\nB\n\n\n5\n169.99\n103.33\nBrown\nA\n\n\n6\n165.38\n84.37\nBrown\nB\n\n\n7\n171.92\n80.29\nGreen\nA\n\n\n8\n173.02\n97.12\nBlue\nA\n\n\n9\n165.83\n91.32\nGreen\nB\n\n\n10\n163.81\n89.87\nBrown\nA\n\n\n11\n165.78\n74.25\nGreen\nB\n\n\n12\n175.28\n99.72\nGrey\nB\n\n\n13\n171.90\n95.85\nBlue\nB\n\n\n14\n171.11\n63.92\nBrown\nB\n\n\n15\n167.29\n66.29\nGrey\nB\n\n\n16\n167.43\n97.85\nBlue\nB\n\n\n17\n166.59\n77.91\nGrey\nB\n\n\n18\n169.54\n89.53\nGrey\nA\n\n\n19\n162.91\n81.23\nBrown\nB\n\n\n20\n156.62\n71.98\nGrey\nB\n\n\n21\n168.07\n83.66\nBrown\nB\n\n\n22\n167.72\n81.11\nBlue\nA\n\n\n23\n173.65\n78.10\nGreen\nA\n\n\n24\n171.84\n74.55\nGrey\nA\n\n\n25\n161.53\n70.32\nBrown\nA\n\n\n26\n167.05\n90.10\nBrown\nB\n\n\n27\n172.42\n88.43\nBlue\nA\n\n\n28\n176.32\n63.16\nGrey\nA\n\n\n29\n181.28\n87.74\nGreen\nB\n\n\n30\n171.20\n63.42\nBrown\nB\n\n\n31\n166.78\n74.78\nBlue\nB\n\n\n32\n168.40\n80.77\nGreen\nA\n\n\n33\n167.06\n78.07\nGrey\nB\n\n\n34\n162.80\n69.65\nBlue\nA\n\n\n35\n154.76\n84.17\nBrown\nA\n\n\n36\n163.79\n86.04\nBrown\nB\n\n\n37\n158.00\n82.08\nGreen\nB\n\n\n38\n170.47\n68.50\nBlue\nA\n\n\n39\n170.56\n77.96\nBlue\nB\n\n\n40\n180.94\n94.93\nGreen\nA\n\n\n41\n167.84\n95.25\nBrown\nA\n\n\n42\n167.48\n99.63\nBrown\nA\n\n\n43\n167.45\n93.59\nGrey\nA\n\n\n44\n152.83\n88.78\nGrey\nA\n\n\n45\n169.91\n78.77\nGrey\nA\n\n\n46\n167.39\n75.19\nGreen\nA\n\n\n47\n163.90\n77.07\nGrey\nB\n\n\n48\n171.55\n75.64\nGreen\nB\n\n\n49\n169.16\n90.56\nGrey\nB\n\n\n50\n172.17\n72.51\nBlue\nA\n\n\n51\n176.74\n81.63\nBlue\nA\n\n\n52\n171.20\n76.86\nBlue\nA\n\n\n53\n175.02\n97.72\nBlue\nB\n\n\n54\n165.89\n87.05\nGreen\nB\n\n\n55\n159.78\n76.90\nGreen\nA\n\n\n56\n169.08\n81.10\nBrown\nB\n\n\n57\n172.15\n65.48\nBrown\nB\n\n\n58\n165.38\n81.77\nGreen\nB\n\n\n59\n164.43\n81.79\nGrey\nA\n\n\n60\n174.78\n74.47\nBrown\nA\n\n\n61\n182.01\n74.23\nGrey\nB\n\n\n62\n166.11\n79.51\nBrown\nA\n\n\n63\n174.10\n90.42\nGrey\nA\n\n\n64\n174.12\n82.12\nBlue\nA\n\n\n65\n169.17\n91.05\nGrey\nB\n\n\n66\n181.42\n77.08\nGreen\nB\n\n\n67\n176.10\n82.71\nBrown\nA\n\n\n68\n169.15\n78.50\nGrey\nB\n\n\n69\n172.27\n89.14\nBlue\nA\n\n\n70\n166.27\n74.35\nGreen\nA\n\n\n71\n168.44\n70.31\nGreen\nA\n\n\n72\n166.40\n95.56\nGrey\nB\n\n\n73\n167.81\n72.94\nBrown\nA\n\n\n74\n169.04\n86.17\nGreen\nA\n\n\n75\n170.34\n74.29\nGrey\nB\n\n\n76\n173.59\n85.34\nBrown\nB\n\n\n77\n160.20\n83.85\nGreen\nB\n\n\n78\n163.58\n99.63\nBlue\nA\n\n\n79\n170.72\n85.68\nGrey\nB\n\n\n80\n165.34\n94.12\nBrown\nA\n\n\n81\n177.27\n76.52\nGreen\nB\n\n\n82\n157.97\n69.20\nGrey\nA\n\n\n83\n180.20\n93.03\nBlue\nA\n\n\n84\n164.41\n80.35\nBlue\nB\n\n\n85\n171.17\n87.68\nGreen\nB\n\n\n86\n173.12\n91.04\nBrown\nA\n\n\n87\n170.82\n79.29\nBrown\nA\n\n\n88\n179.01\n70.03\nGreen\nB\n\n\n89\n173.40\n85.50\nGrey\nB\n\n\n90\n153.63\n85.02\nBlue\nA\n\n\n91\n157.98\n81.01\nGrey\nB\n\n\n92\n177.32\n90.66\nGrey\nA\n\n\n93\n169.64\n64.72\nGreen\nB\n\n\n94\n176.31\n79.63\nBlue\nA\n\n\n95\n173.12\n87.03\nGreen\nB\n\n\n96\n181.55\n94.48\nBrown\nA\n\n\n97\n164.51\n77.91\nGrey\nA\n\n\n98\n173.67\n70.98\nGreen\nA\n\n\n99\n185.87\n73.14\nBlue\nB\n\n\n100\n175.63\n106.73\nGreen\nA\n\n\n101\n170.16\n63.49\nBlue\nA\n\n\n102\n161.98\n92.24\nBlue\nA\n\n\n103\n164.81\n64.20\nBlue\nA\n\n\n104\n171.76\n91.59\nGrey\nB\n\n\n105\n173.45\n79.38\nBlue\nB\n\n\n106\n178.81\n85.98\nBlue\nB\n\n\n107\n169.10\n92.82\nGrey\nB\n\n\n108\n166.88\n91.30\nBlue\nA\n\n\n109\n173.63\n78.75\nBrown\nB\n\n\n110\n173.67\n54.60\nGreen\nB\n\n\n111\n164.05\n71.77\nGrey\nB\n\n\n112\n170.56\n85.79\nGreen\nA\n\n\n113\n161.59\n65.32\nGreen\nB\n\n\n114\n159.97\n79.96\nGreen\nA\n\n\n115\n167.57\n86.89\nGrey\nB\n\n\n116\n165.20\n86.76\nBlue\nA\n\n\n117\n162.48\n55.40\nGreen\nA\n\n\n118\n179.48\n91.55\nBlue\nB\n\n\n119\n167.69\n85.30\nBlue\nB\n\n\n120\n164.32\n86.76\nBlue\nB\n\n\n121\n176.56\n78.42\nGreen\nA\n\n\n122\n166.03\n68.93\nBlue\nB\n\n\n123\n175.66\n91.10\nGrey\nA\n\n\n124\n173.17\n95.23\nBlue\nA\n\n\n125\n175.84\n100.18\nBrown\nA\n\n\n126\n163.15\n75.93\nBlue\nA\n\n\n127\n170.37\n86.70\nGrey\nA\n\n\n128\n174.11\n85.43\nGrey\nB\n\n\n129\n164.79\n85.64\nGrey\nB\n\n\n130\n170.73\n76.34\nGrey\nA\n\n\n131\n186.59\n70.37\nBrown\nB\n\n\n132\n165.57\n75.13\nBlue\nA\n\n\n133\n169.04\n67.44\nBlue\nB\n\n\n134\n175.40\n101.61\nGreen\nB\n\n\n135\n172.84\n70.44\nBlue\nB\n\n\n136\n173.65\n73.54\nBrown\nA\n\n\n137\n165.04\n87.82\nGreen\nB\n\n\n138\n178.02\n82.15\nBrown\nB\n\n\n139\n170.15\n82.39\nGrey\nA\n\n\n140\n167.53\n68.22\nGreen\nA\n\n\n141\n161.17\n86.42\nBlue\nB\n\n\n142\n159.85\n76.22\nGreen\nA\n\n\n143\n177.30\n64.93\nGrey\nA\n\n\n144\n170.08\n91.70\nGreen\nB\n\n\n145\n171.94\n66.35\nGrey\nA\n\n\n146\n168.39\n84.10\nGreen\nA\n\n\n147\n181.65\n83.92\nBrown\nA\n\n\n148\n162.03\n63.61\nGreen\nA\n\n\n149\n173.01\n83.91\nGreen\nA\n\n\n150\n167.48\n94.82\nGrey\nB\n\n\n151\n162.33\n75.85\nGrey\nB\n\n\n152\n173.18\n75.34\nBlue\nA\n\n\n153\n174.91\n96.38\nBrown\nB\n\n\n154\n167.47\n90.25\nBlue\nB\n\n\n155\n174.41\n94.96\nGrey\nA\n\n\n156\n174.90\n78.69\nGrey\nB\n\n\n157\n171.82\n72.72\nGreen\nA\n\n\n158\n168.90\n81.85\nGrey\nA\n\n\n159\n162.98\n76.76\nBrown\nB\n\n\n160\n155.14\n89.70\nBlue\nB\n\n\n161\n165.63\n66.75\nBlue\nA\n\n\n162\n165.11\n94.75\nGrey\nB\n\n\n163\n178.82\n100.58\nBrown\nA\n\n\n164\n172.67\n75.55\nBrown\nB\n\n\n165\n170.26\n66.56\nGreen\nB\n\n\n166\n167.62\n84.77\nGrey\nB\n\n\n167\n163.63\n55.40\nBlue\nB\n\n\n168\n165.41\n79.29\nGrey\nB\n\n\n169\n174.51\n70.43\nGrey\nB\n\n\n170\n180.01\n70.95\nGreen\nB\n\n\n171\n177.35\n78.97\nBlue\nB\n\n\n172\n174.29\n52.47\nGreen\nB\n\n\n173\n166.63\n78.44\nGrey\nB\n\n\n174\n180.02\n75.06\nBlue\nB\n\n\n175\n168.21\n93.89\nGreen\nB\n\n\n176\n161.29\n67.78\nBrown\nB\n\n\n177\n172.94\n61.05\nGreen\nB\n\n\n178\n166.38\n89.27\nBrown\nA\n\n\n179\n175.07\n82.56\nGrey\nB\n\n\n180\n170.23\n87.77\nBlue\nA\n\n\n181\n175.95\n92.22\nBrown\nB\n\n\n182\n169.59\n78.52\nGrey\nA\n\n\n183\n174.96\n78.73\nBrown\nB\n\n\n184\n172.37\n83.49\nBlue\nA\n\n\n185\n175.60\n77.63\nGrey\nB\n\n\n186\n177.30\n56.96\nGreen\nA\n\n\n187\n176.32\n72.43\nBrown\nA\n\n\n188\n164.18\n63.03\nGreen\nA\n\n\n189\n164.53\n76.59\nGreen\nA\n\n\n190\n171.87\n60.85\nGreen\nB\n\n\n191\n172.65\n98.63\nGreen\nA\n\n\n192\n177.06\n79.33\nBlue\nA\n\n\n193\n171.54\n75.83\nBrown\nA\n\n\n194\n168.89\n74.78\nBlue\nB\n\n\n195\n163.36\n96.49\nGrey\nA\n\n\n196\n160.62\n84.62\nGrey\nA\n\n\n197\n165.65\n69.40\nBlue\nA\n\n\n198\n169.85\n84.64\nGreen\nA\n\n\n199\n156.28\n74.89\nGrey\nA\n\n\n200\n174.21\n86.76\nGrey\nA\n\n\n201\n170.00\n86.61\nBlue\nB\n\n\n202\n159.73\n76.70\nGreen\nB\n\n\n203\n164.18\n82.22\nBlue\nB\n\n\n204\n165.78\n92.82\nBrown\nA\n\n\n205\n165.10\n85.67\nGreen\nA\n\n\n206\n172.86\n83.77\nBrown\nB\n\n\n207\n169.74\n73.18\nGrey\nA\n\n\n208\n175.94\n81.90\nBlue\nA\n\n\n209\n162.98\n84.52\nBrown\nB\n\n\n210\n159.15\n73.38\nBlue\nB\n\n\n211\n169.32\n73.60\nBlue\nB\n\n\n212\n154.14\n71.95\nBlue\nA\n\n\n213\n172.24\n75.03\nBrown\nA\n\n\n214\n154.08\n90.05\nBrown\nB\n\n\n215\n167.74\n91.83\nGrey\nA\n\n\n216\n170.58\n76.46\nBlue\nB\n\n\n217\n166.15\n77.12\nGrey\nB\n\n\n218\n178.03\n89.99\nBrown\nB\n\n\n219\n164.31\n95.61\nBrown\nA\n\n\n220\n178.09\n87.15\nBlue\nA\n\n\n221\n168.28\n76.83\nBrown\nA\n\n\n222\n178.79\n69.79\nGrey\nA\n\n\n223\n163.44\n82.43\nGrey\nB\n\n\n224\n175.38\n72.01\nGreen\nB\n\n\n225\n180.53\n72.40\nGrey\nA\n\n\n226\n176.48\n79.89\nGrey\nA\n\n\n227\n173.83\n71.29\nBrown\nA\n\n\n228\n163.92\n97.71\nBlue\nA\n\n\n229\n169.49\n81.67\nGreen\nA\n\n\n230\n167.89\n76.51\nGrey\nA\n\n\n231\n164.06\n77.95\nBlue\nA\n\n\n232\n177.57\n60.08\nBrown\nA\n\n\n233\n170.36\n93.87\nGreen\nA\n\n\n234\n163.29\n78.48\nBrown\nB\n\n\n235\n162.85\n84.71\nBrown\nB\n\n\n236\n159.09\n75.07\nBlue\nA\n\n\n237\n171.42\n65.11\nBlue\nA\n\n\n238\n168.34\n83.67\nGrey\nA\n\n\n239\n172.22\n80.99\nBlue\nA\n\n\n240\n166.33\n83.19\nBlue\nB\n\n\n241\n174.84\n85.51\nGrey\nB\n\n\n242\n165.34\n69.62\nGreen\nA\n\n\n243\n169.36\n79.82\nGreen\nA\n\n\n244\n179.62\n93.70\nBrown\nB\n\n\n245\n169.82\n84.24\nBlue\nA\n\n\n246\n166.66\n83.28\nGreen\nB\n\n\n247\n161.48\n85.71\nGreen\nB\n\n\n248\n157.12\n77.46\nBlue\nA\n\n\n249\n180.87\n76.46\nGreen\nB\n\n\n250\n165.45\n74.02\nGrey\nB\n\n\n251\n174.05\n90.16\nGrey\nB\n\n\n252\n169.76\n82.22\nBrown\nB\n\n\n253\n163.57\n88.21\nBrown\nB\n\n\n254\n169.04\n79.57\nGreen\nB\n\n\n255\n166.77\n86.78\nGreen\nA\n\n\n256\n177.32\n81.80\nBlue\nA\n\n\n257\n174.64\n79.11\nGreen\nA\n\n\n258\n157.93\n71.06\nBlue\nA\n\n\n259\n166.43\n84.81\nGreen\nA\n\n\n260\n181.11\n95.02\nGrey\nA\n\n\n261\n175.02\n64.48\nGreen\nA\n\n\n262\n166.49\n75.80\nBlue\nA\n\n\n263\n172.96\n101.45\nBrown\nB\n\n\n264\n167.46\n77.60\nBrown\nA\n\n\n265\n171.88\n99.65\nBlue\nB\n\n\n266\n169.96\n76.15\nBlue\nB\n\n\n267\n171.61\n69.22\nBrown\nB\n\n\n268\n173.93\n77.01\nGrey\nB\n\n\n269\n175.86\n87.87\nBrown\nA\n\n\n270\n163.80\n79.77\nBrown\nA\n\n\n271\n162.62\n89.06\nBrown\nA\n\n\n272\n164.56\n81.04\nBlue\nB\n\n\n273\n169.15\n78.08\nBlue\nB\n\n\n274\n178.99\n82.12\nBlue\nB\n\n\n275\n172.16\n79.83\nBlue\nB\n\n\n276\n177.58\n64.16\nBlue\nA\n\n\n277\n172.11\n87.64\nBlue\nA\n\n\n278\n172.05\n80.89\nGreen\nB\n\n\n279\n158.79\n88.85\nGrey\nA\n\n\n280\n164.65\n76.36\nGrey\nB\n\n\n281\n158.25\n85.47\nBlue\nA\n\n\n282\n161.47\n86.85\nGrey\nA\n\n\n283\n168.93\n74.24\nBlue\nB\n\n\n284\n173.54\n81.79\nGrey\nB\n\n\n285\n168.52\n71.50\nGrey\nA\n\n\n286\n175.56\n79.94\nBlue\nA\n\n\n287\n171.62\n108.83\nBlue\nA\n\n\n288\n181.84\n68.46\nBrown\nB\n\n\n289\n158.44\n86.19\nBlue\nB\n\n\n290\n176.02\n82.23\nGreen\nB\n\n\n291\n168.42\n84.62\nGreen\nB\n\n\n292\n173.19\n83.46\nGrey\nB\n\n\n293\n166.54\n85.19\nBrown\nB\n\n\n294\n151.38\n81.86\nGrey\nA\n\n\n295\n168.90\n88.59\nGreen\nB\n\n\n296\n172.88\n90.38\nBlue\nA\n\n\n297\n163.58\n86.98\nGreen\nB\n\n\n298\n171.87\n72.61\nBrown\nA\n\n\n299\n155.50\n86.58\nGrey\nB\n\n\n300\n161.69\n77.95\nGreen\nA\n\n\n301\n163.56\n83.34\nBlue\nA\n\n\n302\n156.77\n83.00\nGrey\nA\n\n\n303\n179.06\n81.64\nBlue\nB\n\n\n304\n160.63\n79.35\nBlue\nA\n\n\n305\n179.69\n80.81\nBrown\nB\n\n\n306\n177.41\n80.01\nBrown\nB\n\n\n307\n171.50\n77.46\nGreen\nB\n\n\n308\n165.03\n95.09\nGrey\nB\n\n\n309\n165.97\n73.05\nBlue\nB\n\n\n310\n174.97\n88.43\nBrown\nB\n\n\n311\n166.61\n69.08\nGreen\nA\n\n\n312\n167.91\n87.84\nBlue\nA\n\n\n313\n169.47\n56.45\nBlue\nB\n\n\n314\n167.06\n72.44\nBrown\nA\n\n\n315\n169.09\n85.62\nBrown\nA\n\n\n316\n176.48\n84.64\nGreen\nB\n\n\n317\n169.26\n77.97\nBrown\nA\n\n\n318\n166.44\n81.41\nBlue\nB\n\n\n319\n167.66\n97.88\nBrown\nB\n\n\n320\n177.46\n86.76\nGrey\nA\n\n\n321\n167.35\n87.24\nGreen\nB\n\n\n322\n172.86\n73.35\nGrey\nB\n\n\n323\n177.16\n89.08\nGrey\nA\n\n\n324\n165.88\n90.44\nGreen\nA\n\n\n325\n167.17\n85.64\nBlue\nA\n\n\n326\n183.38\n55.84\nGrey\nB\n\n\n327\n169.61\n84.00\nGrey\nB\n\n\n328\n169.70\n85.50\nGreen\nA\n\n\n329\n166.65\n82.95\nGrey\nB\n\n\n330\n164.89\n82.81\nBlue\nB\n\n\n331\n158.82\n74.39\nGrey\nB\n\n\n332\n168.01\n88.06\nBrown\nA\n\n\n333\n165.09\n76.29\nBrown\nB\n\n\n334\n180.56\n75.08\nBlue\nB\n\n\n335\n167.27\n77.80\nBlue\nA\n\n\n336\n173.88\n69.05\nBlue\nB\n\n\n337\n168.97\n77.02\nBrown\nA\n\n\n338\n173.34\n73.76\nBrown\nB\n\n\n339\n176.46\n87.81\nGrey\nA\n\n\n340\n169.78\n94.35\nGreen\nA\n\n\n341\n169.27\n59.98\nGrey\nB\n\n\n342\n173.28\n75.23\nGreen\nA\n\n\n343\n175.18\n97.06\nBlue\nB\n\n\n344\n169.39\n73.95\nBrown\nB\n\n\n345\n172.04\n70.90\nBrown\nB\n\n\n346\n161.62\n96.00\nGrey\nB\n\n\n347\n167.23\n89.55\nGrey\nA\n\n\n348\n168.43\n76.65\nGrey\nB\n\n\n349\n165.32\n81.25\nBrown\nA\n\n\n350\n170.01\n70.74\nGreen\nA\n\n\n351\n173.34\n68.53\nGreen\nA\n\n\n352\n176.02\n77.40\nBlue\nB\n\n\n353\n180.56\n78.09\nBlue\nA\n\n\n354\n170.24\n80.80\nBlue\nA\n\n\n355\n158.60\n103.87\nGreen\nB\n\n\n356\n174.98\n78.75\nGrey\nA\n\n\n357\n168.61\n72.29\nGreen\nB\n\n\n358\n170.10\n68.90\nBlue\nA\n\n\n359\n174.01\n77.02\nBlue\nA\n\n\n360\n164.99\n72.64\nGrey\nB\n\n\n361\n159.98\n83.14\nGrey\nB\n\n\n362\n175.54\n96.49\nGreen\nB\n\n\n363\n179.56\n96.62\nGrey\nA\n\n\n364\n165.69\n91.31\nBlue\nB\n\n\n365\n173.79\n85.11\nGreen\nB\n\n\n366\n187.49\n100.73\nBrown\nB\n\n\n367\n160.26\n76.32\nGreen\nA\n\n\n368\n173.90\n73.22\nGreen\nB\n\n\n369\n172.34\n87.56\nBrown\nA\n\n\n370\n167.85\n71.15\nBrown\nB\n\n\n371\n164.94\n78.22\nBlue\nA\n\n\n372\n168.43\n100.49\nGreen\nB\n\n\n373\n170.77\n61.10\nGreen\nA\n\n\n374\n165.16\n94.65\nGrey\nB\n\n\n375\n181.06\n82.71\nBlue\nB\n\n\n376\n180.98\n69.60\nGreen\nA\n\n\n377\n165.63\n102.78\nBrown\nB\n\n\n378\n173.88\n84.07\nBlue\nA\n\n\n379\n161.95\n77.01\nGreen\nB\n\n\n380\n154.79\n90.84\nBrown\nB\n\n\n381\n172.77\n86.06\nBrown\nB\n\n\n382\n167.95\n80.49\nBlue\nA\n\n\n383\n172.97\n101.62\nGrey\nB\n\n\n384\n171.57\n87.71\nGrey\nA\n\n\n385\n176.72\n75.32\nBlue\nB\n\n\n386\n164.06\n87.94\nGreen\nA\n\n\n387\n172.79\n83.01\nBlue\nB\n\n\n388\n175.86\n75.64\nBrown\nB\n\n\n389\n167.42\n92.96\nBlue\nB\n\n\n390\n162.53\n65.76\nGreen\nB\n\n\n391\n168.44\n74.42\nGreen\nB\n\n\n392\n167.32\n84.70\nBrown\nA\n\n\n393\n182.32\n69.11\nBlue\nB\n\n\n394\n165.47\n77.11\nGrey\nB\n\n\n395\n173.39\n78.83\nBrown\nB\n\n\n396\n176.25\n63.43\nGrey\nB\n\n\n397\n172.76\n78.82\nBrown\nA\n\n\n398\n165.97\n87.00\nBrown\nA\n\n\n399\n161.92\n72.14\nBlue\nA\n\n\n400\n170.86\n74.11\nGreen\nA\n\n\n401\n167.52\n92.29\nGrey\nA\n\n\n402\n164.94\n84.64\nGreen\nA\n\n\n403\n168.27\n79.70\nBlue\nB\n\n\n404\n171.15\n79.21\nGrey\nA\n\n\n405\n175.77\n74.46\nBlue\nA\n\n\n406\n168.97\n89.02\nBrown\nB\n\n\n407\n158.81\n80.27\nBlue\nA\n\n\n408\n174.03\n89.98\nBrown\nA\n\n\n409\n169.40\n86.23\nGrey\nB\n\n\n410\n165.39\n71.14\nGrey\nB\n\n\n411\n169.39\n69.60\nBlue\nA\n\n\n412\n169.70\n64.77\nGrey\nA\n\n\n413\n169.33\n55.84\nGreen\nB\n\n\n414\n166.31\n66.28\nBlue\nB\n\n\n415\n171.87\n82.67\nBlue\nA\n\n\n416\n169.81\n85.32\nBlue\nB\n\n\n417\n165.96\n98.49\nBrown\nA\n\n\n418\n170.11\n82.69\nGreen\nA\n\n\n419\n172.79\n71.13\nGreen\nA\n\n\n420\n151.57\n74.58\nGreen\nB\n\n\n421\n170.07\n77.48\nBlue\nB\n\n\n422\n175.22\n86.84\nGrey\nB\n\n\n423\n167.23\n83.74\nBlue\nB\n\n\n424\n167.22\n71.24\nGreen\nB\n\n\n425\n170.32\n75.31\nBlue\nB\n\n\n426\n171.78\n73.14\nBrown\nB\n\n\n427\n167.27\n59.76\nGrey\nA\n\n\n428\n171.14\n86.26\nBrown\nA\n\n\n429\n163.64\n86.49\nBlue\nA\n\n\n430\n168.21\n80.75\nBlue\nA\n\n\n431\n173.15\n90.29\nBrown\nB\n\n\n432\n179.22\n77.37\nBrown\nA\n\n\n433\n167.71\n87.98\nBrown\nA\n\n\n434\n164.39\n72.47\nGrey\nB\n\n\n435\n162.67\n92.86\nGreen\nB\n\n\n436\n167.86\n82.60\nBrown\nB\n\n\n437\n175.16\n89.60\nBlue\nA\n\n\n438\n171.33\n76.94\nGrey\nA\n\n\n439\n170.80\n92.12\nBlue\nA\n\n\n440\n153.98\n63.60\nBlue\nA\n\n\n441\n176.48\n91.12\nBrown\nB\n\n\n442\n165.54\n86.03\nGrey\nA\n\n\n443\n170.35\n71.17\nGrey\nB\n\n\n444\n164.12\n69.42\nGreen\nB\n\n\n445\n166.53\n92.79\nBlue\nA\n\n\n446\n161.65\n80.08\nGrey\nA\n\n\n447\n162.83\n71.39\nGrey\nB\n\n\n448\n154.30\n73.71\nBlue\nA\n\n\n449\n171.31\n96.96\nGrey\nB\n\n\n450\n170.92\n92.17\nGrey\nA\n\n\n451\n176.17\n80.38\nBlue\nB\n\n\n452\n164.79\n85.05\nGrey\nA\n\n\n453\n172.76\n89.85\nBlue\nA\n\n\n454\n172.17\n90.20\nGrey\nA\n\n\n455\n169.22\n80.94\nBlue\nA\n\n\n456\n174.34\n89.89\nGrey\nA\n\n\n457\n159.21\n85.14\nGreen\nA\n\n\n458\n159.25\n84.37\nBrown\nB\n\n\n459\n178.79\n85.92\nBrown\nB\n\n\n460\n170.75\n100.58\nGreen\nB\n\n\n461\n174.01\n87.50\nGreen\nB\n\n\n462\n170.14\n60.14\nBlue\nB\n\n\n463\n166.26\n92.74\nGrey\nA\n\n\n464\n158.56\n86.13\nBlue\nB\n\n\n465\n172.19\n66.96\nBrown\nB\n\n\n466\n180.26\n58.91\nGreen\nA\n\n\n467\n173.94\n76.43\nGreen\nA\n\n\n468\n174.47\n82.83\nBrown\nA\n\n\n469\n174.15\n75.78\nGreen\nB\n\n\n470\n178.28\n77.57\nBlue\nB\n\n\n471\n167.32\n76.81\nBrown\nA\n\n\n472\n167.55\n74.71\nBrown\nB\n\n\n473\n174.61\n80.27\nGreen\nB\n\n\n474\n173.82\n76.83\nBlue\nA\n\n\n475\n167.19\n79.44\nGreen\nA\n\n\n476\n177.24\n93.01\nBlue\nA\n\n\n477\n176.86\n82.12\nGreen\nA\n\n\n478\n179.92\n65.61\nBlue\nA\n\n\n479\n172.28\n93.04\nGreen\nA\n\n\n480\n171.46\n89.48\nGreen\nA\n\n\n481\n172.67\n79.50\nGreen\nB\n\n\n482\n166.06\n77.27\nGreen\nB\n\n\n483\n176.50\n77.26\nBrown\nB\n\n\n484\n156.14\n92.50\nBlue\nA\n\n\n485\n174.33\n63.12\nGreen\nA\n\n\n486\n165.67\n86.60\nBrown\nB\n\n\n487\n182.18\n67.37\nGreen\nA\n\n\n488\n168.91\n86.88\nBrown\nA\n\n\n489\n168.06\n81.96\nBlue\nB\n\n\n490\n168.13\n89.14\nGreen\nA\n\n\n491\n165.28\n79.44\nGrey\nB\n\n\n492\n162.20\n80.96\nGreen\nA\n\n\n493\n168.13\n102.88\nGrey\nA\n\n\n494\n167.04\n82.09\nBrown\nA\n\n\n495\n171.84\n77.24\nGrey\nA\n\n\n496\n184.84\n88.92\nGreen\nA\n\n\n497\n163.31\n75.80\nGrey\nB\n\n\n498\n168.68\n62.92\nBlue\nB\n\n\n499\n164.68\n87.64\nBrown\nA\n\n\n500\n168.44\n80.81\nBrown\nB\n\n\n501\n170.56\n79.15\nGrey\nA\n\n\n502\n170.47\n80.63\nBrown\nB\n\n\n503\n175.32\n78.17\nGrey\nB\n\n\n504\n158.59\n74.18\nBrown\nB\n\n\n505\n165.56\n80.54\nGrey\nA\n\n\n506\n169.45\n94.18\nGreen\nA\n\n\n507\n178.75\n85.72\nGreen\nA\n\n\n508\n162.96\n74.55\nGrey\nB\n\n\n509\n178.21\n73.44\nBlue\nA\n\n\n510\n174.59\n72.40\nBlue\nB\n\n\n511\n165.34\n56.60\nBlue\nA\n\n\n512\n163.03\n86.26\nBrown\nA\n\n\n513\n169.64\n95.38\nGrey\nA\n\n\n514\n164.10\n70.94\nBlue\nB\n\n\n515\n176.51\n62.65\nGreen\nB\n\n\n516\n171.61\n78.36\nBlue\nB\n\n\n517\n172.94\n84.12\nBrown\nA\n\n\n518\n171.89\n87.12\nGreen\nB\n\n\n519\n170.93\n94.28\nGreen\nB\n\n\n520\n177.57\n67.06\nGreen\nB\n\n\n521\n160.03\n78.09\nGreen\nB\n\n\n522\n169.60\n88.06\nGreen\nA\n\n\n523\n173.22\n78.78\nGrey\nA\n\n\n524\n170.88\n93.96\nBlue\nA\n\n\n525\n176.22\n85.53\nGrey\nB\n\n\n526\n161.18\n80.51\nBrown\nB\n\n\n527\n177.53\n71.20\nGreen\nB\n\n\n528\n169.75\n59.59\nBrown\nA\n\n\n529\n176.47\n72.47\nGreen\nA\n\n\n530\n169.93\n73.92\nBrown\nB\n\n\n531\n171.35\n88.80\nBrown\nB\n\n\n532\n154.61\n87.71\nGreen\nB\n\n\n533\n169.48\n100.93\nBlue\nB\n\n\n534\n159.87\n83.71\nBrown\nA\n\n\n535\n181.63\n71.47\nBlue\nA\n\n\n536\n172.27\n76.68\nGreen\nB\n\n\n537\n169.75\n91.72\nBrown\nA\n\n\n538\n172.92\n84.89\nBlue\nB\n\n\n539\n168.23\n96.27\nBlue\nB\n\n\n540\n170.28\n99.65\nGrey\nB\n\n\n541\n178.00\n93.20\nGreen\nB\n\n\n542\n167.68\n78.06\nGreen\nB\n\n\n543\n178.57\n75.86\nGrey\nA\n\n\n544\n161.43\n90.47\nBlue\nA\n\n\n545\n168.57\n87.13\nGreen\nA\n\n\n546\n169.03\n78.56\nBrown\nA\n\n\n547\n176.40\n69.67\nGrey\nB\n\n\n548\n164.51\n73.67\nGrey\nA\n\n\n549\n175.72\n98.95\nBrown\nB\n\n\n550\n164.30\n86.90\nGrey\nA\n\n\n551\n179.74\n75.47\nGrey\nB\n\n\n552\n169.85\n89.23\nBlue\nB\n\n\n553\n164.25\n87.27\nGreen\nA\n\n\n554\n163.10\n76.19\nGrey\nB\n\n\n555\n175.64\n88.12\nBrown\nB\n\n\n556\n169.75\n73.06\nGreen\nA\n\n\n557\n163.19\n95.33\nBrown\nB\n\n\n558\n163.43\n87.91\nGrey\nA\n\n\n559\n170.85\n107.88\nBrown\nA\n\n\n560\n175.98\n66.96\nGrey\nB\n\n\n561\n174.14\n79.59\nGrey\nA\n\n\n562\n164.63\n93.77\nBrown\nA\n\n\n563\n171.05\n83.14\nGrey\nB\n\n\n564\n175.30\n80.91\nBlue\nA\n\n\n565\n171.79\n77.92\nGreen\nA\n\n\n566\n190.44\n81.94\nBlue\nB\n\n\n567\n162.78\n81.46\nBlue\nA\n\n\n568\n164.60\n77.69\nBlue\nB\n\n\n569\n178.35\n67.43\nGrey\nA\n\n\n570\n171.65\n78.93\nBrown\nA\n\n\n571\n177.71\n89.10\nBrown\nA\n\n\n572\n176.95\n78.05\nGrey\nA\n\n\n573\n172.74\n70.49\nBlue\nA\n\n\n574\n176.61\n77.40\nBlue\nA\n\n\n575\n168.20\n77.70\nGreen\nB\n\n\n576\n177.16\n76.00\nGreen\nB\n\n\n577\n163.80\n80.86\nBlue\nA\n\n\n578\n175.10\n82.01\nGrey\nB\n\n\n579\n163.18\n75.15\nBlue\nA\n\n\n580\n163.82\n75.95\nBlue\nA\n\n\n581\n177.32\n78.83\nGrey\nB\n\n\n582\n174.91\n71.80\nGrey\nB\n\n\n583\n166.34\n70.16\nGreen\nA\n\n\n584\n175.25\n65.76\nBrown\nA\n\n\n585\n156.16\n86.63\nGreen\nB\n\n\n586\n166.14\n69.57\nGreen\nA\n\n\n587\n161.35\n82.06\nBlue\nA\n\n\n588\n164.37\n68.86\nGreen\nA\n\n\n589\n164.92\n76.66\nBlue\nB\n\n\n590\n174.23\n82.38\nBrown\nA\n\n\n591\n174.52\n70.99\nGrey\nA\n\n\n592\n186.73\n77.90\nBrown\nA\n\n\n593\n176.61\n66.73\nBrown\nB\n\n\n594\n178.36\n79.33\nBlue\nA\n\n\n595\n179.95\n88.37\nGreen\nA\n\n\n596\n162.99\n67.45\nGreen\nA\n\n\n597\n161.19\n69.84\nBlue\nB\n\n\n598\n166.66\n73.27\nBlue\nB\n\n\n599\n166.08\n76.23\nGrey\nB\n\n\n600\n162.38\n93.61\nGreen\nB\n\n\n601\n156.36\n93.38\nBlue\nA\n\n\n602\n173.69\n82.56\nBrown\nB\n\n\n603\n177.88\n71.49\nGreen\nA\n\n\n604\n162.75\n71.58\nBlue\nB\n\n\n605\n155.25\n79.86\nBrown\nB\n\n\n606\n173.30\n74.63\nBlue\nB\n\n\n607\n171.15\n85.35\nBlue\nA\n\n\n608\n174.29\n81.74\nBlue\nB\n\n\n609\n166.11\n77.77\nGrey\nB\n\n\n610\n177.69\n71.63\nGrey\nA\n\n\n611\n176.83\n97.28\nGreen\nB\n\n\n612\n173.63\n66.37\nGrey\nB\n\n\n613\n168.13\n84.93\nGreen\nA\n\n\n614\n186.67\n89.01\nBlue\nA\n\n\n615\n169.45\n91.76\nBlue\nB\n\n\n616\n178.85\n64.77\nBlue\nA\n\n\n617\n161.17\n68.79\nGrey\nA\n\n\n618\n167.75\n63.01\nGreen\nB\n\n\n619\n171.41\n88.07\nGrey\nB\n\n\n620\n160.24\n79.17\nGrey\nA\n\n\n621\n170.00\n84.39\nGrey\nB\n\n\n622\n172.43\n90.57\nBlue\nA\n\n\n623\n178.24\n82.11\nGreen\nB\n\n\n624\n174.22\n85.25\nBrown\nA\n\n\n625\n180.30\n77.02\nGreen\nA\n\n\n626\n174.27\n89.12\nBrown\nB\n\n\n627\n170.56\n82.55\nGreen\nB\n\n\n628\n176.39\n76.38\nGrey\nB\n\n\n629\n163.32\n65.88\nGreen\nA\n\n\n630\n170.75\n74.43\nGrey\nA\n\n\n631\n160.66\n61.51\nBlue\nB\n\n\n632\n172.63\n83.80\nBrown\nA\n\n\n633\n166.59\n92.43\nBlue\nA\n\n\n634\n169.93\n67.27\nGreen\nA\n\n\n635\n175.05\n77.63\nGrey\nB\n\n\n636\n178.56\n60.04\nBlue\nB\n\n\n637\n168.06\n66.69\nGrey\nA\n\n\n638\n170.22\n73.47\nBlue\nB\n\n\n639\n176.07\n75.65\nBlue\nB\n\n\n640\n166.89\n70.63\nBlue\nB\n\n\n641\n167.15\n62.59\nBlue\nA\n\n\n642\n168.53\n79.38\nBlue\nA\n\n\n643\n172.10\n74.06\nGrey\nB\n\n\n644\n174.17\n63.32\nGrey\nB\n\n\n645\n174.77\n87.55\nGrey\nB\n\n\n646\n176.97\n80.21\nBlue\nB\n\n\n647\n164.17\n79.90\nGrey\nA\n\n\n648\n171.23\n71.95\nGrey\nA\n\n\n649\n178.24\n71.82\nGreen\nA\n\n\n650\n153.72\n72.64\nBrown\nB\n\n\n651\n162.70\n82.01\nBrown\nB\n\n\n652\n170.51\n89.57\nGreen\nA\n\n\n653\n163.95\n68.58\nBrown\nB\n\n\n654\n162.51\n83.46\nGrey\nB\n\n\n655\n164.24\n82.45\nBrown\nB\n\n\n656\n167.54\n83.40\nBrown\nB\n\n\n657\n180.75\n81.15\nBlue\nA\n\n\n658\n169.94\n91.08\nBrown\nB\n\n\n659\n174.52\n73.70\nBrown\nA\n\n\n660\n163.22\n95.60\nBrown\nA\n\n\n661\n175.33\n74.50\nGreen\nB\n\n\n662\n171.08\n62.38\nBrown\nB\n\n\n663\n171.09\n77.07\nBlue\nB\n\n\n664\n170.31\n66.84\nBrown\nB\n\n\n665\n172.64\n95.30\nBrown\nA\n\n\n666\n174.63\n76.54\nBlue\nA\n\n\n667\n169.94\n84.62\nBrown\nA\n\n\n668\n176.14\n63.09\nBrown\nB\n\n\n669\n174.21\n66.37\nGrey\nA\n\n\n670\n172.13\n84.67\nBrown\nB\n\n\n671\n169.09\n84.65\nBrown\nB\n\n\n672\n169.38\n74.12\nBlue\nA\n\n\n673\n168.05\n82.06\nBrown\nB\n\n\n674\n162.81\n88.53\nBrown\nA\n\n\n675\n171.95\n88.09\nBlue\nA\n\n\n676\n170.11\n73.98\nBrown\nA\n\n\n677\n175.39\n91.79\nGreen\nA\n\n\n678\n174.19\n82.75\nGreen\nA\n\n\n679\n167.34\n86.30\nBrown\nA\n\n\n680\n168.52\n98.53\nBlue\nB\n\n\n681\n176.53\n92.44\nBrown\nA\n\n\n682\n166.62\n78.45\nBlue\nB\n\n\n683\n161.31\n62.22\nGrey\nA\n\n\n684\n166.47\n70.96\nBlue\nA\n\n\n685\n180.05\n73.98\nBlue\nB\n\n\n686\n168.94\n89.70\nGreen\nB\n\n\n687\n169.79\n80.33\nBlue\nB\n\n\n688\n168.25\n74.68\nBlue\nB\n\n\n689\n164.29\n82.73\nBlue\nB\n\n\n690\n171.67\n91.56\nBrown\nB\n\n\n691\n174.31\n77.22\nBrown\nA\n\n\n692\n172.06\n71.97\nBlue\nB\n\n\n693\n161.57\n72.75\nBlue\nB\n\n\n694\n164.84\n76.83\nBlue\nB\n\n\n695\n172.66\n67.10\nGreen\nB\n\n\n696\n162.87\n49.90\nBlue\nB\n\n\n697\n163.19\n78.14\nBrown\nA\n\n\n698\n164.02\n96.30\nGreen\nA\n\n\n699\n183.65\n99.65\nBrown\nA\n\n\n700\n175.41\n82.76\nBrown\nB\n\n\n701\n174.07\n80.72\nBlue\nB\n\n\n702\n174.03\n94.90\nBrown\nA\n\n\n703\n167.99\n56.45\nBrown\nB\n\n\n704\n173.09\n78.02\nGreen\nB\n\n\n705\n171.77\n99.21\nBrown\nB\n\n\n706\n179.12\n73.48\nGreen\nB\n\n\n707\n174.09\n70.61\nBlue\nA\n\n\n708\n161.14\n77.89\nGrey\nA\n\n\n709\n174.88\n73.97\nBlue\nA\n\n\n710\n170.58\n73.96\nBlue\nB\n\n\n711\n170.48\n80.32\nGrey\nB\n\n\n712\n179.76\n93.34\nGreen\nB\n\n\n713\n170.23\n85.36\nBlue\nB\n\n\n714\n168.76\n87.17\nBlue\nA\n\n\n715\n172.88\n81.29\nGreen\nB\n\n\n716\n172.18\n89.87\nGreen\nB\n\n\n717\n171.80\n76.74\nBrown\nB\n\n\n718\n166.94\n73.91\nBrown\nB\n\n\n719\n165.70\n90.13\nGreen\nA\n\n\n720\n171.07\n70.05\nBlue\nA\n\n\n721\n164.01\n66.34\nBlue\nA\n\n\n722\n168.21\n70.46\nBrown\nA\n\n\n723\n171.18\n79.93\nBrown\nA\n\n\n724\n164.36\n78.43\nBrown\nA\n\n\n725\n166.96\n95.54\nBlue\nA\n\n\n726\n163.79\n87.12\nBlue\nB\n\n\n727\n165.65\n70.37\nBrown\nA\n\n\n728\n175.15\n81.44\nGrey\nA\n\n\n729\n174.15\n84.45\nBrown\nB\n\n\n730\n180.04\n92.50\nGreen\nA\n\n\n731\n170.75\n92.74\nBlue\nB\n\n\n732\n168.77\n88.26\nBrown\nB\n\n\n733\n164.22\n71.09\nGreen\nB\n\n\n734\n162.97\n76.52\nBrown\nA\n\n\n735\n176.71\n77.90\nGrey\nA\n\n\n736\n176.80\n71.54\nBlue\nB\n\n\n737\n165.90\n90.97\nGreen\nA\n\n\n738\n172.60\n79.67\nBlue\nA\n\n\n739\n167.44\n80.15\nGrey\nB\n\n\n740\n165.58\n90.47\nBlue\nA\n\n\n741\n173.97\n68.93\nGreen\nB\n\n\n742\n171.99\n75.40\nGrey\nA\n\n\n743\n172.34\n78.00\nGreen\nA\n\n\n744\n179.89\n103.31\nBlue\nB\n\n\n745\n167.02\n74.14\nBlue\nA\n\n\n746\n172.16\n54.04\nBlue\nB\n\n\n747\n176.38\n70.12\nGrey\nA\n\n\n748\n170.93\n82.14\nGrey\nB\n\n\n749\n167.08\n91.17\nBrown\nB\n\n\n750\n164.93\n82.62\nBlue\nA\n\n\n751\n175.88\n76.24\nGrey\nB\n\n\n752\n166.28\n83.51\nBrown\nB\n\n\n753\n170.95\n75.33\nGreen\nA\n\n\n754\n179.68\n66.80\nGreen\nB\n\n\n755\n169.16\n93.42\nBrown\nA\n\n\n756\n168.96\n90.89\nBlue\nA\n\n\n757\n163.47\n93.37\nBrown\nA\n\n\n758\n171.15\n71.93\nBrown\nB\n\n\n759\n167.40\n75.02\nBlue\nA\n\n\n760\n161.63\n102.45\nGrey\nA\n\n\n761\n180.13\n77.66\nBrown\nB\n\n\n762\n178.47\n80.87\nBlue\nA\n\n\n763\n169.63\n75.21\nGrey\nA\n\n\n764\n176.56\n86.78\nGreen\nA\n\n\n765\n177.74\n82.43\nGrey\nB\n\n\n766\n169.19\n69.64\nGreen\nA\n\n\n767\n164.83\n97.09\nBrown\nA\n\n\n768\n163.19\n89.89\nBlue\nA\n\n\n769\n165.76\n85.69\nBlue\nB\n\n\n770\n173.29\n72.52\nGreen\nA\n\n\n771\n167.18\n77.84\nGrey\nB\n\n\n772\n172.95\n78.55\nGreen\nB\n\n\n773\n176.74\n74.88\nBlue\nA\n\n\n774\n177.22\n87.75\nGrey\nB\n\n\n775\n166.53\n74.29\nGreen\nB\n\n\n776\n160.60\n67.70\nGreen\nB\n\n\n777\n176.38\n88.54\nGreen\nA\n\n\n778\n174.40\n85.31\nBrown\nA\n\n\n779\n165.25\n91.00\nGreen\nA\n\n\n780\n177.43\n89.33\nBlue\nB\n\n\n781\n167.65\n63.56\nGreen\nA\n\n\n782\n177.33\n94.90\nGrey\nB\n\n\n783\n170.09\n86.71\nGreen\nA\n\n\n784\n165.35\n77.97\nGreen\nB\n\n\n785\n170.60\n76.48\nGrey\nB\n\n\n786\n162.26\n67.41\nGreen\nB\n\n\n787\n167.22\n84.14\nGreen\nB\n\n\n788\n175.02\n74.77\nGreen\nB\n\n\n789\n168.25\n82.26\nBrown\nA\n\n\n790\n179.58\n82.23\nBrown\nB\n\n\n791\n166.60\n63.60\nGrey\nA\n\n\n792\n183.53\n93.09\nGreen\nB\n\n\n793\n162.68\n87.86\nBlue\nA\n\n\n794\n162.25\n78.41\nGrey\nB\n\n\n795\n166.39\n86.34\nBlue\nA\n\n\n796\n168.94\n76.32\nGrey\nA\n\n\n797\n169.38\n66.64\nGreen\nA\n\n\n798\n160.81\n80.23\nBrown\nA\n\n\n799\n175.86\n103.65\nBlue\nA\n\n\n800\n173.55\n75.50\nGreen\nB\n\n\n801\n175.93\n78.76\nBrown\nA\n\n\n802\n174.23\n72.99\nGreen\nB\n\n\n803\n155.07\n78.15\nBrown\nA\n\n\n804\n154.94\n91.89\nGreen\nA\n\n\n805\n181.97\n85.87\nBlue\nB\n\n\n806\n168.37\n78.18\nBlue\nB\n\n\n807\n168.38\n84.86\nGrey\nB\n\n\n808\n164.10\n86.29\nBrown\nB\n\n\n809\n176.51\n83.06\nBrown\nB\n\n\n810\n169.17\n70.59\nBlue\nA\n\n\n811\n165.30\n88.88\nGreen\nA\n\n\n812\n152.73\n106.71\nGrey\nB\n\n\n813\n162.30\n78.38\nGrey\nA\n\n\n814\n169.78\n88.09\nGreen\nA\n\n\n815\n156.24\n69.05\nBrown\nB\n\n\n816\n173.76\n84.85\nBrown\nA\n\n\n817\n167.88\n68.38\nGrey\nA\n\n\n818\n173.61\n80.97\nBrown\nA\n\n\n819\n173.97\n65.25\nBrown\nA\n\n\n820\n170.20\n72.93\nGreen\nA\n\n\n821\n163.11\n76.60\nGreen\nB\n\n\n822\n168.18\n79.78\nGreen\nB\n\n\n823\n180.30\n74.17\nBrown\nA\n\n\n824\n178.59\n108.06\nGrey\nB\n\n\n825\n175.04\n93.19\nBlue\nB\n\n\n826\n166.47\n83.47\nGreen\nB\n\n\n827\n167.79\n103.34\nGreen\nB\n\n\n828\n168.53\n87.19\nGreen\nA\n\n\n829\n173.41\n85.98\nGreen\nA\n\n\n830\n177.26\n71.78\nGreen\nB\n\n\n831\n165.19\n73.09\nGrey\nB\n\n\n832\n160.25\n79.25\nBrown\nA\n\n\n833\n166.17\n75.82\nBlue\nB\n\n\n834\n165.99\n90.73\nBrown\nA\n\n\n835\n174.01\n93.04\nGrey\nA\n\n\n836\n170.75\n73.70\nGreen\nA\n\n\n837\n165.53\n76.12\nGrey\nB\n\n\n838\n163.12\n79.36\nBrown\nB\n\n\n839\n175.52\n104.40\nGrey\nA\n\n\n840\n162.10\n82.79\nGrey\nA\n\n\n841\n170.70\n81.55\nGrey\nB\n\n\n842\n179.68\n80.26\nGrey\nA\n\n\n843\n173.63\n74.21\nBlue\nA\n\n\n844\n164.29\n95.37\nBlue\nA\n\n\n845\n176.13\n65.54\nGrey\nB\n\n\n846\n166.36\n95.99\nBlue\nA\n\n\n847\n159.11\n95.86\nGrey\nB\n\n\n848\n161.11\n82.53\nGreen\nA\n\n\n849\n168.29\n75.64\nBlue\nB\n\n\n850\n169.12\n92.68\nGrey\nA\n\n\n851\n178.47\n79.49\nBlue\nA\n\n\n852\n164.98\n84.26\nBrown\nB\n\n\n853\n167.15\n91.39\nBrown\nA\n\n\n854\n174.75\n89.21\nBlue\nA\n\n\n855\n173.06\n96.82\nGrey\nA\n\n\n856\n170.89\n85.34\nGreen\nA\n\n\n857\n176.36\n81.04\nGreen\nB\n\n\n858\n159.71\n89.90\nGreen\nB\n\n\n859\n179.42\n74.60\nBrown\nA\n\n\n860\n171.31\n77.28\nBrown\nA\n\n\n861\n175.87\n79.65\nGrey\nB\n\n\n862\n172.01\n73.07\nGreen\nA\n\n\n863\n172.25\n88.08\nGreen\nA\n\n\n864\n174.65\n103.53\nGrey\nB\n\n\n865\n169.25\n87.58\nBlue\nB\n\n\n866\n174.45\n76.70\nGrey\nB\n\n\n867\n168.06\n73.86\nGreen\nA\n\n\n868\n168.20\n94.57\nBrown\nB\n\n\n869\n174.37\n83.11\nBrown\nB\n\n\n870\n177.28\n84.83\nGreen\nB\n\n\n871\n161.53\n68.31\nBlue\nA\n\n\n872\n176.04\n82.64\nBlue\nA\n\n\n873\n168.29\n89.21\nBrown\nB\n\n\n874\n171.79\n84.39\nGrey\nA\n\n\n875\n161.65\n64.42\nGrey\nA\n\n\n876\n167.76\n72.40\nBlue\nB\n\n\n877\n165.00\n85.91\nBlue\nA\n\n\n878\n169.62\n86.85\nGreen\nA\n\n\n879\n164.89\n86.33\nBrown\nB\n\n\n880\n172.45\n92.88\nBlue\nA\n\n\n881\n177.68\n82.90\nGrey\nA\n\n\n882\n171.01\n73.70\nBrown\nB\n\n\n883\n172.80\n70.30\nGreen\nA\n\n\n884\n162.82\n78.72\nGrey\nA\n\n\n885\n172.07\n78.42\nBrown\nB\n\n\n886\n167.53\n76.82\nGreen\nB\n\n\n887\n166.53\n61.72\nBrown\nA\n\n\n888\n175.83\n82.41\nBrown\nA\n\n\n889\n175.85\n78.54\nBlue\nA\n\n\n890\n172.35\n77.06\nGreen\nA\n\n\n891\n159.89\n72.25\nBlue\nB\n\n\n892\n168.86\n74.20\nGreen\nA\n\n\n893\n168.82\n84.83\nGrey\nB\n\n\n894\n162.43\n76.83\nGrey\nA\n\n\n895\n171.67\n78.62\nGreen\nA\n\n\n896\n170.28\n84.15\nGrey\nB\n\n\n897\n164.97\n92.02\nGrey\nA\n\n\n898\n173.88\n79.34\nGrey\nA\n\n\n899\n169.67\n89.66\nBlue\nB\n\n\n900\n161.69\n75.16\nBlue\nA\n\n\n901\n172.27\n85.13\nBrown\nB\n\n\n902\n169.54\n91.62\nGreen\nB\n\n\n903\n168.60\n77.12\nGrey\nB\n\n\n904\n182.19\n95.20\nBrown\nB\n\n\n905\n168.41\n96.50\nGrey\nA\n\n\n906\n172.94\n88.94\nGreen\nA\n\n\n907\n161.49\n74.56\nGreen\nB\n\n\n908\n173.85\n76.79\nGreen\nB\n\n\n909\n174.67\n68.89\nBlue\nB\n\n\n910\n170.00\n79.42\nGreen\nB\n\n\n911\n173.66\n69.17\nGrey\nA\n\n\n912\n171.71\n75.47\nGreen\nB\n\n\n913\n176.86\n86.89\nBrown\nA\n\n\n914\n177.43\n83.44\nGrey\nB\n\n\n915\n176.72\n87.39\nGrey\nA\n\n\n916\n163.52\n85.04\nGreen\nB\n\n\n917\n167.98\n64.71\nBlue\nB\n\n\n918\n169.84\n68.25\nBrown\nB\n\n\n919\n181.70\n86.95\nGrey\nB\n\n\n920\n168.66\n87.02\nGreen\nA\n\n\n921\n178.01\n76.09\nGrey\nB\n\n\n922\n172.97\n86.43\nBlue\nA\n\n\n923\n163.88\n94.98\nBlue\nA\n\n\n924\n175.91\n70.74\nGreen\nA\n\n\n925\n175.02\n83.33\nGrey\nB\n\n\n926\n166.03\n74.03\nGrey\nA\n\n\n927\n168.75\n68.48\nGrey\nB\n\n\n928\n169.23\n91.66\nGrey\nA\n\n\n929\n180.73\n84.52\nBlue\nB\n\n\n930\n171.83\n84.99\nBrown\nB\n\n\n931\n175.38\n84.91\nBrown\nA\n\n\n932\n174.40\n68.84\nGrey\nB\n\n\n933\n169.82\n84.77\nGrey\nB\n\n\n934\n167.19\n86.10\nBrown\nB\n\n\n935\n179.94\n82.12\nBlue\nA\n\n\n936\n164.61\n83.94\nBrown\nA\n\n\n937\n165.90\n80.76\nGreen\nA\n\n\n938\n168.49\n62.05\nGreen\nA\n\n\n939\n171.94\n62.71\nBlue\nA\n\n\n940\n166.10\n70.15\nGreen\nA\n\n\n941\n179.36\n67.38\nGrey\nB\n\n\n942\n170.49\n72.80\nGreen\nB\n\n\n943\n169.66\n72.84\nBrown\nB\n\n\n944\n165.70\n67.24\nGreen\nB\n\n\n945\n167.07\n69.70\nGreen\nA\n\n\n946\n167.18\n85.68\nGreen\nB\n\n\n947\n176.69\n71.44\nBlue\nB\n\n\n948\n167.44\n82.49\nGreen\nB\n\n\n949\n174.51\n86.17\nGrey\nA\n\n\n950\n165.77\n80.27\nBrown\nB\n\n\n951\n159.22\n69.53\nBrown\nA\n\n\n952\n158.99\n81.21\nGrey\nA\n\n\n953\n167.96\n94.78\nBlue\nB\n\n\n954\n166.47\n57.39\nBlue\nA\n\n\n955\n165.49\n77.38\nGrey\nB\n\n\n956\n161.26\n77.51\nBrown\nA\n\n\n957\n171.96\n71.25\nBrown\nB\n\n\n958\n171.74\n74.65\nBlue\nB\n\n\n959\n165.00\n64.00\nGrey\nA\n\n\n960\n175.32\n94.93\nGrey\nA\n\n\n961\n168.47\n70.10\nBrown\nA\n\n\n962\n169.96\n76.55\nGreen\nA\n\n\n963\n159.99\n85.83\nBrown\nB\n\n\n964\n182.92\n68.42\nBlue\nA\n\n\n965\n166.44\n77.82\nGrey\nB\n\n\n966\n168.62\n79.84\nGrey\nB\n\n\n967\n172.09\n61.65\nBlue\nA\n\n\n968\n175.73\n76.45\nBrown\nA\n\n\n969\n168.53\n93.80\nBlue\nA\n\n\n970\n156.00\n90.44\nGrey\nA\n\n\n971\n166.66\n60.89\nBrown\nA\n\n\n972\n161.20\n56.18\nGreen\nA\n\n\n973\n179.80\n77.04\nBrown\nB\n\n\n974\n164.49\n82.16\nGreen\nA\n\n\n975\n164.97\n77.10\nGreen\nA\n\n\n976\n166.25\n72.15\nBlue\nB\n\n\n977\n165.78\n84.93\nBlue\nA\n\n\n978\n159.43\n77.98\nGreen\nB\n\n\n979\n165.40\n108.75\nGrey\nB\n\n\n980\n168.26\n83.79\nGrey\nB\n\n\n981\n171.39\n91.25\nGrey\nB\n\n\n982\n176.38\n70.61\nGreen\nA\n\n\n983\n174.40\n85.17\nGrey\nA\n\n\n984\n169.76\n73.37\nGreen\nB\n\n\n985\n158.29\n96.39\nGrey\nB\n\n\n986\n177.91\n83.13\nGrey\nB\n\n\n987\n167.58\n72.57\nGreen\nB\n\n\n988\n158.10\n67.28\nGrey\nB\n\n\n989\n170.73\n95.74\nBrown\nB\n\n\n990\n165.32\n89.17\nBrown\nB\n\n\n991\n175.11\n72.74\nGrey\nA\n\n\n992\n167.17\n88.95\nGreen\nB\n\n\n993\n172.26\n104.35\nGrey\nA\n\n\n994\n162.35\n60.29\nBrown\nA\n\n\n995\n162.48\n90.76\nGreen\nB\n\n\n996\n174.42\n85.16\nBlue\nB\n\n\n997\n169.26\n72.03\nBrown\nB\n\n\n998\n178.41\n75.57\nGrey\nB\n\n\n999\n167.06\n77.55\nBlue\nA\n\n\n1000\n169.07\n92.08\nBlue\nB"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#how-similar-are-these-groups",
    "href": "content/slides/01-07-experiments.html#how-similar-are-these-groups",
    "title": "Causal Effects and Experiments",
    "section": "How similar are these groups?",
    "text": "How similar are these groups?\nLet’s first check their heights:"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#how-similar-are-these-groups-1",
    "href": "content/slides/01-07-experiments.html#how-similar-are-these-groups-1",
    "title": "Causal Effects and Experiments",
    "section": "How similar are these groups?",
    "text": "How similar are these groups?\nAnd their weights:"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#how-similar-are-these-groups-2",
    "href": "content/slides/01-07-experiments.html#how-similar-are-these-groups-2",
    "title": "Causal Effects and Experiments",
    "section": "How similar are these groups?",
    "text": "How similar are these groups?\nAnd their eye colors:"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#making-sure-this-wasnt-a-fluke",
    "href": "content/slides/01-07-experiments.html#making-sure-this-wasnt-a-fluke",
    "title": "Causal Effects and Experiments",
    "section": "Making sure this wasn’t a fluke",
    "text": "Making sure this wasn’t a fluke\nLet’s re-run this:\n\n\n\n\n\nID\nHeight\nWeight\nEye colour\nGroup\n\n\n\n\n1\n170.62\n77.78\nBrown\nA\n\n\n2\n174.04\n49.24\nBrown\nA\n\n\n3\n171.12\n85.96\nGrey\nB\n\n\n4\n166.27\n89.28\nGrey\nA\n\n\n5\n169.99\n103.33\nBrown\nA\n\n\n6\n165.38\n84.37\nBrown\nA\n\n\n7\n171.92\n80.29\nGreen\nB\n\n\n8\n173.02\n97.12\nBlue\nA\n\n\n9\n165.83\n91.32\nGreen\nA\n\n\n10\n163.81\n89.87\nBrown\nA\n\n\n11\n165.78\n74.25\nGreen\nA\n\n\n12\n175.28\n99.72\nGrey\nA\n\n\n13\n171.90\n95.85\nBlue\nA\n\n\n14\n171.11\n63.92\nBrown\nA\n\n\n15\n167.29\n66.29\nGrey\nB\n\n\n16\n167.43\n97.85\nBlue\nA\n\n\n17\n166.59\n77.91\nGrey\nB\n\n\n18\n169.54\n89.53\nGrey\nB\n\n\n19\n162.91\n81.23\nBrown\nB\n\n\n20\n156.62\n71.98\nGrey\nB\n\n\n21\n168.07\n83.66\nBrown\nA\n\n\n22\n167.72\n81.11\nBlue\nA\n\n\n23\n173.65\n78.10\nGreen\nB\n\n\n24\n171.84\n74.55\nGrey\nA\n\n\n25\n161.53\n70.32\nBrown\nA\n\n\n26\n167.05\n90.10\nBrown\nA\n\n\n27\n172.42\n88.43\nBlue\nB\n\n\n28\n176.32\n63.16\nGrey\nB\n\n\n29\n181.28\n87.74\nGreen\nB\n\n\n30\n171.20\n63.42\nBrown\nA\n\n\n31\n166.78\n74.78\nBlue\nB\n\n\n32\n168.40\n80.77\nGreen\nB\n\n\n33\n167.06\n78.07\nGrey\nA\n\n\n34\n162.80\n69.65\nBlue\nB\n\n\n35\n154.76\n84.17\nBrown\nB\n\n\n36\n163.79\n86.04\nBrown\nA\n\n\n37\n158.00\n82.08\nGreen\nA\n\n\n38\n170.47\n68.50\nBlue\nB\n\n\n39\n170.56\n77.96\nBlue\nA\n\n\n40\n180.94\n94.93\nGreen\nA\n\n\n41\n167.84\n95.25\nBrown\nA\n\n\n42\n167.48\n99.63\nBrown\nA\n\n\n43\n167.45\n93.59\nGrey\nA\n\n\n44\n152.83\n88.78\nGrey\nB\n\n\n45\n169.91\n78.77\nGrey\nA\n\n\n46\n167.39\n75.19\nGreen\nA\n\n\n47\n163.90\n77.07\nGrey\nB\n\n\n48\n171.55\n75.64\nGreen\nA\n\n\n49\n169.16\n90.56\nGrey\nA\n\n\n50\n172.17\n72.51\nBlue\nB\n\n\n51\n176.74\n81.63\nBlue\nB\n\n\n52\n171.20\n76.86\nBlue\nA\n\n\n53\n175.02\n97.72\nBlue\nB\n\n\n54\n165.89\n87.05\nGreen\nA\n\n\n55\n159.78\n76.90\nGreen\nA\n\n\n56\n169.08\n81.10\nBrown\nB\n\n\n57\n172.15\n65.48\nBrown\nB\n\n\n58\n165.38\n81.77\nGreen\nA\n\n\n59\n164.43\n81.79\nGrey\nA\n\n\n60\n174.78\n74.47\nBrown\nA\n\n\n61\n182.01\n74.23\nGrey\nA\n\n\n62\n166.11\n79.51\nBrown\nA\n\n\n63\n174.10\n90.42\nGrey\nB\n\n\n64\n174.12\n82.12\nBlue\nA\n\n\n65\n169.17\n91.05\nGrey\nB\n\n\n66\n181.42\n77.08\nGreen\nA\n\n\n67\n176.10\n82.71\nBrown\nA\n\n\n68\n169.15\n78.50\nGrey\nA\n\n\n69\n172.27\n89.14\nBlue\nA\n\n\n70\n166.27\n74.35\nGreen\nB\n\n\n71\n168.44\n70.31\nGreen\nA\n\n\n72\n166.40\n95.56\nGrey\nB\n\n\n73\n167.81\n72.94\nBrown\nB\n\n\n74\n169.04\n86.17\nGreen\nB\n\n\n75\n170.34\n74.29\nGrey\nB\n\n\n76\n173.59\n85.34\nBrown\nA\n\n\n77\n160.20\n83.85\nGreen\nB\n\n\n78\n163.58\n99.63\nBlue\nB\n\n\n79\n170.72\n85.68\nGrey\nA\n\n\n80\n165.34\n94.12\nBrown\nB\n\n\n81\n177.27\n76.52\nGreen\nA\n\n\n82\n157.97\n69.20\nGrey\nA\n\n\n83\n180.20\n93.03\nBlue\nB\n\n\n84\n164.41\n80.35\nBlue\nA\n\n\n85\n171.17\n87.68\nGreen\nA\n\n\n86\n173.12\n91.04\nBrown\nB\n\n\n87\n170.82\n79.29\nBrown\nA\n\n\n88\n179.01\n70.03\nGreen\nB\n\n\n89\n173.40\n85.50\nGrey\nA\n\n\n90\n153.63\n85.02\nBlue\nB\n\n\n91\n157.98\n81.01\nGrey\nB\n\n\n92\n177.32\n90.66\nGrey\nA\n\n\n93\n169.64\n64.72\nGreen\nA\n\n\n94\n176.31\n79.63\nBlue\nA\n\n\n95\n173.12\n87.03\nGreen\nA\n\n\n96\n181.55\n94.48\nBrown\nB\n\n\n97\n164.51\n77.91\nGrey\nB\n\n\n98\n173.67\n70.98\nGreen\nB\n\n\n99\n185.87\n73.14\nBlue\nA\n\n\n100\n175.63\n106.73\nGreen\nA\n\n\n101\n170.16\n63.49\nBlue\nA\n\n\n102\n161.98\n92.24\nBlue\nA\n\n\n103\n164.81\n64.20\nBlue\nB\n\n\n104\n171.76\n91.59\nGrey\nA\n\n\n105\n173.45\n79.38\nBlue\nB\n\n\n106\n178.81\n85.98\nBlue\nA\n\n\n107\n169.10\n92.82\nGrey\nB\n\n\n108\n166.88\n91.30\nBlue\nB\n\n\n109\n173.63\n78.75\nBrown\nB\n\n\n110\n173.67\n54.60\nGreen\nB\n\n\n111\n164.05\n71.77\nGrey\nB\n\n\n112\n170.56\n85.79\nGreen\nA\n\n\n113\n161.59\n65.32\nGreen\nB\n\n\n114\n159.97\n79.96\nGreen\nB\n\n\n115\n167.57\n86.89\nGrey\nB\n\n\n116\n165.20\n86.76\nBlue\nA\n\n\n117\n162.48\n55.40\nGreen\nB\n\n\n118\n179.48\n91.55\nBlue\nA\n\n\n119\n167.69\n85.30\nBlue\nB\n\n\n120\n164.32\n86.76\nBlue\nA\n\n\n121\n176.56\n78.42\nGreen\nB\n\n\n122\n166.03\n68.93\nBlue\nA\n\n\n123\n175.66\n91.10\nGrey\nB\n\n\n124\n173.17\n95.23\nBlue\nB\n\n\n125\n175.84\n100.18\nBrown\nB\n\n\n126\n163.15\n75.93\nBlue\nB\n\n\n127\n170.37\n86.70\nGrey\nB\n\n\n128\n174.11\n85.43\nGrey\nA\n\n\n129\n164.79\n85.64\nGrey\nB\n\n\n130\n170.73\n76.34\nGrey\nA\n\n\n131\n186.59\n70.37\nBrown\nA\n\n\n132\n165.57\n75.13\nBlue\nB\n\n\n133\n169.04\n67.44\nBlue\nB\n\n\n134\n175.40\n101.61\nGreen\nA\n\n\n135\n172.84\n70.44\nBlue\nB\n\n\n136\n173.65\n73.54\nBrown\nB\n\n\n137\n165.04\n87.82\nGreen\nB\n\n\n138\n178.02\n82.15\nBrown\nA\n\n\n139\n170.15\n82.39\nGrey\nB\n\n\n140\n167.53\n68.22\nGreen\nB\n\n\n141\n161.17\n86.42\nBlue\nA\n\n\n142\n159.85\n76.22\nGreen\nB\n\n\n143\n177.30\n64.93\nGrey\nA\n\n\n144\n170.08\n91.70\nGreen\nB\n\n\n145\n171.94\n66.35\nGrey\nB\n\n\n146\n168.39\n84.10\nGreen\nB\n\n\n147\n181.65\n83.92\nBrown\nA\n\n\n148\n162.03\n63.61\nGreen\nB\n\n\n149\n173.01\n83.91\nGreen\nA\n\n\n150\n167.48\n94.82\nGrey\nB\n\n\n151\n162.33\n75.85\nGrey\nB\n\n\n152\n173.18\n75.34\nBlue\nB\n\n\n153\n174.91\n96.38\nBrown\nB\n\n\n154\n167.47\n90.25\nBlue\nB\n\n\n155\n174.41\n94.96\nGrey\nB\n\n\n156\n174.90\n78.69\nGrey\nB\n\n\n157\n171.82\n72.72\nGreen\nA\n\n\n158\n168.90\n81.85\nGrey\nA\n\n\n159\n162.98\n76.76\nBrown\nA\n\n\n160\n155.14\n89.70\nBlue\nB\n\n\n161\n165.63\n66.75\nBlue\nA\n\n\n162\n165.11\n94.75\nGrey\nA\n\n\n163\n178.82\n100.58\nBrown\nB\n\n\n164\n172.67\n75.55\nBrown\nA\n\n\n165\n170.26\n66.56\nGreen\nA\n\n\n166\n167.62\n84.77\nGrey\nA\n\n\n167\n163.63\n55.40\nBlue\nB\n\n\n168\n165.41\n79.29\nGrey\nB\n\n\n169\n174.51\n70.43\nGrey\nA\n\n\n170\n180.01\n70.95\nGreen\nB\n\n\n171\n177.35\n78.97\nBlue\nB\n\n\n172\n174.29\n52.47\nGreen\nB\n\n\n173\n166.63\n78.44\nGrey\nA\n\n\n174\n180.02\n75.06\nBlue\nB\n\n\n175\n168.21\n93.89\nGreen\nB\n\n\n176\n161.29\n67.78\nBrown\nB\n\n\n177\n172.94\n61.05\nGreen\nA\n\n\n178\n166.38\n89.27\nBrown\nA\n\n\n179\n175.07\n82.56\nGrey\nA\n\n\n180\n170.23\n87.77\nBlue\nB\n\n\n181\n175.95\n92.22\nBrown\nA\n\n\n182\n169.59\n78.52\nGrey\nB\n\n\n183\n174.96\n78.73\nBrown\nB\n\n\n184\n172.37\n83.49\nBlue\nB\n\n\n185\n175.60\n77.63\nGrey\nB\n\n\n186\n177.30\n56.96\nGreen\nA\n\n\n187\n176.32\n72.43\nBrown\nA\n\n\n188\n164.18\n63.03\nGreen\nB\n\n\n189\n164.53\n76.59\nGreen\nB\n\n\n190\n171.87\n60.85\nGreen\nB\n\n\n191\n172.65\n98.63\nGreen\nB\n\n\n192\n177.06\n79.33\nBlue\nB\n\n\n193\n171.54\n75.83\nBrown\nB\n\n\n194\n168.89\n74.78\nBlue\nB\n\n\n195\n163.36\n96.49\nGrey\nB\n\n\n196\n160.62\n84.62\nGrey\nA\n\n\n197\n165.65\n69.40\nBlue\nB\n\n\n198\n169.85\n84.64\nGreen\nB\n\n\n199\n156.28\n74.89\nGrey\nA\n\n\n200\n174.21\n86.76\nGrey\nA\n\n\n201\n170.00\n86.61\nBlue\nA\n\n\n202\n159.73\n76.70\nGreen\nB\n\n\n203\n164.18\n82.22\nBlue\nB\n\n\n204\n165.78\n92.82\nBrown\nB\n\n\n205\n165.10\n85.67\nGreen\nB\n\n\n206\n172.86\n83.77\nBrown\nB\n\n\n207\n169.74\n73.18\nGrey\nB\n\n\n208\n175.94\n81.90\nBlue\nB\n\n\n209\n162.98\n84.52\nBrown\nB\n\n\n210\n159.15\n73.38\nBlue\nB\n\n\n211\n169.32\n73.60\nBlue\nA\n\n\n212\n154.14\n71.95\nBlue\nB\n\n\n213\n172.24\n75.03\nBrown\nB\n\n\n214\n154.08\n90.05\nBrown\nA\n\n\n215\n167.74\n91.83\nGrey\nA\n\n\n216\n170.58\n76.46\nBlue\nA\n\n\n217\n166.15\n77.12\nGrey\nB\n\n\n218\n178.03\n89.99\nBrown\nB\n\n\n219\n164.31\n95.61\nBrown\nA\n\n\n220\n178.09\n87.15\nBlue\nA\n\n\n221\n168.28\n76.83\nBrown\nB\n\n\n222\n178.79\n69.79\nGrey\nB\n\n\n223\n163.44\n82.43\nGrey\nA\n\n\n224\n175.38\n72.01\nGreen\nA\n\n\n225\n180.53\n72.40\nGrey\nB\n\n\n226\n176.48\n79.89\nGrey\nB\n\n\n227\n173.83\n71.29\nBrown\nB\n\n\n228\n163.92\n97.71\nBlue\nA\n\n\n229\n169.49\n81.67\nGreen\nB\n\n\n230\n167.89\n76.51\nGrey\nB\n\n\n231\n164.06\n77.95\nBlue\nB\n\n\n232\n177.57\n60.08\nBrown\nB\n\n\n233\n170.36\n93.87\nGreen\nB\n\n\n234\n163.29\n78.48\nBrown\nB\n\n\n235\n162.85\n84.71\nBrown\nA\n\n\n236\n159.09\n75.07\nBlue\nA\n\n\n237\n171.42\n65.11\nBlue\nB\n\n\n238\n168.34\n83.67\nGrey\nA\n\n\n239\n172.22\n80.99\nBlue\nA\n\n\n240\n166.33\n83.19\nBlue\nA\n\n\n241\n174.84\n85.51\nGrey\nB\n\n\n242\n165.34\n69.62\nGreen\nB\n\n\n243\n169.36\n79.82\nGreen\nA\n\n\n244\n179.62\n93.70\nBrown\nA\n\n\n245\n169.82\n84.24\nBlue\nA\n\n\n246\n166.66\n83.28\nGreen\nB\n\n\n247\n161.48\n85.71\nGreen\nA\n\n\n248\n157.12\n77.46\nBlue\nB\n\n\n249\n180.87\n76.46\nGreen\nA\n\n\n250\n165.45\n74.02\nGrey\nB\n\n\n251\n174.05\n90.16\nGrey\nA\n\n\n252\n169.76\n82.22\nBrown\nA\n\n\n253\n163.57\n88.21\nBrown\nB\n\n\n254\n169.04\n79.57\nGreen\nB\n\n\n255\n166.77\n86.78\nGreen\nB\n\n\n256\n177.32\n81.80\nBlue\nA\n\n\n257\n174.64\n79.11\nGreen\nA\n\n\n258\n157.93\n71.06\nBlue\nB\n\n\n259\n166.43\n84.81\nGreen\nA\n\n\n260\n181.11\n95.02\nGrey\nB\n\n\n261\n175.02\n64.48\nGreen\nA\n\n\n262\n166.49\n75.80\nBlue\nB\n\n\n263\n172.96\n101.45\nBrown\nA\n\n\n264\n167.46\n77.60\nBrown\nA\n\n\n265\n171.88\n99.65\nBlue\nB\n\n\n266\n169.96\n76.15\nBlue\nB\n\n\n267\n171.61\n69.22\nBrown\nB\n\n\n268\n173.93\n77.01\nGrey\nA\n\n\n269\n175.86\n87.87\nBrown\nA\n\n\n270\n163.80\n79.77\nBrown\nA\n\n\n271\n162.62\n89.06\nBrown\nB\n\n\n272\n164.56\n81.04\nBlue\nA\n\n\n273\n169.15\n78.08\nBlue\nB\n\n\n274\n178.99\n82.12\nBlue\nA\n\n\n275\n172.16\n79.83\nBlue\nB\n\n\n276\n177.58\n64.16\nBlue\nB\n\n\n277\n172.11\n87.64\nBlue\nA\n\n\n278\n172.05\n80.89\nGreen\nA\n\n\n279\n158.79\n88.85\nGrey\nB\n\n\n280\n164.65\n76.36\nGrey\nB\n\n\n281\n158.25\n85.47\nBlue\nB\n\n\n282\n161.47\n86.85\nGrey\nB\n\n\n283\n168.93\n74.24\nBlue\nB\n\n\n284\n173.54\n81.79\nGrey\nB\n\n\n285\n168.52\n71.50\nGrey\nA\n\n\n286\n175.56\n79.94\nBlue\nA\n\n\n287\n171.62\n108.83\nBlue\nA\n\n\n288\n181.84\n68.46\nBrown\nB\n\n\n289\n158.44\n86.19\nBlue\nB\n\n\n290\n176.02\n82.23\nGreen\nB\n\n\n291\n168.42\n84.62\nGreen\nB\n\n\n292\n173.19\n83.46\nGrey\nA\n\n\n293\n166.54\n85.19\nBrown\nA\n\n\n294\n151.38\n81.86\nGrey\nA\n\n\n295\n168.90\n88.59\nGreen\nB\n\n\n296\n172.88\n90.38\nBlue\nA\n\n\n297\n163.58\n86.98\nGreen\nA\n\n\n298\n171.87\n72.61\nBrown\nB\n\n\n299\n155.50\n86.58\nGrey\nA\n\n\n300\n161.69\n77.95\nGreen\nA\n\n\n301\n163.56\n83.34\nBlue\nA\n\n\n302\n156.77\n83.00\nGrey\nA\n\n\n303\n179.06\n81.64\nBlue\nA\n\n\n304\n160.63\n79.35\nBlue\nB\n\n\n305\n179.69\n80.81\nBrown\nB\n\n\n306\n177.41\n80.01\nBrown\nB\n\n\n307\n171.50\n77.46\nGreen\nA\n\n\n308\n165.03\n95.09\nGrey\nA\n\n\n309\n165.97\n73.05\nBlue\nB\n\n\n310\n174.97\n88.43\nBrown\nA\n\n\n311\n166.61\n69.08\nGreen\nA\n\n\n312\n167.91\n87.84\nBlue\nB\n\n\n313\n169.47\n56.45\nBlue\nA\n\n\n314\n167.06\n72.44\nBrown\nA\n\n\n315\n169.09\n85.62\nBrown\nA\n\n\n316\n176.48\n84.64\nGreen\nA\n\n\n317\n169.26\n77.97\nBrown\nB\n\n\n318\n166.44\n81.41\nBlue\nA\n\n\n319\n167.66\n97.88\nBrown\nB\n\n\n320\n177.46\n86.76\nGrey\nA\n\n\n321\n167.35\n87.24\nGreen\nA\n\n\n322\n172.86\n73.35\nGrey\nA\n\n\n323\n177.16\n89.08\nGrey\nB\n\n\n324\n165.88\n90.44\nGreen\nB\n\n\n325\n167.17\n85.64\nBlue\nB\n\n\n326\n183.38\n55.84\nGrey\nB\n\n\n327\n169.61\n84.00\nGrey\nB\n\n\n328\n169.70\n85.50\nGreen\nA\n\n\n329\n166.65\n82.95\nGrey\nB\n\n\n330\n164.89\n82.81\nBlue\nA\n\n\n331\n158.82\n74.39\nGrey\nA\n\n\n332\n168.01\n88.06\nBrown\nB\n\n\n333\n165.09\n76.29\nBrown\nA\n\n\n334\n180.56\n75.08\nBlue\nB\n\n\n335\n167.27\n77.80\nBlue\nA\n\n\n336\n173.88\n69.05\nBlue\nB\n\n\n337\n168.97\n77.02\nBrown\nA\n\n\n338\n173.34\n73.76\nBrown\nA\n\n\n339\n176.46\n87.81\nGrey\nB\n\n\n340\n169.78\n94.35\nGreen\nA\n\n\n341\n169.27\n59.98\nGrey\nB\n\n\n342\n173.28\n75.23\nGreen\nA\n\n\n343\n175.18\n97.06\nBlue\nA\n\n\n344\n169.39\n73.95\nBrown\nA\n\n\n345\n172.04\n70.90\nBrown\nB\n\n\n346\n161.62\n96.00\nGrey\nB\n\n\n347\n167.23\n89.55\nGrey\nA\n\n\n348\n168.43\n76.65\nGrey\nA\n\n\n349\n165.32\n81.25\nBrown\nA\n\n\n350\n170.01\n70.74\nGreen\nA\n\n\n351\n173.34\n68.53\nGreen\nB\n\n\n352\n176.02\n77.40\nBlue\nA\n\n\n353\n180.56\n78.09\nBlue\nA\n\n\n354\n170.24\n80.80\nBlue\nB\n\n\n355\n158.60\n103.87\nGreen\nB\n\n\n356\n174.98\n78.75\nGrey\nA\n\n\n357\n168.61\n72.29\nGreen\nB\n\n\n358\n170.10\n68.90\nBlue\nA\n\n\n359\n174.01\n77.02\nBlue\nA\n\n\n360\n164.99\n72.64\nGrey\nA\n\n\n361\n159.98\n83.14\nGrey\nB\n\n\n362\n175.54\n96.49\nGreen\nA\n\n\n363\n179.56\n96.62\nGrey\nA\n\n\n364\n165.69\n91.31\nBlue\nA\n\n\n365\n173.79\n85.11\nGreen\nB\n\n\n366\n187.49\n100.73\nBrown\nB\n\n\n367\n160.26\n76.32\nGreen\nB\n\n\n368\n173.90\n73.22\nGreen\nB\n\n\n369\n172.34\n87.56\nBrown\nA\n\n\n370\n167.85\n71.15\nBrown\nB\n\n\n371\n164.94\n78.22\nBlue\nA\n\n\n372\n168.43\n100.49\nGreen\nA\n\n\n373\n170.77\n61.10\nGreen\nA\n\n\n374\n165.16\n94.65\nGrey\nA\n\n\n375\n181.06\n82.71\nBlue\nA\n\n\n376\n180.98\n69.60\nGreen\nA\n\n\n377\n165.63\n102.78\nBrown\nA\n\n\n378\n173.88\n84.07\nBlue\nA\n\n\n379\n161.95\n77.01\nGreen\nB\n\n\n380\n154.79\n90.84\nBrown\nB\n\n\n381\n172.77\n86.06\nBrown\nA\n\n\n382\n167.95\n80.49\nBlue\nA\n\n\n383\n172.97\n101.62\nGrey\nA\n\n\n384\n171.57\n87.71\nGrey\nA\n\n\n385\n176.72\n75.32\nBlue\nA\n\n\n386\n164.06\n87.94\nGreen\nA\n\n\n387\n172.79\n83.01\nBlue\nB\n\n\n388\n175.86\n75.64\nBrown\nB\n\n\n389\n167.42\n92.96\nBlue\nB\n\n\n390\n162.53\n65.76\nGreen\nB\n\n\n391\n168.44\n74.42\nGreen\nB\n\n\n392\n167.32\n84.70\nBrown\nB\n\n\n393\n182.32\n69.11\nBlue\nB\n\n\n394\n165.47\n77.11\nGrey\nA\n\n\n395\n173.39\n78.83\nBrown\nA\n\n\n396\n176.25\n63.43\nGrey\nB\n\n\n397\n172.76\n78.82\nBrown\nA\n\n\n398\n165.97\n87.00\nBrown\nA\n\n\n399\n161.92\n72.14\nBlue\nA\n\n\n400\n170.86\n74.11\nGreen\nA\n\n\n401\n167.52\n92.29\nGrey\nA\n\n\n402\n164.94\n84.64\nGreen\nB\n\n\n403\n168.27\n79.70\nBlue\nA\n\n\n404\n171.15\n79.21\nGrey\nA\n\n\n405\n175.77\n74.46\nBlue\nA\n\n\n406\n168.97\n89.02\nBrown\nB\n\n\n407\n158.81\n80.27\nBlue\nB\n\n\n408\n174.03\n89.98\nBrown\nA\n\n\n409\n169.40\n86.23\nGrey\nB\n\n\n410\n165.39\n71.14\nGrey\nB\n\n\n411\n169.39\n69.60\nBlue\nA\n\n\n412\n169.70\n64.77\nGrey\nB\n\n\n413\n169.33\n55.84\nGreen\nA\n\n\n414\n166.31\n66.28\nBlue\nA\n\n\n415\n171.87\n82.67\nBlue\nA\n\n\n416\n169.81\n85.32\nBlue\nB\n\n\n417\n165.96\n98.49\nBrown\nA\n\n\n418\n170.11\n82.69\nGreen\nB\n\n\n419\n172.79\n71.13\nGreen\nA\n\n\n420\n151.57\n74.58\nGreen\nB\n\n\n421\n170.07\n77.48\nBlue\nA\n\n\n422\n175.22\n86.84\nGrey\nB\n\n\n423\n167.23\n83.74\nBlue\nA\n\n\n424\n167.22\n71.24\nGreen\nB\n\n\n425\n170.32\n75.31\nBlue\nB\n\n\n426\n171.78\n73.14\nBrown\nB\n\n\n427\n167.27\n59.76\nGrey\nB\n\n\n428\n171.14\n86.26\nBrown\nA\n\n\n429\n163.64\n86.49\nBlue\nA\n\n\n430\n168.21\n80.75\nBlue\nB\n\n\n431\n173.15\n90.29\nBrown\nB\n\n\n432\n179.22\n77.37\nBrown\nA\n\n\n433\n167.71\n87.98\nBrown\nA\n\n\n434\n164.39\n72.47\nGrey\nA\n\n\n435\n162.67\n92.86\nGreen\nA\n\n\n436\n167.86\n82.60\nBrown\nB\n\n\n437\n175.16\n89.60\nBlue\nB\n\n\n438\n171.33\n76.94\nGrey\nB\n\n\n439\n170.80\n92.12\nBlue\nB\n\n\n440\n153.98\n63.60\nBlue\nB\n\n\n441\n176.48\n91.12\nBrown\nA\n\n\n442\n165.54\n86.03\nGrey\nB\n\n\n443\n170.35\n71.17\nGrey\nB\n\n\n444\n164.12\n69.42\nGreen\nB\n\n\n445\n166.53\n92.79\nBlue\nB\n\n\n446\n161.65\n80.08\nGrey\nB\n\n\n447\n162.83\n71.39\nGrey\nB\n\n\n448\n154.30\n73.71\nBlue\nB\n\n\n449\n171.31\n96.96\nGrey\nB\n\n\n450\n170.92\n92.17\nGrey\nA\n\n\n451\n176.17\n80.38\nBlue\nA\n\n\n452\n164.79\n85.05\nGrey\nA\n\n\n453\n172.76\n89.85\nBlue\nB\n\n\n454\n172.17\n90.20\nGrey\nA\n\n\n455\n169.22\n80.94\nBlue\nB\n\n\n456\n174.34\n89.89\nGrey\nA\n\n\n457\n159.21\n85.14\nGreen\nA\n\n\n458\n159.25\n84.37\nBrown\nA\n\n\n459\n178.79\n85.92\nBrown\nB\n\n\n460\n170.75\n100.58\nGreen\nA\n\n\n461\n174.01\n87.50\nGreen\nB\n\n\n462\n170.14\n60.14\nBlue\nA\n\n\n463\n166.26\n92.74\nGrey\nA\n\n\n464\n158.56\n86.13\nBlue\nB\n\n\n465\n172.19\n66.96\nBrown\nB\n\n\n466\n180.26\n58.91\nGreen\nA\n\n\n467\n173.94\n76.43\nGreen\nB\n\n\n468\n174.47\n82.83\nBrown\nA\n\n\n469\n174.15\n75.78\nGreen\nA\n\n\n470\n178.28\n77.57\nBlue\nB\n\n\n471\n167.32\n76.81\nBrown\nB\n\n\n472\n167.55\n74.71\nBrown\nB\n\n\n473\n174.61\n80.27\nGreen\nA\n\n\n474\n173.82\n76.83\nBlue\nB\n\n\n475\n167.19\n79.44\nGreen\nA\n\n\n476\n177.24\n93.01\nBlue\nA\n\n\n477\n176.86\n82.12\nGreen\nB\n\n\n478\n179.92\n65.61\nBlue\nB\n\n\n479\n172.28\n93.04\nGreen\nB\n\n\n480\n171.46\n89.48\nGreen\nB\n\n\n481\n172.67\n79.50\nGreen\nA\n\n\n482\n166.06\n77.27\nGreen\nB\n\n\n483\n176.50\n77.26\nBrown\nB\n\n\n484\n156.14\n92.50\nBlue\nB\n\n\n485\n174.33\n63.12\nGreen\nA\n\n\n486\n165.67\n86.60\nBrown\nB\n\n\n487\n182.18\n67.37\nGreen\nB\n\n\n488\n168.91\n86.88\nBrown\nB\n\n\n489\n168.06\n81.96\nBlue\nB\n\n\n490\n168.13\n89.14\nGreen\nB\n\n\n491\n165.28\n79.44\nGrey\nB\n\n\n492\n162.20\n80.96\nGreen\nB\n\n\n493\n168.13\n102.88\nGrey\nB\n\n\n494\n167.04\n82.09\nBrown\nB\n\n\n495\n171.84\n77.24\nGrey\nB\n\n\n496\n184.84\n88.92\nGreen\nA\n\n\n497\n163.31\n75.80\nGrey\nB\n\n\n498\n168.68\n62.92\nBlue\nA\n\n\n499\n164.68\n87.64\nBrown\nB\n\n\n500\n168.44\n80.81\nBrown\nB\n\n\n501\n170.56\n79.15\nGrey\nB\n\n\n502\n170.47\n80.63\nBrown\nA\n\n\n503\n175.32\n78.17\nGrey\nB\n\n\n504\n158.59\n74.18\nBrown\nB\n\n\n505\n165.56\n80.54\nGrey\nA\n\n\n506\n169.45\n94.18\nGreen\nA\n\n\n507\n178.75\n85.72\nGreen\nA\n\n\n508\n162.96\n74.55\nGrey\nA\n\n\n509\n178.21\n73.44\nBlue\nA\n\n\n510\n174.59\n72.40\nBlue\nB\n\n\n511\n165.34\n56.60\nBlue\nB\n\n\n512\n163.03\n86.26\nBrown\nA\n\n\n513\n169.64\n95.38\nGrey\nA\n\n\n514\n164.10\n70.94\nBlue\nA\n\n\n515\n176.51\n62.65\nGreen\nB\n\n\n516\n171.61\n78.36\nBlue\nA\n\n\n517\n172.94\n84.12\nBrown\nA\n\n\n518\n171.89\n87.12\nGreen\nA\n\n\n519\n170.93\n94.28\nGreen\nA\n\n\n520\n177.57\n67.06\nGreen\nA\n\n\n521\n160.03\n78.09\nGreen\nB\n\n\n522\n169.60\n88.06\nGreen\nA\n\n\n523\n173.22\n78.78\nGrey\nB\n\n\n524\n170.88\n93.96\nBlue\nB\n\n\n525\n176.22\n85.53\nGrey\nA\n\n\n526\n161.18\n80.51\nBrown\nB\n\n\n527\n177.53\n71.20\nGreen\nB\n\n\n528\n169.75\n59.59\nBrown\nA\n\n\n529\n176.47\n72.47\nGreen\nA\n\n\n530\n169.93\n73.92\nBrown\nB\n\n\n531\n171.35\n88.80\nBrown\nB\n\n\n532\n154.61\n87.71\nGreen\nA\n\n\n533\n169.48\n100.93\nBlue\nB\n\n\n534\n159.87\n83.71\nBrown\nB\n\n\n535\n181.63\n71.47\nBlue\nB\n\n\n536\n172.27\n76.68\nGreen\nA\n\n\n537\n169.75\n91.72\nBrown\nA\n\n\n538\n172.92\n84.89\nBlue\nB\n\n\n539\n168.23\n96.27\nBlue\nA\n\n\n540\n170.28\n99.65\nGrey\nB\n\n\n541\n178.00\n93.20\nGreen\nB\n\n\n542\n167.68\n78.06\nGreen\nA\n\n\n543\n178.57\n75.86\nGrey\nA\n\n\n544\n161.43\n90.47\nBlue\nA\n\n\n545\n168.57\n87.13\nGreen\nB\n\n\n546\n169.03\n78.56\nBrown\nB\n\n\n547\n176.40\n69.67\nGrey\nB\n\n\n548\n164.51\n73.67\nGrey\nB\n\n\n549\n175.72\n98.95\nBrown\nA\n\n\n550\n164.30\n86.90\nGrey\nA\n\n\n551\n179.74\n75.47\nGrey\nA\n\n\n552\n169.85\n89.23\nBlue\nB\n\n\n553\n164.25\n87.27\nGreen\nB\n\n\n554\n163.10\n76.19\nGrey\nA\n\n\n555\n175.64\n88.12\nBrown\nB\n\n\n556\n169.75\n73.06\nGreen\nB\n\n\n557\n163.19\n95.33\nBrown\nB\n\n\n558\n163.43\n87.91\nGrey\nB\n\n\n559\n170.85\n107.88\nBrown\nB\n\n\n560\n175.98\n66.96\nGrey\nA\n\n\n561\n174.14\n79.59\nGrey\nA\n\n\n562\n164.63\n93.77\nBrown\nB\n\n\n563\n171.05\n83.14\nGrey\nB\n\n\n564\n175.30\n80.91\nBlue\nA\n\n\n565\n171.79\n77.92\nGreen\nB\n\n\n566\n190.44\n81.94\nBlue\nA\n\n\n567\n162.78\n81.46\nBlue\nA\n\n\n568\n164.60\n77.69\nBlue\nA\n\n\n569\n178.35\n67.43\nGrey\nB\n\n\n570\n171.65\n78.93\nBrown\nB\n\n\n571\n177.71\n89.10\nBrown\nB\n\n\n572\n176.95\n78.05\nGrey\nB\n\n\n573\n172.74\n70.49\nBlue\nB\n\n\n574\n176.61\n77.40\nBlue\nA\n\n\n575\n168.20\n77.70\nGreen\nB\n\n\n576\n177.16\n76.00\nGreen\nA\n\n\n577\n163.80\n80.86\nBlue\nA\n\n\n578\n175.10\n82.01\nGrey\nA\n\n\n579\n163.18\n75.15\nBlue\nB\n\n\n580\n163.82\n75.95\nBlue\nB\n\n\n581\n177.32\n78.83\nGrey\nB\n\n\n582\n174.91\n71.80\nGrey\nA\n\n\n583\n166.34\n70.16\nGreen\nB\n\n\n584\n175.25\n65.76\nBrown\nA\n\n\n585\n156.16\n86.63\nGreen\nB\n\n\n586\n166.14\n69.57\nGreen\nB\n\n\n587\n161.35\n82.06\nBlue\nB\n\n\n588\n164.37\n68.86\nGreen\nA\n\n\n589\n164.92\n76.66\nBlue\nB\n\n\n590\n174.23\n82.38\nBrown\nA\n\n\n591\n174.52\n70.99\nGrey\nA\n\n\n592\n186.73\n77.90\nBrown\nA\n\n\n593\n176.61\n66.73\nBrown\nB\n\n\n594\n178.36\n79.33\nBlue\nB\n\n\n595\n179.95\n88.37\nGreen\nA\n\n\n596\n162.99\n67.45\nGreen\nB\n\n\n597\n161.19\n69.84\nBlue\nB\n\n\n598\n166.66\n73.27\nBlue\nB\n\n\n599\n166.08\n76.23\nGrey\nA\n\n\n600\n162.38\n93.61\nGreen\nA\n\n\n601\n156.36\n93.38\nBlue\nA\n\n\n602\n173.69\n82.56\nBrown\nB\n\n\n603\n177.88\n71.49\nGreen\nA\n\n\n604\n162.75\n71.58\nBlue\nB\n\n\n605\n155.25\n79.86\nBrown\nA\n\n\n606\n173.30\n74.63\nBlue\nA\n\n\n607\n171.15\n85.35\nBlue\nA\n\n\n608\n174.29\n81.74\nBlue\nA\n\n\n609\n166.11\n77.77\nGrey\nA\n\n\n610\n177.69\n71.63\nGrey\nA\n\n\n611\n176.83\n97.28\nGreen\nB\n\n\n612\n173.63\n66.37\nGrey\nA\n\n\n613\n168.13\n84.93\nGreen\nA\n\n\n614\n186.67\n89.01\nBlue\nB\n\n\n615\n169.45\n91.76\nBlue\nB\n\n\n616\n178.85\n64.77\nBlue\nA\n\n\n617\n161.17\n68.79\nGrey\nB\n\n\n618\n167.75\n63.01\nGreen\nA\n\n\n619\n171.41\n88.07\nGrey\nA\n\n\n620\n160.24\n79.17\nGrey\nB\n\n\n621\n170.00\n84.39\nGrey\nB\n\n\n622\n172.43\n90.57\nBlue\nA\n\n\n623\n178.24\n82.11\nGreen\nB\n\n\n624\n174.22\n85.25\nBrown\nA\n\n\n625\n180.30\n77.02\nGreen\nB\n\n\n626\n174.27\n89.12\nBrown\nA\n\n\n627\n170.56\n82.55\nGreen\nA\n\n\n628\n176.39\n76.38\nGrey\nB\n\n\n629\n163.32\n65.88\nGreen\nA\n\n\n630\n170.75\n74.43\nGrey\nA\n\n\n631\n160.66\n61.51\nBlue\nA\n\n\n632\n172.63\n83.80\nBrown\nA\n\n\n633\n166.59\n92.43\nBlue\nB\n\n\n634\n169.93\n67.27\nGreen\nA\n\n\n635\n175.05\n77.63\nGrey\nB\n\n\n636\n178.56\n60.04\nBlue\nB\n\n\n637\n168.06\n66.69\nGrey\nB\n\n\n638\n170.22\n73.47\nBlue\nA\n\n\n639\n176.07\n75.65\nBlue\nB\n\n\n640\n166.89\n70.63\nBlue\nA\n\n\n641\n167.15\n62.59\nBlue\nA\n\n\n642\n168.53\n79.38\nBlue\nA\n\n\n643\n172.10\n74.06\nGrey\nA\n\n\n644\n174.17\n63.32\nGrey\nA\n\n\n645\n174.77\n87.55\nGrey\nB\n\n\n646\n176.97\n80.21\nBlue\nB\n\n\n647\n164.17\n79.90\nGrey\nA\n\n\n648\n171.23\n71.95\nGrey\nB\n\n\n649\n178.24\n71.82\nGreen\nB\n\n\n650\n153.72\n72.64\nBrown\nA\n\n\n651\n162.70\n82.01\nBrown\nB\n\n\n652\n170.51\n89.57\nGreen\nB\n\n\n653\n163.95\n68.58\nBrown\nA\n\n\n654\n162.51\n83.46\nGrey\nA\n\n\n655\n164.24\n82.45\nBrown\nB\n\n\n656\n167.54\n83.40\nBrown\nA\n\n\n657\n180.75\n81.15\nBlue\nB\n\n\n658\n169.94\n91.08\nBrown\nA\n\n\n659\n174.52\n73.70\nBrown\nA\n\n\n660\n163.22\n95.60\nBrown\nA\n\n\n661\n175.33\n74.50\nGreen\nB\n\n\n662\n171.08\n62.38\nBrown\nA\n\n\n663\n171.09\n77.07\nBlue\nB\n\n\n664\n170.31\n66.84\nBrown\nB\n\n\n665\n172.64\n95.30\nBrown\nA\n\n\n666\n174.63\n76.54\nBlue\nB\n\n\n667\n169.94\n84.62\nBrown\nB\n\n\n668\n176.14\n63.09\nBrown\nB\n\n\n669\n174.21\n66.37\nGrey\nB\n\n\n670\n172.13\n84.67\nBrown\nB\n\n\n671\n169.09\n84.65\nBrown\nB\n\n\n672\n169.38\n74.12\nBlue\nA\n\n\n673\n168.05\n82.06\nBrown\nA\n\n\n674\n162.81\n88.53\nBrown\nB\n\n\n675\n171.95\n88.09\nBlue\nA\n\n\n676\n170.11\n73.98\nBrown\nA\n\n\n677\n175.39\n91.79\nGreen\nA\n\n\n678\n174.19\n82.75\nGreen\nA\n\n\n679\n167.34\n86.30\nBrown\nA\n\n\n680\n168.52\n98.53\nBlue\nB\n\n\n681\n176.53\n92.44\nBrown\nB\n\n\n682\n166.62\n78.45\nBlue\nB\n\n\n683\n161.31\n62.22\nGrey\nB\n\n\n684\n166.47\n70.96\nBlue\nA\n\n\n685\n180.05\n73.98\nBlue\nB\n\n\n686\n168.94\n89.70\nGreen\nA\n\n\n687\n169.79\n80.33\nBlue\nB\n\n\n688\n168.25\n74.68\nBlue\nA\n\n\n689\n164.29\n82.73\nBlue\nB\n\n\n690\n171.67\n91.56\nBrown\nB\n\n\n691\n174.31\n77.22\nBrown\nB\n\n\n692\n172.06\n71.97\nBlue\nA\n\n\n693\n161.57\n72.75\nBlue\nA\n\n\n694\n164.84\n76.83\nBlue\nB\n\n\n695\n172.66\n67.10\nGreen\nA\n\n\n696\n162.87\n49.90\nBlue\nA\n\n\n697\n163.19\n78.14\nBrown\nA\n\n\n698\n164.02\n96.30\nGreen\nB\n\n\n699\n183.65\n99.65\nBrown\nA\n\n\n700\n175.41\n82.76\nBrown\nB\n\n\n701\n174.07\n80.72\nBlue\nA\n\n\n702\n174.03\n94.90\nBrown\nA\n\n\n703\n167.99\n56.45\nBrown\nB\n\n\n704\n173.09\n78.02\nGreen\nB\n\n\n705\n171.77\n99.21\nBrown\nB\n\n\n706\n179.12\n73.48\nGreen\nB\n\n\n707\n174.09\n70.61\nBlue\nA\n\n\n708\n161.14\n77.89\nGrey\nB\n\n\n709\n174.88\n73.97\nBlue\nB\n\n\n710\n170.58\n73.96\nBlue\nA\n\n\n711\n170.48\n80.32\nGrey\nA\n\n\n712\n179.76\n93.34\nGreen\nB\n\n\n713\n170.23\n85.36\nBlue\nA\n\n\n714\n168.76\n87.17\nBlue\nB\n\n\n715\n172.88\n81.29\nGreen\nA\n\n\n716\n172.18\n89.87\nGreen\nA\n\n\n717\n171.80\n76.74\nBrown\nB\n\n\n718\n166.94\n73.91\nBrown\nA\n\n\n719\n165.70\n90.13\nGreen\nA\n\n\n720\n171.07\n70.05\nBlue\nB\n\n\n721\n164.01\n66.34\nBlue\nA\n\n\n722\n168.21\n70.46\nBrown\nA\n\n\n723\n171.18\n79.93\nBrown\nA\n\n\n724\n164.36\n78.43\nBrown\nB\n\n\n725\n166.96\n95.54\nBlue\nA\n\n\n726\n163.79\n87.12\nBlue\nA\n\n\n727\n165.65\n70.37\nBrown\nB\n\n\n728\n175.15\n81.44\nGrey\nB\n\n\n729\n174.15\n84.45\nBrown\nA\n\n\n730\n180.04\n92.50\nGreen\nB\n\n\n731\n170.75\n92.74\nBlue\nA\n\n\n732\n168.77\n88.26\nBrown\nA\n\n\n733\n164.22\n71.09\nGreen\nA\n\n\n734\n162.97\n76.52\nBrown\nA\n\n\n735\n176.71\n77.90\nGrey\nA\n\n\n736\n176.80\n71.54\nBlue\nA\n\n\n737\n165.90\n90.97\nGreen\nB\n\n\n738\n172.60\n79.67\nBlue\nB\n\n\n739\n167.44\n80.15\nGrey\nA\n\n\n740\n165.58\n90.47\nBlue\nA\n\n\n741\n173.97\n68.93\nGreen\nA\n\n\n742\n171.99\n75.40\nGrey\nB\n\n\n743\n172.34\n78.00\nGreen\nA\n\n\n744\n179.89\n103.31\nBlue\nB\n\n\n745\n167.02\n74.14\nBlue\nB\n\n\n746\n172.16\n54.04\nBlue\nB\n\n\n747\n176.38\n70.12\nGrey\nB\n\n\n748\n170.93\n82.14\nGrey\nB\n\n\n749\n167.08\n91.17\nBrown\nB\n\n\n750\n164.93\n82.62\nBlue\nB\n\n\n751\n175.88\n76.24\nGrey\nB\n\n\n752\n166.28\n83.51\nBrown\nB\n\n\n753\n170.95\n75.33\nGreen\nB\n\n\n754\n179.68\n66.80\nGreen\nA\n\n\n755\n169.16\n93.42\nBrown\nB\n\n\n756\n168.96\n90.89\nBlue\nB\n\n\n757\n163.47\n93.37\nBrown\nB\n\n\n758\n171.15\n71.93\nBrown\nA\n\n\n759\n167.40\n75.02\nBlue\nA\n\n\n760\n161.63\n102.45\nGrey\nA\n\n\n761\n180.13\n77.66\nBrown\nB\n\n\n762\n178.47\n80.87\nBlue\nA\n\n\n763\n169.63\n75.21\nGrey\nA\n\n\n764\n176.56\n86.78\nGreen\nB\n\n\n765\n177.74\n82.43\nGrey\nB\n\n\n766\n169.19\n69.64\nGreen\nB\n\n\n767\n164.83\n97.09\nBrown\nB\n\n\n768\n163.19\n89.89\nBlue\nA\n\n\n769\n165.76\n85.69\nBlue\nA\n\n\n770\n173.29\n72.52\nGreen\nB\n\n\n771\n167.18\n77.84\nGrey\nB\n\n\n772\n172.95\n78.55\nGreen\nA\n\n\n773\n176.74\n74.88\nBlue\nA\n\n\n774\n177.22\n87.75\nGrey\nB\n\n\n775\n166.53\n74.29\nGreen\nA\n\n\n776\n160.60\n67.70\nGreen\nA\n\n\n777\n176.38\n88.54\nGreen\nA\n\n\n778\n174.40\n85.31\nBrown\nA\n\n\n779\n165.25\n91.00\nGreen\nA\n\n\n780\n177.43\n89.33\nBlue\nA\n\n\n781\n167.65\n63.56\nGreen\nA\n\n\n782\n177.33\n94.90\nGrey\nA\n\n\n783\n170.09\n86.71\nGreen\nB\n\n\n784\n165.35\n77.97\nGreen\nA\n\n\n785\n170.60\n76.48\nGrey\nA\n\n\n786\n162.26\n67.41\nGreen\nA\n\n\n787\n167.22\n84.14\nGreen\nA\n\n\n788\n175.02\n74.77\nGreen\nA\n\n\n789\n168.25\n82.26\nBrown\nB\n\n\n790\n179.58\n82.23\nBrown\nB\n\n\n791\n166.60\n63.60\nGrey\nB\n\n\n792\n183.53\n93.09\nGreen\nA\n\n\n793\n162.68\n87.86\nBlue\nB\n\n\n794\n162.25\n78.41\nGrey\nB\n\n\n795\n166.39\n86.34\nBlue\nA\n\n\n796\n168.94\n76.32\nGrey\nA\n\n\n797\n169.38\n66.64\nGreen\nA\n\n\n798\n160.81\n80.23\nBrown\nA\n\n\n799\n175.86\n103.65\nBlue\nA\n\n\n800\n173.55\n75.50\nGreen\nB\n\n\n801\n175.93\n78.76\nBrown\nB\n\n\n802\n174.23\n72.99\nGreen\nA\n\n\n803\n155.07\n78.15\nBrown\nA\n\n\n804\n154.94\n91.89\nGreen\nB\n\n\n805\n181.97\n85.87\nBlue\nA\n\n\n806\n168.37\n78.18\nBlue\nB\n\n\n807\n168.38\n84.86\nGrey\nA\n\n\n808\n164.10\n86.29\nBrown\nA\n\n\n809\n176.51\n83.06\nBrown\nA\n\n\n810\n169.17\n70.59\nBlue\nA\n\n\n811\n165.30\n88.88\nGreen\nA\n\n\n812\n152.73\n106.71\nGrey\nB\n\n\n813\n162.30\n78.38\nGrey\nA\n\n\n814\n169.78\n88.09\nGreen\nA\n\n\n815\n156.24\n69.05\nBrown\nA\n\n\n816\n173.76\n84.85\nBrown\nA\n\n\n817\n167.88\n68.38\nGrey\nB\n\n\n818\n173.61\n80.97\nBrown\nB\n\n\n819\n173.97\n65.25\nBrown\nA\n\n\n820\n170.20\n72.93\nGreen\nB\n\n\n821\n163.11\n76.60\nGreen\nA\n\n\n822\n168.18\n79.78\nGreen\nB\n\n\n823\n180.30\n74.17\nBrown\nB\n\n\n824\n178.59\n108.06\nGrey\nB\n\n\n825\n175.04\n93.19\nBlue\nB\n\n\n826\n166.47\n83.47\nGreen\nA\n\n\n827\n167.79\n103.34\nGreen\nA\n\n\n828\n168.53\n87.19\nGreen\nB\n\n\n829\n173.41\n85.98\nGreen\nA\n\n\n830\n177.26\n71.78\nGreen\nB\n\n\n831\n165.19\n73.09\nGrey\nB\n\n\n832\n160.25\n79.25\nBrown\nA\n\n\n833\n166.17\n75.82\nBlue\nA\n\n\n834\n165.99\n90.73\nBrown\nB\n\n\n835\n174.01\n93.04\nGrey\nB\n\n\n836\n170.75\n73.70\nGreen\nB\n\n\n837\n165.53\n76.12\nGrey\nA\n\n\n838\n163.12\n79.36\nBrown\nB\n\n\n839\n175.52\n104.40\nGrey\nA\n\n\n840\n162.10\n82.79\nGrey\nB\n\n\n841\n170.70\n81.55\nGrey\nA\n\n\n842\n179.68\n80.26\nGrey\nA\n\n\n843\n173.63\n74.21\nBlue\nB\n\n\n844\n164.29\n95.37\nBlue\nA\n\n\n845\n176.13\n65.54\nGrey\nB\n\n\n846\n166.36\n95.99\nBlue\nB\n\n\n847\n159.11\n95.86\nGrey\nB\n\n\n848\n161.11\n82.53\nGreen\nB\n\n\n849\n168.29\n75.64\nBlue\nB\n\n\n850\n169.12\n92.68\nGrey\nA\n\n\n851\n178.47\n79.49\nBlue\nB\n\n\n852\n164.98\n84.26\nBrown\nA\n\n\n853\n167.15\n91.39\nBrown\nB\n\n\n854\n174.75\n89.21\nBlue\nB\n\n\n855\n173.06\n96.82\nGrey\nB\n\n\n856\n170.89\n85.34\nGreen\nA\n\n\n857\n176.36\n81.04\nGreen\nA\n\n\n858\n159.71\n89.90\nGreen\nB\n\n\n859\n179.42\n74.60\nBrown\nA\n\n\n860\n171.31\n77.28\nBrown\nB\n\n\n861\n175.87\n79.65\nGrey\nA\n\n\n862\n172.01\n73.07\nGreen\nB\n\n\n863\n172.25\n88.08\nGreen\nB\n\n\n864\n174.65\n103.53\nGrey\nB\n\n\n865\n169.25\n87.58\nBlue\nB\n\n\n866\n174.45\n76.70\nGrey\nB\n\n\n867\n168.06\n73.86\nGreen\nB\n\n\n868\n168.20\n94.57\nBrown\nB\n\n\n869\n174.37\n83.11\nBrown\nA\n\n\n870\n177.28\n84.83\nGreen\nA\n\n\n871\n161.53\n68.31\nBlue\nA\n\n\n872\n176.04\n82.64\nBlue\nB\n\n\n873\n168.29\n89.21\nBrown\nB\n\n\n874\n171.79\n84.39\nGrey\nB\n\n\n875\n161.65\n64.42\nGrey\nB\n\n\n876\n167.76\n72.40\nBlue\nB\n\n\n877\n165.00\n85.91\nBlue\nA\n\n\n878\n169.62\n86.85\nGreen\nA\n\n\n879\n164.89\n86.33\nBrown\nB\n\n\n880\n172.45\n92.88\nBlue\nB\n\n\n881\n177.68\n82.90\nGrey\nA\n\n\n882\n171.01\n73.70\nBrown\nB\n\n\n883\n172.80\n70.30\nGreen\nA\n\n\n884\n162.82\n78.72\nGrey\nA\n\n\n885\n172.07\n78.42\nBrown\nB\n\n\n886\n167.53\n76.82\nGreen\nB\n\n\n887\n166.53\n61.72\nBrown\nB\n\n\n888\n175.83\n82.41\nBrown\nA\n\n\n889\n175.85\n78.54\nBlue\nB\n\n\n890\n172.35\n77.06\nGreen\nB\n\n\n891\n159.89\n72.25\nBlue\nA\n\n\n892\n168.86\n74.20\nGreen\nA\n\n\n893\n168.82\n84.83\nGrey\nA\n\n\n894\n162.43\n76.83\nGrey\nA\n\n\n895\n171.67\n78.62\nGreen\nA\n\n\n896\n170.28\n84.15\nGrey\nA\n\n\n897\n164.97\n92.02\nGrey\nA\n\n\n898\n173.88\n79.34\nGrey\nA\n\n\n899\n169.67\n89.66\nBlue\nA\n\n\n900\n161.69\n75.16\nBlue\nB\n\n\n901\n172.27\n85.13\nBrown\nA\n\n\n902\n169.54\n91.62\nGreen\nA\n\n\n903\n168.60\n77.12\nGrey\nB\n\n\n904\n182.19\n95.20\nBrown\nA\n\n\n905\n168.41\n96.50\nGrey\nB\n\n\n906\n172.94\n88.94\nGreen\nB\n\n\n907\n161.49\n74.56\nGreen\nA\n\n\n908\n173.85\n76.79\nGreen\nA\n\n\n909\n174.67\n68.89\nBlue\nB\n\n\n910\n170.00\n79.42\nGreen\nB\n\n\n911\n173.66\n69.17\nGrey\nB\n\n\n912\n171.71\n75.47\nGreen\nB\n\n\n913\n176.86\n86.89\nBrown\nB\n\n\n914\n177.43\n83.44\nGrey\nA\n\n\n915\n176.72\n87.39\nGrey\nA\n\n\n916\n163.52\n85.04\nGreen\nA\n\n\n917\n167.98\n64.71\nBlue\nB\n\n\n918\n169.84\n68.25\nBrown\nA\n\n\n919\n181.70\n86.95\nGrey\nA\n\n\n920\n168.66\n87.02\nGreen\nA\n\n\n921\n178.01\n76.09\nGrey\nB\n\n\n922\n172.97\n86.43\nBlue\nA\n\n\n923\n163.88\n94.98\nBlue\nB\n\n\n924\n175.91\n70.74\nGreen\nB\n\n\n925\n175.02\n83.33\nGrey\nA\n\n\n926\n166.03\n74.03\nGrey\nA\n\n\n927\n168.75\n68.48\nGrey\nB\n\n\n928\n169.23\n91.66\nGrey\nA\n\n\n929\n180.73\n84.52\nBlue\nA\n\n\n930\n171.83\n84.99\nBrown\nA\n\n\n931\n175.38\n84.91\nBrown\nA\n\n\n932\n174.40\n68.84\nGrey\nA\n\n\n933\n169.82\n84.77\nGrey\nB\n\n\n934\n167.19\n86.10\nBrown\nB\n\n\n935\n179.94\n82.12\nBlue\nB\n\n\n936\n164.61\n83.94\nBrown\nB\n\n\n937\n165.90\n80.76\nGreen\nA\n\n\n938\n168.49\n62.05\nGreen\nB\n\n\n939\n171.94\n62.71\nBlue\nB\n\n\n940\n166.10\n70.15\nGreen\nA\n\n\n941\n179.36\n67.38\nGrey\nA\n\n\n942\n170.49\n72.80\nGreen\nA\n\n\n943\n169.66\n72.84\nBrown\nB\n\n\n944\n165.70\n67.24\nGreen\nA\n\n\n945\n167.07\n69.70\nGreen\nB\n\n\n946\n167.18\n85.68\nGreen\nA\n\n\n947\n176.69\n71.44\nBlue\nA\n\n\n948\n167.44\n82.49\nGreen\nB\n\n\n949\n174.51\n86.17\nGrey\nA\n\n\n950\n165.77\n80.27\nBrown\nA\n\n\n951\n159.22\n69.53\nBrown\nB\n\n\n952\n158.99\n81.21\nGrey\nA\n\n\n953\n167.96\n94.78\nBlue\nA\n\n\n954\n166.47\n57.39\nBlue\nB\n\n\n955\n165.49\n77.38\nGrey\nB\n\n\n956\n161.26\n77.51\nBrown\nB\n\n\n957\n171.96\n71.25\nBrown\nB\n\n\n958\n171.74\n74.65\nBlue\nA\n\n\n959\n165.00\n64.00\nGrey\nA\n\n\n960\n175.32\n94.93\nGrey\nA\n\n\n961\n168.47\n70.10\nBrown\nA\n\n\n962\n169.96\n76.55\nGreen\nB\n\n\n963\n159.99\n85.83\nBrown\nA\n\n\n964\n182.92\n68.42\nBlue\nA\n\n\n965\n166.44\n77.82\nGrey\nB\n\n\n966\n168.62\n79.84\nGrey\nB\n\n\n967\n172.09\n61.65\nBlue\nA\n\n\n968\n175.73\n76.45\nBrown\nB\n\n\n969\n168.53\n93.80\nBlue\nA\n\n\n970\n156.00\n90.44\nGrey\nB\n\n\n971\n166.66\n60.89\nBrown\nA\n\n\n972\n161.20\n56.18\nGreen\nA\n\n\n973\n179.80\n77.04\nBrown\nA\n\n\n974\n164.49\n82.16\nGreen\nB\n\n\n975\n164.97\n77.10\nGreen\nA\n\n\n976\n166.25\n72.15\nBlue\nB\n\n\n977\n165.78\n84.93\nBlue\nA\n\n\n978\n159.43\n77.98\nGreen\nB\n\n\n979\n165.40\n108.75\nGrey\nB\n\n\n980\n168.26\n83.79\nGrey\nA\n\n\n981\n171.39\n91.25\nGrey\nA\n\n\n982\n176.38\n70.61\nGreen\nB\n\n\n983\n174.40\n85.17\nGrey\nB\n\n\n984\n169.76\n73.37\nGreen\nA\n\n\n985\n158.29\n96.39\nGrey\nA\n\n\n986\n177.91\n83.13\nGrey\nB\n\n\n987\n167.58\n72.57\nGreen\nA\n\n\n988\n158.10\n67.28\nGrey\nB\n\n\n989\n170.73\n95.74\nBrown\nB\n\n\n990\n165.32\n89.17\nBrown\nB\n\n\n991\n175.11\n72.74\nGrey\nB\n\n\n992\n167.17\n88.95\nGreen\nB\n\n\n993\n172.26\n104.35\nGrey\nA\n\n\n994\n162.35\n60.29\nBrown\nA\n\n\n995\n162.48\n90.76\nGreen\nA\n\n\n996\n174.42\n85.16\nBlue\nA\n\n\n997\n169.26\n72.03\nBrown\nA\n\n\n998\n178.41\n75.57\nGrey\nB\n\n\n999\n167.06\n77.55\nBlue\nB\n\n\n1000\n169.07\n92.08\nBlue\nA"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#check-how-similar-they-are",
    "href": "content/slides/01-07-experiments.html#check-how-similar-they-are",
    "title": "Causal Effects and Experiments",
    "section": "Check how similar they are",
    "text": "Check how similar they are"
  },
  {
    "objectID": "content/slides/01-07-experiments.html#increasingly-similar",
    "href": "content/slides/01-07-experiments.html#increasingly-similar",
    "title": "Causal Effects and Experiments",
    "section": "Increasingly similar",
    "text": "Increasingly similar\nIn fact, if we did this many, many, many times, these groups would be, on average, increasingly identical!\nWhy?\n\nCentral limit theorem\nLaw of large numbers\n\n\n\nWe will talk more about those concepts later in the course."
  },
  {
    "objectID": "content/slides/01-07-experiments.html#do-international-monitors-deter-election-day-fraud",
    "href": "content/slides/01-07-experiments.html#do-international-monitors-deter-election-day-fraud",
    "title": "Causal Effects and Experiments",
    "section": "Do international monitors deter election-day fraud?",
    "text": "Do international monitors deter election-day fraud?\nYes!\n\nThe international community monitored the 2003 Armenian Presidential elections\nMonitors were assigned randomly to the polling stations\nHyde found a big average difference between the vote share received by the cheating party at monitored stations compared to non-monitored stations."
  }
]