---
title: "Causal Effects and Experiments"
subtitle: "GVPT399F: Power, Politics, and Data"
format: 
  revealjs:
    slide-number: true
    preview-links: auto
    theme: solarized
    embed-resources: true
execute: 
  echo: true
  warning: false
  fig-align: "center"
bibliography: references.bib
---

```{r}
#| echo: false 

library(tidyverse)
```

## Causes and effects

Our goal is to better understand what factors lead to certain outcomes of interest.

-   Does increasing the number of voting booths close to a potential voter make that person more likely to vote?

-   Do peace treaties signed with factionalized rebel groups more often lead to a return to conflict than those signed with a single, cohesive group?

-   Does trade between two countries make war between them less likely?

## Causes and effects

These are causal statements:

-   More local voting booths $\rightarrow$ More likely to vote

-   More factionalization $\rightarrow$ More likely to restart conflict

-   Trade $\rightarrow$ Less likely to go to war

## How to identify causes and their effects

Proving that changes to one factor *cause* changes to another is very tricky!

-   Need to account for all the other factors

## The efficacy of international election monitors

Do international monitors cause less election-day fraud in democratic elections?

-   Number of elections monitored by international observers exploded throughout the 2000s

-   But do monitors increase the chances the election will be free and fair?

-   In other words, are they effective?

::: aside
Hyde, Susan D. 2007. “The Observer Effect in International Politics: Evidence from a Natural Experiment.” World Politics 60 (1): 37–63. http://www.jstor.org/stable/40060180.
:::

## The efficacy of international election monitors

Dr Susan Hyde set out to answer this very question. From her article (page 39):

> If the presence of international observers causes a reduction in election-day fraud, the effect of observers should be visible at the subnational level by comparing polling stations that were visited by observers with those that were not visited. More specifically, if international monitoring reduces electionday fraud directly, all else held equal, the cheating parties should gain less of their ill-gotten vote share in polling stations that were visited by international monitors.

## Causal relationships

Refers to the directional connection between a change in one variable and a corresponding change in another.

-   The direction matters!

-   **Treatment variable:** the variable causing changes to another variable.

-   **Outcome variable:** the variable changing as a result of changes to another variable (the treatment).

## Treatment and outcome variables

We want to test whether the presence of international monitors (treatment) leads to less election day fraud (outcome).

*International election monitors present at polling stations* $\rightarrow$ *Less election-day fraud at that station*

## Treatment variable

At any given polling station in any given election, monitors may be: 1) present, or 2) not present.

Two different conditions:

-   **Treatment:** condition with treatment (monitors are present)

-   **Control:** condition without treatment (monitors are not present)

::: aside
Treatment variables do not need to be binary.
:::

## Outcome variable

At any given polling station in any given election, fraud may: 1) occur, or 2) not occur.

::: aside
Outcome variables also do not need to binary.
:::

## Observing our outcome

Sometimes it can be hard to observe our outcome of interest.

-   How might we see all election-day fraud?

-   How might we measure it?

## Observing our outcome

Hyde's answer: vote-share!

*International election monitors present at polling stations* $\rightarrow$ *Less election-day fraud at that station* $\rightarrow$ *Lower vote-share for the cheating party*

## Individual causal effects

We want to know whether the treatment *causes* a change in our outcome of interest.

What might this look like in the real world?

-   Imagine we are looking at a specific election

-   Five polling stations

## Parallel worlds

![](img/indiv_exp.png){fig-align="center"}

## Hypothetical election

```{r}
#| echo: false

indiv_effect_df <- tibble(
  polling_station_id = 1:5,
  vote_share_monitored = round(rbeta(5, 4, 6) * 100, 2),
  vote_share_not_monitored = round(rbeta(5, 11, 2) * 100, 2)
)

indiv_effect_df |> 
  rename(ID = polling_station_id,
         `Monitored vote %` = vote_share_monitored,
         `Non-monitored vote %` = vote_share_not_monitored) |> 
  knitr::kable()
```

## Individual effects

The *only* difference between these two conditions is the presence of international monitors!

-   The difference between vote shares under these conditions is *caused by the monitors*.

## Individual effects

```{r}
#| echo: false

indiv_effect_df |> 
  mutate(difference = vote_share_monitored - vote_share_not_monitored) |> 
  rename(ID = polling_station_id,
         `Monitored vote %` = vote_share_monitored,
         `Non-monitored vote %` = vote_share_not_monitored,
         `Difference (%)` = difference) |> 
  knitr::kable()
```

## No parallel worlds

Sadly for us, we cannot create parallel worlds...

## What now?

```{r}
#| echo: false

factual_indiv_df <- indiv_effect_df |> 
  mutate(monitored = rbinom(5, 1, 0.5),
         vote_share_monitored = if_else(monitored == 1, vote_share_monitored, NA_real_),
         vote_share_not_monitored = if_else(monitored == 0, vote_share_not_monitored, NA_real_)) |> 
  relocate(monitored, .after = polling_station_id)

factual_indiv_df |> 
  mutate(difference = vote_share_monitored - vote_share_not_monitored) |> 
  rename(ID = polling_station_id,
         Monitored = monitored,
         `Monitored vote %` = vote_share_monitored,
         `Non-monitored vote %` = vote_share_not_monitored,
         Difference = difference) |> 
  knitr::kable()
```

## Average causal effects

We need to move away from looking at individuals and start to look for patterns in our group.

## Back to our parallel worlds

```{r}
#| echo: false

indiv_effect_df |> 
  mutate(difference = vote_share_monitored - vote_share_not_monitored) |> 
  rename(ID = polling_station_id,
         `Monitored vote %` = vote_share_monitored,
         `Non-monitored vote %` = vote_share_not_monitored,
         Difference = difference) |> 
  knitr::kable()
```

## Difference of averages across all individuals

What was the average vote share received in each world?

```{r}
#| echo: false

indiv_effect_df |> 
  mutate(difference = vote_share_monitored - vote_share_not_monitored) |> 
  summarise(vote_share_monitored = round(mean(vote_share_monitored), 2),
            vote_share_not_monitored = round(mean(vote_share_not_monitored), 2),
            difference = vote_share_monitored - vote_share_not_monitored) |> 
  rename(`Avg. monitored vote %` = vote_share_monitored,
         `Avg. non-monitored vote %` = vote_share_not_monitored,
         Difference = difference) |> 
  knitr::kable()
```

## Back to reality

```{r}
#| echo: false

factual_indiv_df |> 
  mutate(difference = vote_share_monitored - vote_share_not_monitored) |> 
  rename(ID = polling_station_id,
         Monitored = monitored,
         `Monitored vote %` = vote_share_monitored,
         `Non-monitored vote %` = vote_share_not_monitored,
         Difference = difference) |> 
  knitr::kable()
```

## Difference-of-means

What was the average vote share received in each group?

```{r}
#| echo: false

factual_indiv_df |> 
  mutate(difference = vote_share_monitored - vote_share_not_monitored) |> 
  summarise(vote_share_monitored = mean(vote_share_monitored, na.rm = T),
            vote_share_not_monitored = mean(vote_share_not_monitored, na.rm = T),
            difference = vote_share_monitored - vote_share_not_monitored) |> 
  mutate(across(everything(), ~ round(.x, 2))) |> 
  rename(`Avg. monitored vote %` = vote_share_monitored,
         `Avg. non-monitored vote %` = vote_share_not_monitored,
         Difference = difference) |> 
  knitr::kable()
```

## How on Earth does this work so well?

Randomization!

-   Monitors were assigned to polling stations randomly (for example, with the flip of a coin)

-   This created two groups of stations that were roughly identical **on average** to one another prior to treatment

-   This mimics what happens when we split our world into two (creating two literally identical groups)

## Our goal

We want two groups that are completely identical to one another prior to treatment.

-   This allows us to compare their outcomes after treatment and claim that the treatment *caused* differences in those outcomes (if any differences exist)

## Our goal

![](img/indiv_exp.png){fig-align="center"}

## Next best thing

Instead, we should try to make two groups that are as similar as possible to each other prior to treatment.

## The magic of randomization

Perfectly random assignment does this very well!

![](img/coin.webp){fig-align="center"}

## Don't take my word for it

Imagine we have a group of 1,000 individuals. We know the following about them:

-   Height

-   Weight

-   Eye colour

## Our group

```{r}
#| echo: false

group_df <- tibble(
  id = 1:1000,
  height = rnorm(1000, 170, 6),
  weight = rnorm(1000, 80, 10),
  eye_colour = sample(c("Blue", "Green", "Brown", "Grey"), 1000, replace = T)
) 

group_df |> 
  mutate(across(height:weight, ~ round(.x, 2))) |> 
  rename(ID = id,
         Height = height, 
         Weight = weight, 
         `Eye colour` = eye_colour) |> 
  knitr::kable()
```

## Random assignment

I'm now going to flip (an imaginary, computer-generated) coin for each of these 1,000 individuals to assigned them to group A or B:

```{r}
#| echo: false

rand_group <- group_df |> 
  mutate(
    group = rbinom(1000, 1, 0.5),
    group = factor(group, labels = c("A", "B"))
  )

rand_group |> 
  mutate(across(height:weight, ~ round(.x, 2))) |> 
  rename(ID = id,
         Height = height, 
         Weight = weight, 
         `Eye colour` = eye_colour, 
         Group = group) |> 
  knitr::kable()
```

## How similar are these groups?

Let's first check their heights:

```{r}
#| echo: false

ggplot(rand_group, aes(x = height, fill = group)) + 
  geom_density(alpha = 0.5) + 
  theme_minimal() + 
  labs(x = "Height (cm)",
       y = "Density",
       fill = "Group")
```

## How similar are these groups?

And their weights:

```{r}
#| echo: false

ggplot(rand_group, aes(x = weight, fill = group)) + 
  geom_density(alpha = 0.5) + 
  theme_minimal() + 
  labs(x = "Weight (kg)",
       y = "Density",
       fill = "Group")
```

## How similar are these groups?

And their eye colors:

```{r}
#| echo: false

rand_group |> 
  count(group, eye_colour) |> 
  ggplot(aes(x = n, y = reorder(eye_colour, n), fill = group)) + 
  geom_bar(position = "dodge", stat = "identity") + 
  labs(x = "Count",
       y = "Eye color",
       fill = "Group")
```

## Making sure this wasn't a fluke

Let's re-run this:

```{r}
#| echo: false

rand_group <- rand_group |> 
  mutate(
    group = rbinom(1000, 1, 0.5),
    group = factor(group, labels = c("A", "B"))
  )

rand_group |> 
  mutate(across(height:weight, ~ round(.x, 2))) |> 
  rename(ID = id,
         Height = height, 
         Weight = weight, 
         `Eye colour` = eye_colour, 
         Group = group) |> 
  knitr::kable()
```

## Check how similar they are

```{r}
#| echo: false

library(patchwork)

p1 <- ggplot(rand_group, aes(x = height, fill = group)) + 
  geom_density(alpha = 0.5) + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(x = "Height (cm)",
       y = "Density",
       fill = "Group")

p2 <- ggplot(rand_group, aes(x = weight, fill = group)) + 
  geom_density(alpha = 0.5) + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(x = "Weight (kg)",
       y = "Density",
       fill = "Group")

p3 <- rand_group |> 
  count(group, eye_colour) |> 
  ggplot(aes(x = n, y = reorder(eye_colour, n), fill = group)) + 
  geom_bar(position = "dodge", stat = "identity") + 
  labs(x = "Count",
       y = "Eye color",
       fill = "Group")

p1 | p2 | p3
```

## Increasingly similar

In fact, if we did this many, many, many times, these groups would be, on average, increasingly identical!

Why?

-   Central limit theorem

-   Law of large numbers

::: aside
We will talk more about those concepts later in the course.
:::

## Do international monitors deter election-day fraud?

Yes!

-   The international community monitored the 2003 Armenian Presidential elections
-   Monitors were assigned randomly to the polling stations
-   Hyde found a big average difference between the vote share received by the cheating party at monitored stations compared to non-monitored stations.
